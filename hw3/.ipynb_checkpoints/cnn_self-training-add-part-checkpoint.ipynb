{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "METHOD = 'cnn_self-training-add-part'\n",
    "\n",
    "LABELLED_DATA_FILE = 'data/all_label.p'\n",
    "UNLABELED_DATA_FILE = 'data/all_unlabel.p'\n",
    "TEST_DATA_FILE = 'data/test.p'\n",
    "\n",
    "OUTPUT_FOLDER = 'output/'\n",
    "MODEL_FOLDER = 'model/' + METHOD + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(MODEL_FOLDER):\n",
    "    os.makedirs(MODEL_FOLDER)\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelled_data = np.array(pickle.load(open(LABELLED_DATA_FILE, 'rb')))\n",
    "unlabeled_data = np.array(pickle.load(open(UNLABELED_DATA_FILE, 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "img_rows, img_cols, img_channels = 32, 32, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate x, y from data\n",
    "\n",
    "# reshape labelled data to (5000, 3, 32, 32)\n",
    "X_train_label = labelled_data.reshape((5000, img_channels, img_rows, img_cols)).astype('float32') / 255\n",
    "\n",
    "# reshape unlabeled data to (45000, 3, 32, 32)\n",
    "nb_unlabeled_data = unlabeled_data.shape[0]\n",
    "X_train_unlabel = unlabeled_data.reshape((nb_unlabeled_data, img_channels, img_rows, img_cols)).astype('float32') / 255\n",
    "\n",
    "y_train_label_class = np.array([classIdx for classIdx in range(len(labelled_data)) for i in range(len(labelled_data[classIdx]))])\n",
    "Y_train_label = np_utils.to_categorical(y_train_label_class, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: remove\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train_reshaped = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_train]) / 255.0\n",
    "X_test_reshaped = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_test]) / 255.0\n",
    "Y_test_categ = np_utils.to_categorical(y_test.flatten(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJrElEQVR4nCXTW29cx2EA4LnPnDm3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\noyQO/gjApWe1WMMl7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F4631200B70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize\n",
    "from scipy.misc import toimage\n",
    "toimage(X_train_unlabel[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "def certainty(prob_arr):  # higher is more certain\n",
    "    return -entropy(prob_arr)\n",
    "\n",
    "def uncertainty(prob_arr):  # lower is better. for descending-ordered sorting\n",
    "    return entropy(prob_arr)\n",
    "\n",
    "#     sorted_arr = np.sort(prob_arr)\n",
    "#     return sorted_arr[-1] / sorted_arr[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set model\n",
    "\n",
    "def reset_model():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\", input_shape=X_train_label.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(Convolution2D(32, 3, 3))\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same', dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(Convolution2D(64, 3, 3))\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same', dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# avoid change to the original labelled data\n",
    "X_train_ori_label = np.copy(X_train_label)\n",
    "Y_train_ori_label = np.copy(Y_train_label)\n",
    "X_train_ori_unlabel = np.copy(X_train_unlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extract_ratio = 0.25\n",
    "nb_extract_rounds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_round: 1\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 2s - loss: 2.2342 - acc: 0.1524 - val_loss: 2.3845 - val_acc: 0.1092\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.9670 - acc: 0.2832 - val_loss: 2.5522 - val_acc: 0.1411\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.8132 - acc: 0.3324 - val_loss: 2.3840 - val_acc: 0.1799\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.7040 - acc: 0.3718 - val_loss: 2.5060 - val_acc: 0.1935\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.6239 - acc: 0.4068 - val_loss: 2.3253 - val_acc: 0.2121\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.5676 - acc: 0.4322 - val_loss: 2.2023 - val_acc: 0.2438\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.5123 - acc: 0.4446 - val_loss: 2.1344 - val_acc: 0.2609\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.4592 - acc: 0.4674 - val_loss: 2.2576 - val_acc: 0.2493\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.4203 - acc: 0.4798 - val_loss: 2.3167 - val_acc: 0.2400\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.3874 - acc: 0.5018 - val_loss: 2.0688 - val_acc: 0.2807\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.3344 - acc: 0.5240 - val_loss: 2.1414 - val_acc: 0.2786\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.3127 - acc: 0.5296 - val_loss: 2.1765 - val_acc: 0.2755\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.2884 - acc: 0.5300 - val_loss: 2.0951 - val_acc: 0.2751\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.2354 - acc: 0.5560 - val_loss: 2.2524 - val_acc: 0.2662\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.1944 - acc: 0.5742 - val_loss: 2.1782 - val_acc: 0.2895\n",
      "Epoch 16/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.1654 - acc: 0.5800 - val_loss: 2.0599 - val_acc: 0.3076\n",
      "Epoch 17/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.1537 - acc: 0.5818 - val_loss: 2.1437 - val_acc: 0.2854\n",
      "Epoch 18/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.1142 - acc: 0.5956 - val_loss: 1.9627 - val_acc: 0.3340\n",
      "Epoch 19/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.1046 - acc: 0.6024 - val_loss: 1.9737 - val_acc: 0.3265\n",
      "Epoch 20/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.0677 - acc: 0.6160 - val_loss: 2.0259 - val_acc: 0.3268\n",
      "Epoch 21/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.0075 - acc: 0.6378 - val_loss: 2.0707 - val_acc: 0.3194\n",
      "Epoch 22/100\n",
      "5000/5000 [==============================] - 1s - loss: 1.0092 - acc: 0.6310 - val_loss: 2.1468 - val_acc: 0.3068\n",
      "Epoch 23/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.9666 - acc: 0.6540 - val_loss: 2.0706 - val_acc: 0.3344\n",
      "Epoch 24/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.9402 - acc: 0.6632 - val_loss: 2.0426 - val_acc: 0.3331\n",
      "Epoch 25/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.9013 - acc: 0.6844 - val_loss: 2.0858 - val_acc: 0.3389\n",
      "Epoch 26/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.9065 - acc: 0.6752 - val_loss: 2.0663 - val_acc: 0.3309\n",
      "Epoch 27/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.8607 - acc: 0.6950 - val_loss: 2.0659 - val_acc: 0.3405\n",
      "Epoch 28/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.8372 - acc: 0.7042 - val_loss: 2.1142 - val_acc: 0.3334\n",
      "Epoch 29/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.8158 - acc: 0.7102 - val_loss: 2.0330 - val_acc: 0.3497\n",
      "Epoch 30/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.7934 - acc: 0.7228 - val_loss: 2.1235 - val_acc: 0.3372\n",
      "Epoch 31/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.7854 - acc: 0.7224 - val_loss: 2.1685 - val_acc: 0.3418\n",
      "Epoch 32/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.7586 - acc: 0.7264 - val_loss: 2.1335 - val_acc: 0.3499\n",
      "Epoch 33/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.7494 - acc: 0.7358 - val_loss: 2.0987 - val_acc: 0.3497\n",
      "Epoch 34/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.7127 - acc: 0.7556 - val_loss: 2.2322 - val_acc: 0.3378\n",
      "Epoch 35/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.6813 - acc: 0.7538 - val_loss: 2.3278 - val_acc: 0.3439\n",
      "Epoch 36/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.6898 - acc: 0.7526 - val_loss: 2.1640 - val_acc: 0.3506\n",
      "Epoch 37/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.6473 - acc: 0.7722 - val_loss: 2.2465 - val_acc: 0.3427\n",
      "Epoch 38/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.6439 - acc: 0.7712 - val_loss: 2.3893 - val_acc: 0.3325\n",
      "Epoch 39/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.6277 - acc: 0.7732 - val_loss: 2.3098 - val_acc: 0.3377\n",
      "Epoch 40/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.6006 - acc: 0.7798 - val_loss: 2.4568 - val_acc: 0.3384\n",
      "Epoch 41/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.5858 - acc: 0.7886 - val_loss: 2.2390 - val_acc: 0.3606\n",
      "Epoch 42/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.5858 - acc: 0.7900 - val_loss: 2.5577 - val_acc: 0.3353\n",
      "Epoch 43/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.5874 - acc: 0.7878 - val_loss: 2.3683 - val_acc: 0.3428\n",
      "Epoch 44/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.5567 - acc: 0.8080 - val_loss: 2.4436 - val_acc: 0.3438\n",
      "Epoch 45/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.5470 - acc: 0.8034 - val_loss: 2.5564 - val_acc: 0.3359\n",
      "Epoch 46/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.5334 - acc: 0.8118 - val_loss: 2.3499 - val_acc: 0.3493\n",
      "Epoch 47/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.5304 - acc: 0.8150 - val_loss: 2.4471 - val_acc: 0.3508\n",
      "Epoch 48/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.5129 - acc: 0.8152 - val_loss: 2.3370 - val_acc: 0.3561\n",
      "Epoch 49/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4977 - acc: 0.8248 - val_loss: 2.3346 - val_acc: 0.3522\n",
      "Epoch 50/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4795 - acc: 0.8342 - val_loss: 2.6489 - val_acc: 0.3367\n",
      "Epoch 51/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4809 - acc: 0.8276 - val_loss: 2.3299 - val_acc: 0.3656\n",
      "Epoch 52/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4880 - acc: 0.8250 - val_loss: 2.4497 - val_acc: 0.3528\n",
      "Epoch 53/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4522 - acc: 0.8398 - val_loss: 2.5026 - val_acc: 0.3642\n",
      "Epoch 54/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4470 - acc: 0.8392 - val_loss: 2.7001 - val_acc: 0.3447\n",
      "Epoch 55/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4183 - acc: 0.8552 - val_loss: 2.6509 - val_acc: 0.3481\n",
      "Epoch 56/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4210 - acc: 0.8532 - val_loss: 2.7212 - val_acc: 0.3315\n",
      "Epoch 57/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4785 - acc: 0.8362 - val_loss: 2.6847 - val_acc: 0.3315\n",
      "Epoch 58/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.4348 - acc: 0.8432 - val_loss: 3.0311 - val_acc: 0.3221\n",
      "Epoch 59/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4529 - acc: 0.8408 - val_loss: 2.4688 - val_acc: 0.3642\n",
      "Epoch 60/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3980 - acc: 0.8604 - val_loss: 2.6284 - val_acc: 0.3547\n",
      "Epoch 61/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4047 - acc: 0.8596 - val_loss: 2.6036 - val_acc: 0.3565\n",
      "Epoch 62/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.4033 - acc: 0.8564 - val_loss: 2.5803 - val_acc: 0.3609\n",
      "Epoch 63/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4083 - acc: 0.8594 - val_loss: 2.6139 - val_acc: 0.3543\n",
      "Epoch 64/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3900 - acc: 0.8660 - val_loss: 2.6524 - val_acc: 0.3686\n",
      "Epoch 65/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3659 - acc: 0.8734 - val_loss: 3.0191 - val_acc: 0.3368\n",
      "Epoch 66/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3773 - acc: 0.8662 - val_loss: 2.6407 - val_acc: 0.3661\n",
      "Epoch 67/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3843 - acc: 0.8682 - val_loss: 3.1656 - val_acc: 0.3373\n",
      "Epoch 68/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3975 - acc: 0.8620 - val_loss: 2.6196 - val_acc: 0.3660\n",
      "Epoch 69/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3787 - acc: 0.8668 - val_loss: 2.5185 - val_acc: 0.3718\n",
      "Epoch 70/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3474 - acc: 0.8790 - val_loss: 2.6686 - val_acc: 0.3663\n",
      "Epoch 71/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3506 - acc: 0.8788 - val_loss: 2.6805 - val_acc: 0.3682\n",
      "Epoch 72/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.3499 - acc: 0.8788 - val_loss: 2.8716 - val_acc: 0.3525\n",
      "Epoch 73/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3592 - acc: 0.8786 - val_loss: 2.9094 - val_acc: 0.3546\n",
      "Epoch 74/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3390 - acc: 0.8808 - val_loss: 2.8137 - val_acc: 0.3558\n",
      "Epoch 75/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3213 - acc: 0.8874 - val_loss: 2.9087 - val_acc: 0.3508\n",
      "Epoch 76/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3406 - acc: 0.8820 - val_loss: 2.6877 - val_acc: 0.3691\n",
      "Epoch 77/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3477 - acc: 0.8790 - val_loss: 2.6959 - val_acc: 0.3636\n",
      "Epoch 78/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3201 - acc: 0.8894 - val_loss: 2.9943 - val_acc: 0.3454\n",
      "Epoch 79/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3167 - acc: 0.8904 - val_loss: 2.7959 - val_acc: 0.3694\n",
      "Epoch 80/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3251 - acc: 0.8890 - val_loss: 2.9255 - val_acc: 0.3615\n",
      "Epoch 81/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3019 - acc: 0.8942 - val_loss: 3.1033 - val_acc: 0.3439\n",
      "Epoch 82/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.3261 - acc: 0.8864 - val_loss: 2.8732 - val_acc: 0.3573\n",
      "Epoch 83/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3089 - acc: 0.8948 - val_loss: 2.9801 - val_acc: 0.3635\n",
      "Epoch 84/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3022 - acc: 0.8944 - val_loss: 2.9185 - val_acc: 0.3589\n",
      "Epoch 85/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2899 - acc: 0.9034 - val_loss: 2.9425 - val_acc: 0.3669\n",
      "Epoch 86/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3013 - acc: 0.8942 - val_loss: 2.7873 - val_acc: 0.3816\n",
      "Epoch 87/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3238 - acc: 0.8918 - val_loss: 2.9009 - val_acc: 0.3614\n",
      "Epoch 88/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3084 - acc: 0.8974 - val_loss: 3.2156 - val_acc: 0.3537\n",
      "Epoch 89/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3040 - acc: 0.8964 - val_loss: 2.8425 - val_acc: 0.3695\n",
      "Epoch 90/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3107 - acc: 0.8964 - val_loss: 2.9358 - val_acc: 0.3618\n",
      "Epoch 91/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2895 - acc: 0.9022 - val_loss: 3.0963 - val_acc: 0.3588\n",
      "Epoch 92/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2922 - acc: 0.8974 - val_loss: 3.1032 - val_acc: 0.3607\n",
      "Epoch 93/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2839 - acc: 0.9046 - val_loss: 3.0599 - val_acc: 0.3550\n",
      "Epoch 94/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.2714 - acc: 0.9034 - val_loss: 3.2112 - val_acc: 0.3497\n",
      "Epoch 95/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.3103 - acc: 0.8918 - val_loss: 3.3140 - val_acc: 0.3517\n",
      "Epoch 96/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.2687 - acc: 0.9058 - val_loss: 2.8082 - val_acc: 0.3796\n",
      "Epoch 97/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2654 - acc: 0.9072 - val_loss: 2.9841 - val_acc: 0.3692\n",
      "Epoch 98/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.2683 - acc: 0.9098 - val_loss: 2.9113 - val_acc: 0.3768\n",
      "Epoch 99/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2647 - acc: 0.9078 - val_loss: 3.0001 - val_acc: 0.3675\n",
      "Epoch 100/100\n",
      "5000/5000 [==============================] - 1s - loss: 0.2655 - acc: 0.9040 - val_loss: 2.9310 - val_acc: 0.3715\n",
      "45000/45000 [==============================] - 5s     \n",
      "45000/45000 [==============================] - 4s     \n",
      "extract_round: 2\n",
      "Train on 16250 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "16250/16250 [==============================] - 4s - loss: 1.5156 - acc: 0.4884 - val_loss: 2.8906 - val_acc: 0.1697\n",
      "Epoch 2/100\n",
      "16250/16250 [==============================] - 4s - loss: 1.0012 - acc: 0.6690 - val_loss: 2.3834 - val_acc: 0.2530\n",
      "Epoch 3/100\n",
      "16250/16250 [==============================] - 4s - loss: 0.8291 - acc: 0.7289 - val_loss: 2.6221 - val_acc: 0.2552\n",
      "Epoch 4/100\n",
      "16250/16250 [==============================] - 4s - loss: 0.7406 - acc: 0.7610 - val_loss: 2.2065 - val_acc: 0.2863\n",
      "Epoch 5/100\n",
      "16250/16250 [==============================] - 4s - loss: 0.6839 - acc: 0.7830 - val_loss: 2.1991 - val_acc: 0.3181\n",
      "Epoch 6/100\n",
      "16250/16250 [==============================] - 4s - loss: 0.6326 - acc: 0.7930 - val_loss: 2.2891 - val_acc: 0.3039\n",
      "Epoch 7/100\n",
      "16250/16250 [==============================] - 4s - loss: 0.5935 - acc: 0.8031 - val_loss: 2.1193 - val_acc: 0.3245\n",
      "Epoch 8/100\n",
      "16192/16250 [============================>.] - ETA: 0s - loss: 0.5596 - acc: 0.8168"
     ]
    }
   ],
   "source": [
    "# extract high-certainty labelled-unlabeled data and add to labelled dataset\n",
    "\n",
    "# TODO: remove (X_test_reshaped, Y_test_categ),\n",
    "\n",
    "for extract_round in range(nb_extract_rounds):\n",
    "    print('extract_round:', extract_round+1)\n",
    "    # reset model\n",
    "    model = reset_model()\n",
    "    \n",
    "    # train model\n",
    "    model.fit(X_train_label, Y_train_label,\n",
    "        batch_size=batch_size,\n",
    "        nb_epoch=nb_epoch,  # nb_epoch,\n",
    "        validation_data=(X_test_reshaped, Y_test_categ),\n",
    "        shuffle=True)\n",
    "\n",
    "    # use the model to label unlabeled data\n",
    "    Y_train_unlabel_proba = model.predict_proba(X_train_unlabel, batch_size=10000)  # same as model.predict\n",
    "    Y_train_unlabel_uncertainty = np.apply_along_axis(uncertainty, 1, Y_train_unlabel_proba)\n",
    "    \n",
    "    Y_train_unlabel_class = model.predict_classes(X_train_unlabel, batch_size=10000)\n",
    "    Y_train_unlabel = np_utils.to_categorical(Y_train_unlabel_class, nb_classes)\n",
    "\n",
    "    # sort unlabeled data by uncertainty\n",
    "    sorted_idxs = Y_train_unlabel_uncertainty.argsort()\n",
    "    X_train_unlabel = X_train_unlabel[sorted_idxs]\n",
    "    Y_train_unlabel = Y_train_unlabel[sorted_idxs]\n",
    "    \n",
    "    # extract high-certainty unlabeled data\n",
    "    nb_extract = int(X_train_unlabel.shape[0] * extract_ratio)\n",
    "    X_train_unlabel_certain, X_train_unlabel_uncertain = X_train_unlabel[:nb_extract], X_train_unlabel[nb_extract:]\n",
    "    Y_train_unlabel_certain, Y_train_unlabel_uncertain = Y_train_unlabel[:nb_extract], Y_train_unlabel[nb_extract:]\n",
    "\n",
    "    # update labelled dataset and unlabeled dataset\n",
    "    X_train_label = np.concatenate((X_train_label, X_train_unlabel_certain))\n",
    "    Y_train_label = np.concatenate((Y_train_label, Y_train_unlabel_certain))\n",
    "    X_train_unlabel = X_train_unlabel_uncertain\n",
    "    Y_train_unlabel = Y_train_unlabel_uncertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set model\n",
    "\n",
    "def reset_model_2():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\", input_shape=X_train_label.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(Convolution2D(64, 3, 3))\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same', dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(Convolution2D(64, 3, 3))\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same', dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16250 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "16250/16250 [==============================] - 5s - loss: 1.4473 - acc: 0.5078 - val_loss: 2.5511 - val_acc: 0.1915\n",
      "Epoch 2/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.9391 - acc: 0.6902 - val_loss: 2.2550 - val_acc: 0.2689\n",
      "Epoch 3/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.7727 - acc: 0.7449 - val_loss: 2.1235 - val_acc: 0.3000\n",
      "Epoch 4/100\n",
      "16250/16250 [==============================] - 4s - loss: 0.6811 - acc: 0.7770 - val_loss: 2.3524 - val_acc: 0.2834\n",
      "Epoch 5/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.6295 - acc: 0.7956 - val_loss: 2.0804 - val_acc: 0.3232\n",
      "Epoch 6/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.5739 - acc: 0.8124 - val_loss: 2.0535 - val_acc: 0.3360\n",
      "Epoch 7/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.5570 - acc: 0.8224 - val_loss: 1.9920 - val_acc: 0.3517\n",
      "Epoch 8/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.5074 - acc: 0.8343 - val_loss: 2.1426 - val_acc: 0.3430\n",
      "Epoch 9/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.4776 - acc: 0.8447 - val_loss: 2.0036 - val_acc: 0.3751\n",
      "Epoch 10/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.4569 - acc: 0.8486 - val_loss: 1.9798 - val_acc: 0.3808\n",
      "Epoch 11/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.4399 - acc: 0.8552 - val_loss: 2.0158 - val_acc: 0.3717\n",
      "Epoch 12/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.4163 - acc: 0.8604 - val_loss: 2.0027 - val_acc: 0.3837\n",
      "Epoch 13/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3973 - acc: 0.8696 - val_loss: 1.9910 - val_acc: 0.3936\n",
      "Epoch 14/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3839 - acc: 0.8710 - val_loss: 1.9940 - val_acc: 0.3963\n",
      "Epoch 15/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3731 - acc: 0.8767 - val_loss: 2.1148 - val_acc: 0.3841\n",
      "Epoch 16/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3555 - acc: 0.8823 - val_loss: 2.0404 - val_acc: 0.3944\n",
      "Epoch 17/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3502 - acc: 0.8828 - val_loss: 2.0810 - val_acc: 0.3982\n",
      "Epoch 18/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3334 - acc: 0.8873 - val_loss: 2.1306 - val_acc: 0.3935\n",
      "Epoch 19/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3233 - acc: 0.8927 - val_loss: 2.1666 - val_acc: 0.3848\n",
      "Epoch 20/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3078 - acc: 0.8964 - val_loss: 2.1070 - val_acc: 0.4006\n",
      "Epoch 21/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3057 - acc: 0.8981 - val_loss: 2.1558 - val_acc: 0.4151\n",
      "Epoch 22/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2911 - acc: 0.9012 - val_loss: 2.4540 - val_acc: 0.3560\n",
      "Epoch 23/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2847 - acc: 0.9051 - val_loss: 2.2028 - val_acc: 0.3997\n",
      "Epoch 24/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2677 - acc: 0.9074 - val_loss: 2.1635 - val_acc: 0.4188\n",
      "Epoch 25/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2730 - acc: 0.9070 - val_loss: 2.3124 - val_acc: 0.3922\n",
      "Epoch 26/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2575 - acc: 0.9110 - val_loss: 2.2439 - val_acc: 0.3978\n",
      "Epoch 27/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2592 - acc: 0.9121 - val_loss: 2.2879 - val_acc: 0.3986\n",
      "Epoch 28/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2490 - acc: 0.9165 - val_loss: 2.2796 - val_acc: 0.3960\n",
      "Epoch 29/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2346 - acc: 0.9190 - val_loss: 2.4169 - val_acc: 0.3956\n",
      "Epoch 30/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2430 - acc: 0.9166 - val_loss: 2.3274 - val_acc: 0.4045\n",
      "Epoch 31/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2225 - acc: 0.9231 - val_loss: 2.4131 - val_acc: 0.3935\n",
      "Epoch 32/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2220 - acc: 0.9230 - val_loss: 2.4183 - val_acc: 0.4083\n",
      "Epoch 33/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2268 - acc: 0.9226 - val_loss: 2.2738 - val_acc: 0.4294\n",
      "Epoch 34/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2207 - acc: 0.9247 - val_loss: 2.3509 - val_acc: 0.4132\n",
      "Epoch 35/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2223 - acc: 0.9254 - val_loss: 2.4544 - val_acc: 0.3938\n",
      "Epoch 36/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2233 - acc: 0.9280 - val_loss: 2.3607 - val_acc: 0.4104\n",
      "Epoch 37/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2097 - acc: 0.9299 - val_loss: 2.4233 - val_acc: 0.4024\n",
      "Epoch 38/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2033 - acc: 0.9321 - val_loss: 2.4290 - val_acc: 0.4217\n",
      "Epoch 39/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2165 - acc: 0.9273 - val_loss: 2.5076 - val_acc: 0.3988\n",
      "Epoch 40/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1943 - acc: 0.9314 - val_loss: 2.4187 - val_acc: 0.4133\n",
      "Epoch 41/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1936 - acc: 0.9329 - val_loss: 2.5569 - val_acc: 0.4037\n",
      "Epoch 42/100\n",
      "16250/16250 [==============================] - 4s - loss: 0.1963 - acc: 0.9343 - val_loss: 2.4930 - val_acc: 0.4110\n",
      "Epoch 43/100\n",
      "16250/16250 [==============================] - 4s - loss: 0.1931 - acc: 0.9352 - val_loss: 2.6855 - val_acc: 0.3945\n",
      "Epoch 44/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1830 - acc: 0.9375 - val_loss: 2.6187 - val_acc: 0.4096\n",
      "Epoch 45/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1888 - acc: 0.9361 - val_loss: 2.6977 - val_acc: 0.4044\n",
      "Epoch 46/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1793 - acc: 0.9387 - val_loss: 2.7952 - val_acc: 0.3948\n",
      "Epoch 47/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1741 - acc: 0.9410 - val_loss: 2.6380 - val_acc: 0.4106\n",
      "Epoch 48/100\n",
      "16250/16250 [==============================] - 4s - loss: 0.1706 - acc: 0.9424 - val_loss: 2.6545 - val_acc: 0.4192\n",
      "Epoch 49/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1853 - acc: 0.9380 - val_loss: 2.5887 - val_acc: 0.4145\n",
      "Epoch 50/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1657 - acc: 0.9435 - val_loss: 2.5365 - val_acc: 0.4240\n",
      "Epoch 51/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1622 - acc: 0.9433 - val_loss: 2.5663 - val_acc: 0.4187\n",
      "Epoch 52/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1683 - acc: 0.9433 - val_loss: 2.7712 - val_acc: 0.4025\n",
      "Epoch 53/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1623 - acc: 0.9447 - val_loss: 2.7852 - val_acc: 0.4093\n",
      "Epoch 54/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1740 - acc: 0.9440 - val_loss: 2.8493 - val_acc: 0.4140\n",
      "Epoch 55/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1707 - acc: 0.9418 - val_loss: 2.9451 - val_acc: 0.3929\n",
      "Epoch 56/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1551 - acc: 0.9480 - val_loss: 2.8963 - val_acc: 0.4095\n",
      "Epoch 57/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1635 - acc: 0.9439 - val_loss: 2.9244 - val_acc: 0.4123\n",
      "Epoch 58/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1586 - acc: 0.9446 - val_loss: 2.6752 - val_acc: 0.4295\n",
      "Epoch 59/100\n",
      " 4672/16250 [=======>......................] - ETA: 3s - loss: 0.1509 - acc: 0.9471"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-54051dfb4dd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# nb_epoch,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_categ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    840\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_bak = model\n",
    "\n",
    "model = reset_model_2()\n",
    "\n",
    "# TODO: remove (X_test_reshaped, Y_test_categ),\n",
    "\n",
    "model.fit(X_train_label, Y_train_label,\n",
    "    batch_size=batch_size,\n",
    "    nb_epoch=100,  # nb_epoch,\n",
    "    validation_data=(X_test_reshaped, Y_test_categ),\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_train_label_class_predict = model.predict_classes(X_train_ori_label, batch_size=5000)\n",
    "val_acc = np.sum(Y_train_label_class_predict == y_train_label_class) / float(len(y_train_label_class))\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = (METHOD\n",
    "    + '_filters-64w3-64w3-512'\n",
    "    + '_add-0.25'\n",
    "    + '_epo-100x2-60' # + str(nb_epoch)\n",
    "    + '_0.4295' # + str(val_acc)[:6]\n",
    ")\n",
    "model.save(MODEL_FOLDER + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = pickle.load(open(TEST_DATA_FILE, 'rb'))  # dict\n",
    "X_test = np.array(test_data['data']).reshape((10000, 3, 32, 32)).astype('float32')\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s\n"
     ]
    }
   ],
   "source": [
    "result = model.predict_classes(X_test, batch_size=10000)\n",
    "csv_content = list(zip(test_data['ID'], result.tolist()))\n",
    "np.savetxt(OUTPUT_FOLDER + model_name + \".csv\", csv_content, fmt=\"%i\", header=\"ID,class\", comments=\"\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_reshaped = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_train])\n",
    "X_test_reshaped = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25609999999999999"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_class_predict = model.predict_classes(X_test_reshaped, batch_size=10000)\n",
    "np.sum(Y_test_class_predict == y_test.flatten()) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24102000000000001"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_class_predict = model.predict_classes(X_train_reshaped, batch_size=10000)\n",
    "np.sum(Y_train_class_predict == y_train.flatten()) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toimage(X_train_reshaped[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train_class_predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toimage(X_train_reshaped[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
