{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELLED_DATA_FILE = 'data/all_label.p'\n",
    "UNLABELED_DATA_FILE = 'data/all_unlabel.p'\n",
    "TEST_DATA_FILE = 'data/test.p'\n",
    "\n",
    "METHOD = 'cnn_supervised_ycbcr'\n",
    "\n",
    "OUTPUT_FOLDER = 'output/'\n",
    "MODEL_FOLDER = 'model/' + METHOD + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(MODEL_FOLDER):\n",
    "    os.makedirs(MODEL_FOLDER)\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelled_data = np.array(pickle.load(open(LABELLED_DATA_FILE, 'rb')))\n",
    "# unlabeled_data = np.array(pickle.load(open(UNLABELED_DATA_FILE, 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def img_rgb_to_ycbcr(img):\n",
    "    # img.shape should be (3, rows, cols)\n",
    "    r, g, b = img[0], img[1], img[2]\n",
    "    return np.array([0.299*r + 0.587*g + 0.114*b, -0.168736*r -0.331264*g +0.5*b, 0.5*r -0.418688*g -0.081312*b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate x, y from data\n",
    "X_train_label = labelled_data.reshape((5000, 3, 32, 32)).astype('float32') / 255\n",
    "X_train_label = np.apply_along_axis(img_rgb_to_ycbcr, 1, X_train_label)\n",
    "\n",
    "y_train_label_class = np.array([classIdx for classIdx in range(len(labelled_data)) for i in range(len(labelled_data[classIdx]))])\n",
    "Y_train_label = np_utils.to_categorical(y_train_label_class, len(labelled_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3, 32, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADG0lEQVR4nAXBS29bVRQG0G/vs++5\nDzu2k5SktISkRRGgMgDKADoB8ff4F8yZISEkBpRJeUUNRYWaR5XICXk4aew49vW955y9WYu+SAkK\nWBMby4q4NBWq0SsyD1O2KDEmVYBSmxjgmNR4KVw6n7yft162YlKArWlD5ot4k9TrnPNcMidEbZL7\naslACE1gl9tCUx4XEhqX43KxmQcpE6IpyFSNIaWZJGIRL9P900fbFZslaholXB+NLZo4qJGVzsvB\n05fLvGR2WUUodfzHL6cdn3nJGL7wVLT7R3mv9OIVVEp39HgvraBykS0YKwbF7ycoqhLiE1JXymx4\nUF1RBUZkMWoGy2dj9p0qiTi0rPXsxlwsS8tiliIZ5f+8mKPsd4MUSUHXx7/Wua4MfJsLgij7sH9K\nJr2SxREonj35bhpikZtmUEfQ4vjpZLX1Flpxjuz6v+FZApZnq9mchFhRPz+Yd6rpt60IITWBKyMy\nHayoj9o28+Xls7ARxmFmd4Xi9PHBi79CSlG29MI1k8uzy4uLYdubh+Vk7ZawvvpqOAs5LC3nV8PF\n+fjwfDK16QIycNh4VzjY9nWnuTG48dcnL0+nzey6bnq+39m9jbDzsSDq64eX0Rmy4y/HvDBuUmdQ\nrN5758E6L/yH0pn+/dPwnLtxouVV8vVali+rt3Y2du9lyGNGcnP44yiyFZgtU1O2gZrauutvrxVT\n8sG5I/n5m73gK9XqdlPUr7Y/aQ/+tO7V99XWxpur6szktx/ORCW1EFkWq59+9vyqt/noahS56wxk\nJOoHkMzfvd0d7W1+9LA9m+58/nC0Ndi6ExVGKg/mo6Jfrr53x/+723///sR/UG7dWnkjL7MEJSM6\nPD/p9LvuppeoP+fuzWVZzmpGXS+qqvCZCPplQRriwoTKVNcuhayNmoyTBlGSJTJoMu/ZZpIlL0kh\nUUkMKTNSFiCZzzURwMpMBMCIAAJgEAUCYkpwBHPwUUI0wBQGQKMA4MWkWScjBhgcLRIATmSAGgNM\ni9FhAhMAFnYgMAgGBhQCqKteC5UjCBMZ2LGTxGAhShL/B4+M0LT2dOPCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32 at 0x7FF63FE65CF8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.misc import toimage\n",
    "toimage(X_train_label[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: remove\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# X_train_reshaped = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_train])\n",
    "X_test_reshaped = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_test])\n",
    "X_test_reshaped = np.apply_along_axis(img_rgb_to_ycbcr, 1, X_test_reshaped)\n",
    "Y_test_categ = np_utils.to_categorical(y_test.flatten(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "nb_epoch = 100\n",
    "img_rows, img_cols, img_channels = 32, 32, 3\n",
    "# nb_filters = [32, 64]\n",
    "# nb_nodes = [512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same', dim_ordering=\"th\", input_shape=X_train_label.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Convolution2D(64, 3, 3))\n",
    "# model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Convolution2D(64, 3, 3))\n",
    "# model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.9984 - acc: 0.2698 - val_loss: 13.9653 - val_acc: 0.1285\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.6627 - acc: 0.3918 - val_loss: 12.6694 - val_acc: 0.2068\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.4569 - acc: 0.4754 - val_loss: 12.2617 - val_acc: 0.2321\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.3500 - acc: 0.5062 - val_loss: 12.3923 - val_acc: 0.2258\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.2313 - acc: 0.5612 - val_loss: 12.9104 - val_acc: 0.1948\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.1310 - acc: 0.5960 - val_loss: 11.7427 - val_acc: 0.2651\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.0304 - acc: 0.6386 - val_loss: 12.0980 - val_acc: 0.2444\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.9299 - acc: 0.6714 - val_loss: 11.4856 - val_acc: 0.2825\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.8155 - acc: 0.7098 - val_loss: 11.8600 - val_acc: 0.2597\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.7434 - acc: 0.7456 - val_loss: 11.2296 - val_acc: 0.2978\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.6476 - acc: 0.7782 - val_loss: 11.8035 - val_acc: 0.2632\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.5390 - acc: 0.8086 - val_loss: 11.7351 - val_acc: 0.2688\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4703 - acc: 0.8384 - val_loss: 11.2934 - val_acc: 0.2947\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4184 - acc: 0.8608 - val_loss: 11.0880 - val_acc: 0.3080\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3608 - acc: 0.8736 - val_loss: 11.9803 - val_acc: 0.2536\n",
      "Epoch 16/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3018 - acc: 0.8982 - val_loss: 11.3503 - val_acc: 0.2914\n",
      "Epoch 17/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2559 - acc: 0.9100 - val_loss: 11.4251 - val_acc: 0.2887\n",
      "Epoch 18/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2338 - acc: 0.9208 - val_loss: 11.4273 - val_acc: 0.2890\n",
      "Epoch 19/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2128 - acc: 0.9292 - val_loss: 11.5929 - val_acc: 0.2785\n",
      "Epoch 20/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1790 - acc: 0.9424 - val_loss: 11.4283 - val_acc: 0.2877\n",
      "Epoch 21/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1657 - acc: 0.9472 - val_loss: 11.3066 - val_acc: 0.2959\n",
      "Epoch 22/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1513 - acc: 0.9500 - val_loss: 11.5803 - val_acc: 0.2789\n",
      "Epoch 23/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1507 - acc: 0.9510 - val_loss: 11.8959 - val_acc: 0.2601\n",
      "Epoch 24/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1224 - acc: 0.9632 - val_loss: 11.6057 - val_acc: 0.2778\n",
      "Epoch 25/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1223 - acc: 0.9606 - val_loss: 11.5792 - val_acc: 0.2785\n",
      "Epoch 26/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1056 - acc: 0.9654 - val_loss: 12.1241 - val_acc: 0.2461\n",
      "Epoch 27/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1010 - acc: 0.9688 - val_loss: 11.6059 - val_acc: 0.2775\n",
      "Epoch 28/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.0994 - acc: 0.9664 - val_loss: 12.0885 - val_acc: 0.2486\n",
      "Epoch 29/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1255 - acc: 0.9610 - val_loss: 11.6156 - val_acc: 0.2773\n",
      "Epoch 30/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.0953 - acc: 0.9710 - val_loss: 11.9350 - val_acc: 0.2579\n",
      "Epoch 31/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.0852 - acc: 0.9754 - val_loss: 11.9264 - val_acc: 0.2584\n",
      "Epoch 32/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.0741 - acc: 0.9756 - val_loss: 11.3940 - val_acc: 0.2911\n",
      "Epoch 33/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.0787 - acc: 0.9760 - val_loss: 11.5329 - val_acc: 0.2828\n",
      "Epoch 34/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.0703 - acc: 0.9774 - val_loss: 11.6597 - val_acc: 0.2751\n",
      "Epoch 35/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.0650 - acc: 0.9788 - val_loss: 11.5027 - val_acc: 0.2841\n",
      "Epoch 36/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.0783 - acc: 0.9736 - val_loss: 11.8887 - val_acc: 0.2608\n",
      "Epoch 37/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.0748 - acc: 0.9748 - val_loss: 12.1869 - val_acc: 0.2428\n",
      "Epoch 38/100\n",
      " 800/5000 [===>..........................] - ETA: 1s - loss: 0.0563 - acc: 0.9838"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-11c32e2d445e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_categ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#           validation_split=0.1,  # (X_train_label, Y_train_label),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           shuffle=True)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# TODO: remove (X_test_reshaped, Y_test_categ)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    840\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train_label, Y_train_label,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=nb_epoch,\n",
    "          validation_data=(X_test_reshaped, Y_test_categ),\n",
    "#           validation_split=0.1,  # (X_train_label, Y_train_label),\n",
    "          shuffle=True)\n",
    "\n",
    "# TODO: remove (X_test_reshaped, Y_test_categ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = (METHOD\n",
    "    + '_filter-32w3-64w3-512'\n",
    "    + '_epo-100' # + str(nb_epoch)\n",
    "    + '_test-0.507'\n",
    ")\n",
    "\n",
    "model.save(MODEL_FOLDER + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = pickle.load(open(TEST_DATA_FILE, 'rb'))  # dict\n",
    "X_test = np.array(test_data['data']).reshape((10000, 3, 32, 32)).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = model.predict_classes(X_test, batch_size=10000)\n",
    "csv_content = list(zip(test_data['ID'], result.tolist()))\n",
    "np.savetxt(OUTPUT_FOLDER + model_name + \".csv\", csv_content, fmt=\"%i\", header=\"ID,class\", comments=\"\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
