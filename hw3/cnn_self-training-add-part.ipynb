{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "METHOD = 'cnn_self-training-add-part'\n",
    "\n",
    "LABELLED_DATA_FILE = 'data/all_label.p'\n",
    "UNLABELED_DATA_FILE = 'data/all_unlabel.p'\n",
    "TEST_DATA_FILE = 'data/test.p'\n",
    "\n",
    "OUTPUT_FOLDER = 'output/'\n",
    "MODEL_FOLDER = 'model/' + METHOD + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(MODEL_FOLDER):\n",
    "    os.makedirs(MODEL_FOLDER)\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelled_data = np.array(pickle.load(open(LABELLED_DATA_FILE, 'rb')))\n",
    "unlabeled_data = np.array(pickle.load(open(UNLABELED_DATA_FILE, 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "img_rows, img_cols, img_channels = 32, 32, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate x, y from data\n",
    "\n",
    "# reshape labelled data to (5000, 3, 32, 32)\n",
    "X_train_label = labelled_data.reshape((5000, img_channels, img_rows, img_cols)).astype('float32') / 255\n",
    "\n",
    "# reshape unlabeled data to (45000, 3, 32, 32)\n",
    "nb_unlabeled_data = unlabeled_data.shape[0]\n",
    "X_train_unlabel = unlabeled_data.reshape((nb_unlabeled_data, img_channels, img_rows, img_cols)).astype('float32') / 255\n",
    "\n",
    "y_train_label_class = np.array([classIdx for classIdx in range(len(labelled_data)) for i in range(len(labelled_data[classIdx]))])\n",
    "Y_train_label = np_utils.to_categorical(y_train_label_class, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: remove\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train_reshaped = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_train]) / 255.0\n",
    "X_test_reshaped = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_test]) / 255.0\n",
    "Y_test_categ = np_utils.to_categorical(y_test.flatten(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJrElEQVR4nCXTW29cx2EA4LnPnDm3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\noyQO/gjApWe1WMMl7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F9B557A3CF8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize\n",
    "from scipy.misc import toimage\n",
    "toimage(X_train_unlabel[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "def certainty(prob_arr):  # higher is more certain\n",
    "    return -entropy(prob_arr)\n",
    "\n",
    "def uncertainty(prob_arr):  # lower is better. for descending-ordered sorting\n",
    "    return entropy(prob_arr)\n",
    "\n",
    "#     sorted_arr = np.sort(prob_arr)\n",
    "#     return sorted_arr[-1] / sorted_arr[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set model\n",
    "\n",
    "def reset_model():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\", input_shape=X_train_label.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(Convolution2D(32, 3, 3))\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same', dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(Convolution2D(64, 3, 3))\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same', dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# avoid change to the original labelled data\n",
    "X_train_ori_label = np.copy(X_train_label)\n",
    "Y_train_ori_label = np.copy(Y_train_label)\n",
    "X_train_ori_unlabel = np.copy(X_train_unlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extract_ratio = 0.25\n",
    "nb_extract_rounds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_round: 1\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 2s - loss: 2.1764 - acc: 0.1888 - val_loss: 2.4777 - val_acc: 0.1205\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.8691 - acc: 0.3232 - val_loss: 2.4799 - val_acc: 0.1592\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.7166 - acc: 0.3736 - val_loss: 2.3842 - val_acc: 0.1865\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.6226 - acc: 0.4118 - val_loss: 2.1325 - val_acc: 0.2428\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.5579 - acc: 0.4318 - val_loss: 2.3116 - val_acc: 0.2242\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.4582 - acc: 0.4786 - val_loss: 2.2056 - val_acc: 0.2430\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.3769 - acc: 0.5058 - val_loss: 2.1883 - val_acc: 0.2676\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.3313 - acc: 0.5290 - val_loss: 2.0745 - val_acc: 0.2823\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.2953 - acc: 0.5350 - val_loss: 2.1086 - val_acc: 0.2948\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.2417 - acc: 0.5570 - val_loss: 2.2428 - val_acc: 0.2753\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.1989 - acc: 0.5732 - val_loss: 2.1760 - val_acc: 0.2867\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.1572 - acc: 0.5866 - val_loss: 2.2268 - val_acc: 0.2825\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.0984 - acc: 0.6044 - val_loss: 2.1035 - val_acc: 0.3029\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.0727 - acc: 0.6132 - val_loss: 2.1875 - val_acc: 0.3007\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 2s - loss: 1.0385 - acc: 0.6318 - val_loss: 2.1801 - val_acc: 0.3126\n",
      "Epoch 16/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.9884 - acc: 0.6470 - val_loss: 2.0401 - val_acc: 0.3209\n",
      "Epoch 17/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.9425 - acc: 0.6632 - val_loss: 2.1556 - val_acc: 0.3116\n",
      "Epoch 18/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.9174 - acc: 0.6780 - val_loss: 2.1812 - val_acc: 0.3230\n",
      "Epoch 19/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.8856 - acc: 0.6834 - val_loss: 2.0246 - val_acc: 0.3450\n",
      "Epoch 20/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.8347 - acc: 0.7060 - val_loss: 2.1747 - val_acc: 0.3275\n",
      "Epoch 21/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.8310 - acc: 0.7056 - val_loss: 2.0447 - val_acc: 0.3518\n",
      "Epoch 22/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.8043 - acc: 0.7134 - val_loss: 2.1620 - val_acc: 0.3350\n",
      "Epoch 23/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.7418 - acc: 0.7374 - val_loss: 2.2362 - val_acc: 0.3339\n",
      "Epoch 24/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.7124 - acc: 0.7442 - val_loss: 2.2238 - val_acc: 0.3402\n",
      "Epoch 25/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.6949 - acc: 0.7486 - val_loss: 2.1330 - val_acc: 0.3508\n",
      "Epoch 26/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.6730 - acc: 0.7620 - val_loss: 2.1083 - val_acc: 0.3572\n",
      "Epoch 27/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.6352 - acc: 0.7740 - val_loss: 2.2336 - val_acc: 0.3508\n",
      "Epoch 28/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.6320 - acc: 0.7740 - val_loss: 2.1280 - val_acc: 0.3613\n",
      "Epoch 29/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.5906 - acc: 0.7906 - val_loss: 2.3406 - val_acc: 0.3500\n",
      "Epoch 30/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.5556 - acc: 0.8074 - val_loss: 2.4246 - val_acc: 0.3504\n",
      "Epoch 31/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.5772 - acc: 0.7982 - val_loss: 2.5492 - val_acc: 0.3347\n",
      "Epoch 32/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.5313 - acc: 0.8092 - val_loss: 2.3046 - val_acc: 0.3557\n",
      "Epoch 33/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.5116 - acc: 0.8208 - val_loss: 2.4251 - val_acc: 0.3510\n",
      "Epoch 34/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.5096 - acc: 0.8222 - val_loss: 2.3764 - val_acc: 0.3615\n",
      "Epoch 35/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4624 - acc: 0.8356 - val_loss: 2.9626 - val_acc: 0.3277\n",
      "Epoch 36/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4631 - acc: 0.8402 - val_loss: 2.7461 - val_acc: 0.3407\n",
      "Epoch 37/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4615 - acc: 0.8406 - val_loss: 2.5139 - val_acc: 0.3519\n",
      "Epoch 38/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4179 - acc: 0.8542 - val_loss: 2.6667 - val_acc: 0.3546\n",
      "Epoch 39/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4308 - acc: 0.8504 - val_loss: 2.5771 - val_acc: 0.3579\n",
      "Epoch 40/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4220 - acc: 0.8522 - val_loss: 2.8421 - val_acc: 0.3529\n",
      "Epoch 41/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4428 - acc: 0.8472 - val_loss: 2.7384 - val_acc: 0.3440\n",
      "Epoch 42/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.4004 - acc: 0.8598 - val_loss: 2.7874 - val_acc: 0.3369\n",
      "Epoch 43/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3659 - acc: 0.8706 - val_loss: 2.7900 - val_acc: 0.3458\n",
      "Epoch 44/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3848 - acc: 0.8626 - val_loss: 2.9174 - val_acc: 0.3409\n",
      "Epoch 45/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3561 - acc: 0.8760 - val_loss: 2.8483 - val_acc: 0.3449\n",
      "Epoch 46/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3574 - acc: 0.8770 - val_loss: 2.6746 - val_acc: 0.3576\n",
      "Epoch 47/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3506 - acc: 0.8822 - val_loss: 2.7815 - val_acc: 0.3514\n",
      "Epoch 48/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3264 - acc: 0.8878 - val_loss: 3.0326 - val_acc: 0.3399\n",
      "Epoch 49/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3549 - acc: 0.8758 - val_loss: 2.7046 - val_acc: 0.3631\n",
      "Epoch 50/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3305 - acc: 0.8846 - val_loss: 2.7855 - val_acc: 0.3617\n",
      "Epoch 51/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3442 - acc: 0.8794 - val_loss: 3.0957 - val_acc: 0.3314\n",
      "Epoch 52/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2883 - acc: 0.9002 - val_loss: 3.0018 - val_acc: 0.3475\n",
      "Epoch 53/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2955 - acc: 0.9026 - val_loss: 2.5367 - val_acc: 0.3823\n",
      "Epoch 54/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.3098 - acc: 0.8936 - val_loss: 2.8136 - val_acc: 0.3591\n",
      "Epoch 55/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2960 - acc: 0.8984 - val_loss: 2.7667 - val_acc: 0.3709\n",
      "Epoch 56/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2744 - acc: 0.9048 - val_loss: 2.8534 - val_acc: 0.3674\n",
      "Epoch 57/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2947 - acc: 0.8924 - val_loss: 2.9275 - val_acc: 0.3609\n",
      "Epoch 58/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2465 - acc: 0.9136 - val_loss: 2.9103 - val_acc: 0.3652\n",
      "Epoch 59/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2766 - acc: 0.9052 - val_loss: 3.0023 - val_acc: 0.3589\n",
      "Epoch 60/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2694 - acc: 0.9058 - val_loss: 3.0097 - val_acc: 0.3612\n",
      "Epoch 61/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2552 - acc: 0.9082 - val_loss: 3.0203 - val_acc: 0.3552\n",
      "Epoch 62/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2562 - acc: 0.9144 - val_loss: 3.0179 - val_acc: 0.3574\n",
      "Epoch 63/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2412 - acc: 0.9170 - val_loss: 3.0659 - val_acc: 0.3585\n",
      "Epoch 64/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2640 - acc: 0.9106 - val_loss: 3.0914 - val_acc: 0.3572\n",
      "Epoch 65/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2416 - acc: 0.9194 - val_loss: 3.0186 - val_acc: 0.3587\n",
      "Epoch 66/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2396 - acc: 0.9134 - val_loss: 3.0972 - val_acc: 0.3623\n",
      "Epoch 67/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2189 - acc: 0.9210 - val_loss: 3.0240 - val_acc: 0.3642\n",
      "Epoch 68/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2359 - acc: 0.9200 - val_loss: 3.2944 - val_acc: 0.3464\n",
      "Epoch 69/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2360 - acc: 0.9194 - val_loss: 3.1162 - val_acc: 0.3578\n",
      "Epoch 70/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2342 - acc: 0.9208 - val_loss: 3.0467 - val_acc: 0.3652\n",
      "Epoch 71/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2185 - acc: 0.9240 - val_loss: 3.2444 - val_acc: 0.3583\n",
      "Epoch 72/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2262 - acc: 0.9214 - val_loss: 3.0996 - val_acc: 0.3627\n",
      "Epoch 73/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1980 - acc: 0.9340 - val_loss: 3.0780 - val_acc: 0.3688\n",
      "Epoch 74/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2126 - acc: 0.9274 - val_loss: 2.9727 - val_acc: 0.3732\n",
      "Epoch 75/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2154 - acc: 0.9262 - val_loss: 2.9645 - val_acc: 0.3755\n",
      "Epoch 76/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2067 - acc: 0.9284 - val_loss: 2.9141 - val_acc: 0.3817\n",
      "Epoch 77/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2174 - acc: 0.9266 - val_loss: 2.9383 - val_acc: 0.3765\n",
      "Epoch 78/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1924 - acc: 0.9372 - val_loss: 3.3488 - val_acc: 0.3569\n",
      "Epoch 79/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1994 - acc: 0.9310 - val_loss: 3.2040 - val_acc: 0.3675\n",
      "Epoch 80/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2073 - acc: 0.9258 - val_loss: 3.1801 - val_acc: 0.3694\n",
      "Epoch 81/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1974 - acc: 0.9356 - val_loss: 3.0839 - val_acc: 0.3742\n",
      "Epoch 82/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2102 - acc: 0.9242 - val_loss: 3.0946 - val_acc: 0.3673\n",
      "Epoch 83/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2104 - acc: 0.9284 - val_loss: 3.1324 - val_acc: 0.3709\n",
      "Epoch 84/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1830 - acc: 0.9358 - val_loss: 3.2888 - val_acc: 0.3631\n",
      "Epoch 85/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1929 - acc: 0.9344 - val_loss: 3.1744 - val_acc: 0.3692\n",
      "Epoch 86/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2121 - acc: 0.9300 - val_loss: 3.1668 - val_acc: 0.3677\n",
      "Epoch 87/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1872 - acc: 0.9342 - val_loss: 2.9921 - val_acc: 0.3814\n",
      "Epoch 88/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1698 - acc: 0.9434 - val_loss: 3.4340 - val_acc: 0.3560\n",
      "Epoch 89/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1864 - acc: 0.9344 - val_loss: 3.2264 - val_acc: 0.3640\n",
      "Epoch 90/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1797 - acc: 0.9362 - val_loss: 3.4823 - val_acc: 0.3530\n",
      "Epoch 91/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1767 - acc: 0.9398 - val_loss: 3.5051 - val_acc: 0.3620\n",
      "Epoch 92/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1627 - acc: 0.9446 - val_loss: 3.5541 - val_acc: 0.3594\n",
      "Epoch 93/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1901 - acc: 0.9342 - val_loss: 3.1129 - val_acc: 0.3815\n",
      "Epoch 94/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1908 - acc: 0.9344 - val_loss: 3.2196 - val_acc: 0.3677\n",
      "Epoch 95/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1653 - acc: 0.9452 - val_loss: 3.1910 - val_acc: 0.3785\n",
      "Epoch 96/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1642 - acc: 0.9476 - val_loss: 3.5028 - val_acc: 0.3692\n",
      "Epoch 97/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.2141 - acc: 0.9306 - val_loss: 3.2757 - val_acc: 0.3708\n",
      "Epoch 98/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1666 - acc: 0.9448 - val_loss: 3.1697 - val_acc: 0.3774\n",
      "Epoch 99/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1809 - acc: 0.9416 - val_loss: 3.2442 - val_acc: 0.3735\n",
      "Epoch 100/100\n",
      "5000/5000 [==============================] - 2s - loss: 0.1922 - acc: 0.9338 - val_loss: 3.2215 - val_acc: 0.3685\n",
      "45000/45000 [==============================] - 6s     \n",
      "45000/45000 [==============================] - 5s     \n",
      "extract_round: 2\n",
      "Train on 16250 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "16250/16250 [==============================] - 5s - loss: 1.4832 - acc: 0.4945 - val_loss: 2.4726 - val_acc: 0.2457\n",
      "Epoch 2/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.8983 - acc: 0.7031 - val_loss: 2.3062 - val_acc: 0.2788\n",
      "Epoch 3/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.7272 - acc: 0.7638 - val_loss: 2.3511 - val_acc: 0.2966\n",
      "Epoch 4/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.6432 - acc: 0.7938 - val_loss: 2.0361 - val_acc: 0.3398\n",
      "Epoch 5/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.5877 - acc: 0.8107 - val_loss: 2.1626 - val_acc: 0.3229\n",
      "Epoch 6/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.5359 - acc: 0.8294 - val_loss: 2.0382 - val_acc: 0.3708\n",
      "Epoch 7/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.5040 - acc: 0.8357 - val_loss: 2.0897 - val_acc: 0.3550\n",
      "Epoch 8/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.4739 - acc: 0.8486 - val_loss: 2.0021 - val_acc: 0.3887\n",
      "Epoch 9/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.4482 - acc: 0.8557 - val_loss: 2.0124 - val_acc: 0.3757\n",
      "Epoch 10/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.4189 - acc: 0.8610 - val_loss: 2.1414 - val_acc: 0.3767\n",
      "Epoch 11/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.3954 - acc: 0.8678 - val_loss: 2.1280 - val_acc: 0.3852\n",
      "Epoch 12/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.3820 - acc: 0.8723 - val_loss: 2.0626 - val_acc: 0.3940\n",
      "Epoch 13/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.3616 - acc: 0.8776 - val_loss: 1.9852 - val_acc: 0.4027\n",
      "Epoch 14/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.3513 - acc: 0.8823 - val_loss: 2.0873 - val_acc: 0.3975\n",
      "Epoch 15/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.3396 - acc: 0.8864 - val_loss: 2.2117 - val_acc: 0.3962\n",
      "Epoch 16/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.3134 - acc: 0.8944 - val_loss: 2.1323 - val_acc: 0.4032\n",
      "Epoch 17/30\n",
      "16250/16250 [==============================] - 4s - loss: 0.3127 - acc: 0.8954 - val_loss: 2.1767 - val_acc: 0.4000\n",
      "Epoch 18/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.2940 - acc: 0.9003 - val_loss: 2.5755 - val_acc: 0.3785\n",
      "Epoch 19/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.2848 - acc: 0.9041 - val_loss: 2.2844 - val_acc: 0.3918\n",
      "Epoch 20/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.2817 - acc: 0.9063 - val_loss: 2.3378 - val_acc: 0.3923\n",
      "Epoch 21/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.2722 - acc: 0.9080 - val_loss: 2.4201 - val_acc: 0.3897\n",
      "Epoch 22/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.2646 - acc: 0.9087 - val_loss: 2.3125 - val_acc: 0.4045\n",
      "Epoch 23/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.2580 - acc: 0.9116 - val_loss: 2.2823 - val_acc: 0.4090\n",
      "Epoch 24/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.2402 - acc: 0.9204 - val_loss: 2.5409 - val_acc: 0.3905\n",
      "Epoch 25/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.2373 - acc: 0.9191 - val_loss: 2.4291 - val_acc: 0.3832\n",
      "Epoch 26/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.2335 - acc: 0.9211 - val_loss: 2.4365 - val_acc: 0.3929\n",
      "Epoch 27/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.2180 - acc: 0.9266 - val_loss: 2.8697 - val_acc: 0.3754\n",
      "Epoch 28/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.2154 - acc: 0.9259 - val_loss: 2.5069 - val_acc: 0.4035\n",
      "Epoch 29/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.2233 - acc: 0.9262 - val_loss: 2.5212 - val_acc: 0.4003\n",
      "Epoch 30/30\n",
      "16250/16250 [==============================] - 5s - loss: 0.2260 - acc: 0.9249 - val_loss: 2.4793 - val_acc: 0.3883\n",
      "33750/33750 [==============================] - 4s     \n",
      "33750/33750 [==============================] - 4s     \n",
      "extract_round: 3\n",
      "Train on 24687 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "24687/24687 [==============================] - 7s - loss: 1.3278 - acc: 0.5464 - val_loss: 2.4012 - val_acc: 0.2534\n",
      "Epoch 2/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.7801 - acc: 0.7423 - val_loss: 2.2576 - val_acc: 0.2890\n",
      "Epoch 3/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.6490 - acc: 0.7898 - val_loss: 2.2206 - val_acc: 0.3152\n",
      "Epoch 4/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.5725 - acc: 0.8182 - val_loss: 2.1290 - val_acc: 0.3475\n",
      "Epoch 5/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.5163 - acc: 0.8336 - val_loss: 1.9913 - val_acc: 0.3575\n",
      "Epoch 6/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.4776 - acc: 0.8453 - val_loss: 2.1470 - val_acc: 0.3555\n",
      "Epoch 7/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.4460 - acc: 0.8571 - val_loss: 2.2297 - val_acc: 0.3555\n",
      "Epoch 8/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.4170 - acc: 0.8668 - val_loss: 2.0674 - val_acc: 0.3889\n",
      "Epoch 9/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.4006 - acc: 0.8715 - val_loss: 2.1151 - val_acc: 0.3763\n",
      "Epoch 10/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.3812 - acc: 0.8785 - val_loss: 2.1152 - val_acc: 0.3828\n",
      "Epoch 11/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.3669 - acc: 0.8792 - val_loss: 2.0733 - val_acc: 0.3914\n",
      "Epoch 12/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.3519 - acc: 0.8848 - val_loss: 2.3574 - val_acc: 0.3696\n",
      "Epoch 13/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.3400 - acc: 0.8903 - val_loss: 2.2932 - val_acc: 0.3753\n",
      "Epoch 14/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.3267 - acc: 0.8946 - val_loss: 2.2002 - val_acc: 0.4106\n",
      "Epoch 15/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.3179 - acc: 0.8969 - val_loss: 2.3513 - val_acc: 0.3811\n",
      "Epoch 16/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.3070 - acc: 0.8995 - val_loss: 2.3221 - val_acc: 0.4026\n",
      "Epoch 17/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.2917 - acc: 0.9041 - val_loss: 2.3005 - val_acc: 0.3863\n",
      "Epoch 18/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.2869 - acc: 0.9044 - val_loss: 2.3074 - val_acc: 0.4031\n",
      "Epoch 19/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.2945 - acc: 0.9037 - val_loss: 2.2633 - val_acc: 0.4068\n",
      "Epoch 20/20\n",
      "24687/24687 [==============================] - 7s - loss: 0.2719 - acc: 0.9096 - val_loss: 2.1678 - val_acc: 0.4192\n",
      "25313/25313 [==============================] - 3s     \n",
      "25313/25313 [==============================] - 2s     \n"
     ]
    }
   ],
   "source": [
    "# extract high-certainty labelled-unlabeled data and add to labelled dataset\n",
    "\n",
    "# TODO: remove (X_test_reshaped, Y_test_categ),\n",
    "\n",
    "for extract_round in range(nb_extract_rounds):\n",
    "    nb_epoch = int(500000 / X_train_label.shape[0])\n",
    "    \n",
    "    print('extract_round:', extract_round+1)\n",
    "    # reset model\n",
    "    model = reset_model()\n",
    "    \n",
    "    # train model\n",
    "    model.fit(X_train_label, Y_train_label,\n",
    "        batch_size=batch_size,\n",
    "        nb_epoch=nb_epoch,  # nb_epoch,\n",
    "        validation_data=(X_test_reshaped, Y_test_categ),\n",
    "        shuffle=True)\n",
    "    \n",
    "    # save model\n",
    "\n",
    "    # use the model to label unlabeled data\n",
    "    Y_train_unlabel_proba = model.predict_proba(X_train_unlabel, batch_size=10000)  # same as model.predict\n",
    "    Y_train_unlabel_uncertainty = np.apply_along_axis(uncertainty, 1, Y_train_unlabel_proba)\n",
    "    \n",
    "    Y_train_unlabel_class = model.predict_classes(X_train_unlabel, batch_size=10000)\n",
    "    Y_train_unlabel = np_utils.to_categorical(Y_train_unlabel_class, nb_classes)\n",
    "\n",
    "    # sort unlabeled data by uncertainty\n",
    "    sorted_idxs = Y_train_unlabel_uncertainty.argsort()\n",
    "    X_train_unlabel = X_train_unlabel[sorted_idxs]\n",
    "    Y_train_unlabel = Y_train_unlabel[sorted_idxs]\n",
    "    \n",
    "    # extract high-certainty unlabeled data\n",
    "    nb_extract = int(X_train_unlabel.shape[0] * extract_ratio)\n",
    "    X_train_unlabel_certain, X_train_unlabel_uncertain = X_train_unlabel[:nb_extract], X_train_unlabel[nb_extract:]\n",
    "    Y_train_unlabel_certain, Y_train_unlabel_uncertain = Y_train_unlabel[:nb_extract], Y_train_unlabel[nb_extract:]\n",
    "\n",
    "    # update labelled dataset and unlabeled dataset\n",
    "    X_train_label = np.concatenate((X_train_label, X_train_unlabel_certain))\n",
    "    Y_train_label = np.concatenate((Y_train_label, Y_train_unlabel_certain))\n",
    "    X_train_unlabel = X_train_unlabel_uncertain\n",
    "    Y_train_unlabel = Y_train_unlabel_uncertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set model\n",
    "\n",
    "def reset_model_2():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\", input_shape=X_train_label.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(Convolution2D(64, 3, 3))\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same', dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(Convolution2D(64, 3, 3))\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same', dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16250 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "16250/16250 [==============================] - 5s - loss: 1.4473 - acc: 0.5078 - val_loss: 2.5511 - val_acc: 0.1915\n",
      "Epoch 2/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.9391 - acc: 0.6902 - val_loss: 2.2550 - val_acc: 0.2689\n",
      "Epoch 3/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.7727 - acc: 0.7449 - val_loss: 2.1235 - val_acc: 0.3000\n",
      "Epoch 4/100\n",
      "16250/16250 [==============================] - 4s - loss: 0.6811 - acc: 0.7770 - val_loss: 2.3524 - val_acc: 0.2834\n",
      "Epoch 5/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.6295 - acc: 0.7956 - val_loss: 2.0804 - val_acc: 0.3232\n",
      "Epoch 6/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.5739 - acc: 0.8124 - val_loss: 2.0535 - val_acc: 0.3360\n",
      "Epoch 7/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.5570 - acc: 0.8224 - val_loss: 1.9920 - val_acc: 0.3517\n",
      "Epoch 8/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.5074 - acc: 0.8343 - val_loss: 2.1426 - val_acc: 0.3430\n",
      "Epoch 9/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.4776 - acc: 0.8447 - val_loss: 2.0036 - val_acc: 0.3751\n",
      "Epoch 10/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.4569 - acc: 0.8486 - val_loss: 1.9798 - val_acc: 0.3808\n",
      "Epoch 11/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.4399 - acc: 0.8552 - val_loss: 2.0158 - val_acc: 0.3717\n",
      "Epoch 12/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.4163 - acc: 0.8604 - val_loss: 2.0027 - val_acc: 0.3837\n",
      "Epoch 13/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3973 - acc: 0.8696 - val_loss: 1.9910 - val_acc: 0.3936\n",
      "Epoch 14/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3839 - acc: 0.8710 - val_loss: 1.9940 - val_acc: 0.3963\n",
      "Epoch 15/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3731 - acc: 0.8767 - val_loss: 2.1148 - val_acc: 0.3841\n",
      "Epoch 16/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3555 - acc: 0.8823 - val_loss: 2.0404 - val_acc: 0.3944\n",
      "Epoch 17/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3502 - acc: 0.8828 - val_loss: 2.0810 - val_acc: 0.3982\n",
      "Epoch 18/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3334 - acc: 0.8873 - val_loss: 2.1306 - val_acc: 0.3935\n",
      "Epoch 19/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3233 - acc: 0.8927 - val_loss: 2.1666 - val_acc: 0.3848\n",
      "Epoch 20/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3078 - acc: 0.8964 - val_loss: 2.1070 - val_acc: 0.4006\n",
      "Epoch 21/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.3057 - acc: 0.8981 - val_loss: 2.1558 - val_acc: 0.4151\n",
      "Epoch 22/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2911 - acc: 0.9012 - val_loss: 2.4540 - val_acc: 0.3560\n",
      "Epoch 23/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2847 - acc: 0.9051 - val_loss: 2.2028 - val_acc: 0.3997\n",
      "Epoch 24/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2677 - acc: 0.9074 - val_loss: 2.1635 - val_acc: 0.4188\n",
      "Epoch 25/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2730 - acc: 0.9070 - val_loss: 2.3124 - val_acc: 0.3922\n",
      "Epoch 26/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2575 - acc: 0.9110 - val_loss: 2.2439 - val_acc: 0.3978\n",
      "Epoch 27/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2592 - acc: 0.9121 - val_loss: 2.2879 - val_acc: 0.3986\n",
      "Epoch 28/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2490 - acc: 0.9165 - val_loss: 2.2796 - val_acc: 0.3960\n",
      "Epoch 29/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2346 - acc: 0.9190 - val_loss: 2.4169 - val_acc: 0.3956\n",
      "Epoch 30/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2430 - acc: 0.9166 - val_loss: 2.3274 - val_acc: 0.4045\n",
      "Epoch 31/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2225 - acc: 0.9231 - val_loss: 2.4131 - val_acc: 0.3935\n",
      "Epoch 32/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2220 - acc: 0.9230 - val_loss: 2.4183 - val_acc: 0.4083\n",
      "Epoch 33/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2268 - acc: 0.9226 - val_loss: 2.2738 - val_acc: 0.4294\n",
      "Epoch 34/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2207 - acc: 0.9247 - val_loss: 2.3509 - val_acc: 0.4132\n",
      "Epoch 35/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2223 - acc: 0.9254 - val_loss: 2.4544 - val_acc: 0.3938\n",
      "Epoch 36/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2233 - acc: 0.9280 - val_loss: 2.3607 - val_acc: 0.4104\n",
      "Epoch 37/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2097 - acc: 0.9299 - val_loss: 2.4233 - val_acc: 0.4024\n",
      "Epoch 38/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2033 - acc: 0.9321 - val_loss: 2.4290 - val_acc: 0.4217\n",
      "Epoch 39/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.2165 - acc: 0.9273 - val_loss: 2.5076 - val_acc: 0.3988\n",
      "Epoch 40/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1943 - acc: 0.9314 - val_loss: 2.4187 - val_acc: 0.4133\n",
      "Epoch 41/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1936 - acc: 0.9329 - val_loss: 2.5569 - val_acc: 0.4037\n",
      "Epoch 42/100\n",
      "16250/16250 [==============================] - 4s - loss: 0.1963 - acc: 0.9343 - val_loss: 2.4930 - val_acc: 0.4110\n",
      "Epoch 43/100\n",
      "16250/16250 [==============================] - 4s - loss: 0.1931 - acc: 0.9352 - val_loss: 2.6855 - val_acc: 0.3945\n",
      "Epoch 44/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1830 - acc: 0.9375 - val_loss: 2.6187 - val_acc: 0.4096\n",
      "Epoch 45/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1888 - acc: 0.9361 - val_loss: 2.6977 - val_acc: 0.4044\n",
      "Epoch 46/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1793 - acc: 0.9387 - val_loss: 2.7952 - val_acc: 0.3948\n",
      "Epoch 47/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1741 - acc: 0.9410 - val_loss: 2.6380 - val_acc: 0.4106\n",
      "Epoch 48/100\n",
      "16250/16250 [==============================] - 4s - loss: 0.1706 - acc: 0.9424 - val_loss: 2.6545 - val_acc: 0.4192\n",
      "Epoch 49/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1853 - acc: 0.9380 - val_loss: 2.5887 - val_acc: 0.4145\n",
      "Epoch 50/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1657 - acc: 0.9435 - val_loss: 2.5365 - val_acc: 0.4240\n",
      "Epoch 51/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1622 - acc: 0.9433 - val_loss: 2.5663 - val_acc: 0.4187\n",
      "Epoch 52/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1683 - acc: 0.9433 - val_loss: 2.7712 - val_acc: 0.4025\n",
      "Epoch 53/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1623 - acc: 0.9447 - val_loss: 2.7852 - val_acc: 0.4093\n",
      "Epoch 54/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1740 - acc: 0.9440 - val_loss: 2.8493 - val_acc: 0.4140\n",
      "Epoch 55/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1707 - acc: 0.9418 - val_loss: 2.9451 - val_acc: 0.3929\n",
      "Epoch 56/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1551 - acc: 0.9480 - val_loss: 2.8963 - val_acc: 0.4095\n",
      "Epoch 57/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1635 - acc: 0.9439 - val_loss: 2.9244 - val_acc: 0.4123\n",
      "Epoch 58/100\n",
      "16250/16250 [==============================] - 5s - loss: 0.1586 - acc: 0.9446 - val_loss: 2.6752 - val_acc: 0.4295\n",
      "Epoch 59/100\n",
      " 4672/16250 [=======>......................] - ETA: 3s - loss: 0.1509 - acc: 0.9471"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-54051dfb4dd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# nb_epoch,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_categ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    840\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_bak = model\n",
    "\n",
    "model = reset_model_2()\n",
    "\n",
    "# TODO: remove (X_test_reshaped, Y_test_categ),\n",
    "\n",
    "model.fit(X_train_label, Y_train_label,\n",
    "    batch_size=batch_size,\n",
    "    nb_epoch=100,  # nb_epoch,\n",
    "    validation_data=(X_test_reshaped, Y_test_categ),\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_train_label_class_predict = model.predict_classes(X_train_ori_label, batch_size=5000)\n",
    "val_acc = np.sum(Y_train_label_class_predict == y_train_label_class) / float(len(y_train_label_class))\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = (METHOD\n",
    "    + '_filters-64w3-64w3-512'\n",
    "    + '_add-0.25'\n",
    "    + '_epo-100x3' # + str(nb_epoch)\n",
    "    + '_0.4192' # + str(val_acc)[:6]\n",
    ")\n",
    "model.save(MODEL_FOLDER + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = pickle.load(open(TEST_DATA_FILE, 'rb'))  # dict\n",
    "X_test = np.array(test_data['data']).reshape((10000, 3, 32, 32)).astype('float32')\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s\n"
     ]
    }
   ],
   "source": [
    "result = model.predict_classes(X_test, batch_size=10000)\n",
    "csv_content = list(zip(test_data['ID'], result.tolist()))\n",
    "np.savetxt(OUTPUT_FOLDER + model_name + \".csv\", csv_content, fmt=\"%i\", header=\"ID,class\", comments=\"\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_reshaped = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_train])\n",
    "X_test_reshaped = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41920000000000002"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_class_predict = model.predict_classes(X_test_reshaped, batch_size=10000)\n",
    "np.sum(Y_test_class_predict == y_test.flatten()) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24102000000000001"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_class_predict = model.predict_classes(X_train_reshaped, batch_size=10000)\n",
    "np.sum(Y_train_class_predict == y_train.flatten()) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toimage(X_train_reshaped[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train_class_predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toimage(X_train_reshaped[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
