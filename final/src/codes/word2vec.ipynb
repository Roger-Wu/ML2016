{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import brown\n",
    "from gensim.models import word2vec\n",
    "import time\n",
    "from gensim.models import phrases\n",
    "\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "nltk_stopwords = set(stopwords.words(\"english\"))\n",
    "# frequency_list = FreqDist(i.lower() for i in brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "MODEL_FOLDER = 'model/'\n",
    "OUTPUT_FOLDER = 'output/'\n",
    "TRAIN_FILES = ['biology.csv', 'cooking.csv', 'crypto.csv', 'diy.csv', 'robotics.csv', 'travel.csv']\n",
    "TEST_FILE = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOMAIN_COUNT = len(TRAIN_FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_trains = [pd.read_csv(DATA_FOLDER + filename) for filename in TRAIN_FILES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13196, 4)\n",
      "(15404, 4)\n",
      "(10432, 4)\n",
      "(25918, 4)\n",
      "(2771, 4)\n",
      "(19279, 4)\n"
     ]
    }
   ],
   "source": [
    "for df in df_trains:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([df.shape[0] for df in df_trains])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the criticality of the ribosome bindin...</td>\n",
       "      <td>&lt;p&gt;In prokaryotic translation, how critical fo...</td>\n",
       "      <td>ribosome binding-sites translation synthetic-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>How is RNAse contamination in RNA based experi...</td>\n",
       "      <td>&lt;p&gt;Does anyone have any suggestions to prevent...</td>\n",
       "      <td>rna biochemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Are lymphocyte sizes clustered in two groups?</td>\n",
       "      <td>&lt;p&gt;Tortora writes in &lt;em&gt;Principles of Anatomy...</td>\n",
       "      <td>immunology cell-biology hematology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>How long does antibiotic-dosed LB maintain goo...</td>\n",
       "      <td>&lt;p&gt;Various people in our lab will prepare a li...</td>\n",
       "      <td>cell-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Is exon order always preserved in splicing?</td>\n",
       "      <td>&lt;p&gt;Are there any cases in which the splicing m...</td>\n",
       "      <td>splicing mrna spliceosome introns exons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>How can I avoid digesting protein-bound DNA?</td>\n",
       "      <td>&lt;p&gt;I'm interested in sequencing and analyzing ...</td>\n",
       "      <td>dna biochemistry molecular-biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Under what conditions do dendritic spines form?</td>\n",
       "      <td>&lt;p&gt;I'm looking for resources or any informatio...</td>\n",
       "      <td>neuroscience synapses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>How should I ship plasmids?</td>\n",
       "      <td>&lt;p&gt;I shipped 10 µL of my vector miniprep to a ...</td>\n",
       "      <td>plasmids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>What is the reason behind choosing the reporte...</td>\n",
       "      <td>&lt;p&gt;I noticed within example experiments in cla...</td>\n",
       "      <td>molecular-genetics gene-expression experimenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>How many times did endosymbiosis occur?</td>\n",
       "      <td>&lt;p&gt;According to the endosymbiont theory, mitoc...</td>\n",
       "      <td>evolution mitochondria chloroplasts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  What is the criticality of the ribosome bindin...   \n",
       "1   2  How is RNAse contamination in RNA based experi...   \n",
       "2   3      Are lymphocyte sizes clustered in two groups?   \n",
       "3   4  How long does antibiotic-dosed LB maintain goo...   \n",
       "4   5        Is exon order always preserved in splicing?   \n",
       "5   6       How can I avoid digesting protein-bound DNA?   \n",
       "6   8    Under what conditions do dendritic spines form?   \n",
       "7   9                        How should I ship plasmids?   \n",
       "8  10  What is the reason behind choosing the reporte...   \n",
       "9  11            How many times did endosymbiosis occur?   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>In prokaryotic translation, how critical fo...   \n",
       "1  <p>Does anyone have any suggestions to prevent...   \n",
       "2  <p>Tortora writes in <em>Principles of Anatomy...   \n",
       "3  <p>Various people in our lab will prepare a li...   \n",
       "4  <p>Are there any cases in which the splicing m...   \n",
       "5  <p>I'm interested in sequencing and analyzing ...   \n",
       "6  <p>I'm looking for resources or any informatio...   \n",
       "7  <p>I shipped 10 µL of my vector miniprep to a ...   \n",
       "8  <p>I noticed within example experiments in cla...   \n",
       "9  <p>According to the endosymbiont theory, mitoc...   \n",
       "\n",
       "                                                tags  \n",
       "0  ribosome binding-sites translation synthetic-b...  \n",
       "1                                   rna biochemistry  \n",
       "2                 immunology cell-biology hematology  \n",
       "3                                       cell-culture  \n",
       "4            splicing mrna spliceosome introns exons  \n",
       "5                 dna biochemistry molecular-biology  \n",
       "6                              neuroscience synapses  \n",
       "7                                           plasmids  \n",
       "8  molecular-genetics gene-expression experimenta...  \n",
       "9                evolution mitochondria chloroplasts  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trains[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ribosome binding-sites translation synthetic-biology',\n",
       " 'rna biochemistry',\n",
       " 'immunology cell-biology hematology',\n",
       " 'cell-culture',\n",
       " 'splicing mrna spliceosome introns exons',\n",
       " 'dna biochemistry molecular-biology',\n",
       " 'neuroscience synapses',\n",
       " 'plasmids',\n",
       " 'molecular-genetics gene-expression experimental-design',\n",
       " 'evolution mitochondria chloroplasts',\n",
       " 'high-throughput cell-based',\n",
       " 'molecular-biology synthetic-biology',\n",
       " 'bioinformatics homework',\n",
       " 'neuroscience immunology',\n",
       " 'splicing histone',\n",
       " 'genomics gene-annotation exons',\n",
       " 'microbiology virology influenza',\n",
       " 'epigenetics',\n",
       " 'molecular-biology dna-isolation',\n",
       " 'cell-membrane adaptation cell-biology']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0_tags = df_trains[0]['tags'].tolist()\n",
    "train_0_tags[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678\n",
      "['reflexes', 'chloroplasts', 'operons', 'dnapolymerase', 'cytogenetics', 'cloning', 'inflammation', 'dna-replication', 'mutations', 'translation']\n"
     ]
    }
   ],
   "source": [
    "train_0_tag_set = set()\n",
    "for tags in train_0_tags:\n",
    "    for tag in tags.split():\n",
    "        train_0_tag_set.add(tag)\n",
    "print(len(train_0_tag_set))\n",
    "\n",
    "train_0_unique_tags = list(train_0_tag_set)\n",
    "\n",
    "print(train_0_unique_tags[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81926, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is spin as it relates to subatomic partic...</td>\n",
       "      <td>&lt;p&gt;I often hear about subatomic particles havi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What is your simplest explanation of the strin...</td>\n",
       "      <td>&lt;p&gt;How would you explain string theory to non ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Lie theory, Representations and particle physics</td>\n",
       "      <td>&lt;p&gt;This is a question that has been posted at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Will Determinism be ever possible?</td>\n",
       "      <td>&lt;p&gt;What are the main problems that we need to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Hamilton's Principle</td>\n",
       "      <td>&lt;p&gt;Hamilton's principle states that a dynamic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>What is sound and how is it produced?</td>\n",
       "      <td>&lt;p&gt;I've been using the term \"sound\" all my lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>What experiment would disprove string theory?</td>\n",
       "      <td>&lt;p&gt;I know that there's big controversy between...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>Why does the sky change color? Why the sky is ...</td>\n",
       "      <td>&lt;p&gt;Why does the sky change color? Why the sky ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>How's the energy of particle collisions calcul...</td>\n",
       "      <td>&lt;p&gt;Physicists often refer to the energy of col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>Monte Carlo use</td>\n",
       "      <td>&lt;p&gt;Where is the Monte Carlo method used in phy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  What is spin as it relates to subatomic partic...   \n",
       "1   2  What is your simplest explanation of the strin...   \n",
       "2   3   Lie theory, Representations and particle physics   \n",
       "3   7                 Will Determinism be ever possible?   \n",
       "4   9                               Hamilton's Principle   \n",
       "5  13              What is sound and how is it produced?   \n",
       "6  15      What experiment would disprove string theory?   \n",
       "7  17  Why does the sky change color? Why the sky is ...   \n",
       "8  19  How's the energy of particle collisions calcul...   \n",
       "9  21                                    Monte Carlo use   \n",
       "\n",
       "                                             content  \n",
       "0  <p>I often hear about subatomic particles havi...  \n",
       "1  <p>How would you explain string theory to non ...  \n",
       "2  <p>This is a question that has been posted at ...  \n",
       "3  <p>What are the main problems that we need to ...  \n",
       "4  <p>Hamilton's principle states that a dynamic ...  \n",
       "5  <p>I've been using the term \"sound\" all my lif...  \n",
       "6  <p>I know that there's big controversy between...  \n",
       "7  <p>Why does the sky change color? Why the sky ...  \n",
       "8  <p>Physicists often refer to the energy of col...  \n",
       "9  <p>Where is the Monte Carlo method used in phy...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(DATA_FOLDER + TEST_FILE)\n",
    "print(df_test.shape)\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_contents = df_test['content'].tolist()\n",
    "test_titles = df_test['title'].tolist()\n",
    "test_titles_contents = (df_test['title'] + ' ' + df_test['content']).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove [n]\n",
    "# remove pure numbers, don't remove letter+number words, like CO2\n",
    "\n",
    "# remove stopwords\n",
    "# consider µL?\n",
    "# remove formulas\n",
    "\n",
    "\n",
    "numbers = set('0123456789-')\n",
    "\n",
    "def is_useful_word(word):\n",
    "    return (word not in useless_words) and (len(word) > 2) and (re.search('[a-z]', word)) and (word[0] not in numbers)\n",
    "    \n",
    "\n",
    "def cleanse_html(content):\n",
    "    content = BeautifulSoup(content, \"lxml\").get_text()\n",
    "\n",
    "    # remove urls\n",
    "    content = re.sub(r\"\\S+:/\\S+\",\"\", content)  # \"xxx:/xxx\"\n",
    "    content = re.sub(r\"\\S+\\\\\\S+\",\"\", content)  # \"xxx\\xxx\"\n",
    "    \n",
    "    return content\n",
    "    \n",
    "\n",
    "def cleanse_lower_split(content):\n",
    "    # remove html tags\n",
    "    content = BeautifulSoup(content, \"lxml\").get_text()\n",
    "    \n",
    "    # remove urls\n",
    "    content = re.sub(r\"\\S+:/\\S+\",\"\", content)  # \"xxx:/xxx\"\n",
    "    content = re.sub(r\"\\S+\\\\\\S+\",\"\", content)  # \"xxx\\xxx\"\n",
    "    \n",
    "    # replace punctuations and numbers with whitespaces\n",
    "    content = re.sub(r\"[^a-zA-Z0-9\\-]\",\" \", content)\n",
    "        \n",
    "    # convert to lowercase\n",
    "    content = content.lower()\n",
    "    \n",
    "    words = content.split()\n",
    "    \n",
    "    # remove useless words\n",
    "    # stopwords, pure numbers, short words\n",
    "    words = [word for word in words if is_useful_word(word)]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# only reserve words.\n",
    "def cleanse(content):\n",
    "    # remove html tags\n",
    "    content = BeautifulSoup(content, \"lxml\").get_text()\n",
    "    \n",
    "    # remove urls\n",
    "    content = re.sub(r\"\\S+:/\\S+\",\"\", content)  # \"xxx:/xxx\"\n",
    "    content = re.sub(r\"\\S+\\\\\\S+\",\"\", content)  # \"xxx\\xxx\"\n",
    "    \n",
    "    # replace punctuations and numbers with whitespaces\n",
    "    content = re.sub(r\"[^a-zA-Z0-9\\-]\",\" \", content)\n",
    "        \n",
    "    # convert to lowercase\n",
    "    content = content.lower()\n",
    "    \n",
    "    words = content.split()\n",
    "    \n",
    "    # remove useless words\n",
    "    # stopwords, pure numbers, short words\n",
    "    words = [word for word in words if is_useful_word(word)]\n",
    "    \n",
    "    # concat words to a string\n",
    "    content = ' '.join(words)\n",
    "    \n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_word(s):\n",
    "    # if s start with english letter \n",
    "    return (re.search('[a-z]', s[0]))\n",
    "\n",
    "def cleanse_and_split_sentence(s):\n",
    "    # input a sentence, output a list of words\n",
    "    s = re.sub(r\"[^a-zA-Z0-9]\",\" \", s)\n",
    "    word_seq = s.lower().split()\n",
    "    word_seq = [word for word in word_seq if is_word(word)]\n",
    "        \n",
    "    return word_seq\n",
    "    \n",
    "# cleanse and cut sentences\n",
    "def cleanse_content_for_w2v(content):\n",
    "    # output format: [['i', 'don', 't', 'have', 'an', 'apple-pen'], ['there', 's', 'co2', 'in']]\n",
    "    content = BeautifulSoup(content, \"lxml\").get_text()\n",
    "    \n",
    "    content = re.sub(r\"\\S+:/\\S+\",\"\", content)  # \"xxx:/xxx\"\n",
    "    content = re.sub(r\"\\S+\\\\\\S+\",\"\", content)  # \"xxx\\xxx\"\n",
    "    \n",
    "    sentences = tokenizer.tokenize(content)\n",
    "    \n",
    "    word_seqs = []\n",
    "    for s in sentences:\n",
    "        word_seq = cleanse_and_split_sentence(s)\n",
    "        # if len(word_seq) >= 3:\n",
    "        word_seqs.append(word_seq)\n",
    "    \n",
    "    return word_seqs\n",
    "\n",
    "# not removing stopwords here\n",
    "def cleanse_content_for_tfidf(content):\n",
    "    # output format: [['i', 'don', 't', 'have', 'an', 'apple-pen'], ['there', 's', 'co2', 'in']]\n",
    "    content = BeautifulSoup(content, \"lxml\").get_text()\n",
    "    \n",
    "    content = re.sub(r\"\\S+:/\\S+\",\"\", content)  # \"xxx:/xxx\"\n",
    "    content = re.sub(r\"\\S+\\\\\\S+\",\"\", content)  # \"xxx\\xxx\"\n",
    "    \n",
    "    word_seq = cleanse_and_split_sentence(content)\n",
    "    \n",
    "    return word_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'don', 't', 'have', 'an', 'apple', 'pen'], ['there', 's', 'co2', 'in']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = \"I don't 'have' an apple-pen. There's 256 CO2 in 10km^3!\"\n",
    "cleanse_content_for_w2v(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'often', 'hear', 'about', 'subatomic', 'particles', 'having', 'a', 'property', 'called', 'spin', 'but', 'also', 'that', 'it', 'doesn', 't', 'actually', 'relate', 'to', 'spinning', 'about', 'an', 'axis', 'like', 'you', 'would', 'think'], ['which', 'particles', 'have', 'spin'], ['what', 'does', 'spin', 'mean', 'if', 'not', 'an', 'actual', 'spinning', 'motion']]\n",
      "----\n",
      "[['how', 'would', 'you', 'explain', 'string', 'theory', 'to', 'non', 'physicists', 'such', 'as', 'myself'], ['i', 'm', 'specially', 'interested', 'on', 'how', 'plausible', 'is', 'it', 'and', 'what', 'is', 'needed', 'to', 'successfully', 'prove', 'it']]\n",
      "----\n",
      "[['this', 'is', 'a', 'question', 'that', 'has', 'been', 'posted', 'at', 'many', 'different', 'forums', 'i', 'thought', 'maybe', 'someone', 'here', 'would', 'have', 'a', 'better', 'or', 'more', 'conceptual', 'answer', 'than', 'i', 'have', 'seen', 'before', 'why', 'do', 'physicists', 'care', 'about', 'representations', 'of', 'lie', 'groups'], ['for', 'myself', 'when', 'i', 'think', 'about', 'a', 'representation', 'that', 'means', 'there', 'is', 'some', 'sort', 'of', 'group', 'acting', 'on', 'a', 'vector', 'space', 'what', 'is', 'the', 'vector', 'space', 'that', 'this', 'lie', 'group', 'is', 'acting', 'on'], ['or', 'is', 'it', 'that', 'certain', 'things', 'have', 'to', 'be', 'invariant', 'under', 'a', 'group', 'action'], ['maybe', 'this', 'is', 'a', 'dumb', 'question', 'but', 'i', 'thought', 'it', 'might', 'be', 'a', 'good', 'start', 'to', 'clarify', 'i', 'am', 'specifically', 'thinking', 'of', 'the', 'symmetry', 'groups', 'that', 'people', 'think', 'about', 'in', 'relation', 'to', 'the', 'standard', 'model'], ['i', 'do', 'not', 'care', 'why', 'it', 'might', 'be', 'a', 'certain', 'group', 'but', 'more', 'how', 'we', 'see', 'the', 'group', 'acting', 'what', 'is', 'it', 'acting', 'on'], ['etc']]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for content in test_contents[:3]:\n",
    "    print(cleanse_content_for_w2v(content))\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare w2v training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_line(lst):\n",
    "    for s in lst:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleansed_train_domains_titles = []\n",
    "for df in df_trains:\n",
    "    word_seqs = []\n",
    "    for title in df['title'].tolist():\n",
    "        word_seqs.extend(cleanse_content_for_w2v(title))\n",
    "    cleansed_train_domains_titles.append(word_seqs)\n",
    "\n",
    "cleansed_train_domains_contents = []\n",
    "for df in df_trains:\n",
    "    word_seqs = []\n",
    "    for content in df['content'].tolist():\n",
    "        word_seqs.extend(cleanse_content_for_w2v(content))\n",
    "    cleansed_train_domains_contents.append(word_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13518\n",
      "15786\n",
      "10614\n",
      "26574\n",
      "2824\n",
      "20001\n",
      "\n",
      "69511\n",
      "82281\n",
      "69281\n",
      "180431\n",
      "19551\n",
      "104301\n",
      "[['what', 'are', 'some', 'caribbean', 'cruises', 'for', 'october'], ['how', 'can', 'i', 'find', 'a', 'guide', 'that', 'will', 'take', 'me', 'safely', 'through', 'the', 'amazon', 'jungle'], ['does', 'singapore', 'airlines', 'offer', 'any', 'reward', 'seats', 'on', 'their', 'ewr', 'sin', 'route']]\n",
      "[['my', 'fianc', 'e', 'and', 'i', 'are', 'looking', 'for', 'a', 'good', 'caribbean', 'cruise', 'in', 'october', 'and', 'were', 'wondering', 'which', 'islands', 'are', 'best', 'to', 'see', 'and', 'which', 'cruise', 'line', 'to', 'take'], ['it', 'seems', 'like', 'a', 'lot', 'of', 'the', 'cruises', 'don', 't', 'run', 'in', 'this', 'month', 'due', 'to', 'hurricane', 'season', 'so', 'i', 'm', 'looking', 'for', 'other', 'good', 'options'], ['edit', 'we', 'll', 'be', 'travelling', 'in']]\n"
     ]
    }
   ],
   "source": [
    "for cleansed_train_titles in cleansed_train_domains_titles:\n",
    "    print(len(cleansed_train_titles))\n",
    "print()\n",
    "for cleansed_train_contents in cleansed_train_domains_contents:\n",
    "    print(len(cleansed_train_contents))\n",
    "print(cleansed_train_domains_titles[5][:3])\n",
    "print(cleansed_train_domains_contents[5][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df_test\n",
    "\n",
    "cleansed_test_titles = []\n",
    "for title in df['title'].tolist():\n",
    "    cleansed_test_titles.extend(cleanse_content_for_w2v(title))\n",
    "\n",
    "cleansed_test_contents = []\n",
    "for content in df['content'].tolist():\n",
    "    cleansed_test_contents.extend(cleanse_content_for_w2v(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83757\n",
      "494470\n",
      "[['what', 'is', 'spin', 'as', 'it', 'relates', 'to', 'subatomic', 'particles'], ['what', 'is', 'your', 'simplest', 'explanation', 'of', 'the', 'string', 'theory'], ['lie', 'theory', 'representations', 'and', 'particle', 'physics']]\n",
      "[['i', 'often', 'hear', 'about', 'subatomic', 'particles', 'having', 'a', 'property', 'called', 'spin', 'but', 'also', 'that', 'it', 'doesn', 't', 'actually', 'relate', 'to', 'spinning', 'about', 'an', 'axis', 'like', 'you', 'would', 'think'], ['which', 'particles', 'have', 'spin'], ['what', 'does', 'spin', 'mean', 'if', 'not', 'an', 'actual', 'spinning', 'motion']]\n"
     ]
    }
   ],
   "source": [
    "print(len(cleansed_test_titles))\n",
    "print(len(cleansed_test_contents))\n",
    "print(cleansed_test_titles[:3])\n",
    "print(cleansed_test_contents[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleansed_all_w2v = []\n",
    "cleansed_train_titles_contents_w2v = []\n",
    "cleansed_test_titles_contents_w2v = []\n",
    "\n",
    "for cleansed_train_titles in cleansed_train_domains_titles:\n",
    "    cleansed_train_titles_contents_w2v.extend(cleansed_train_titles)\n",
    "for cleansed_train_contents in cleansed_train_domains_contents:\n",
    "    cleansed_train_titles_contents_w2v.extend(cleansed_train_contents)\n",
    "    \n",
    "cleansed_test_titles_contents_w2v.extend(cleansed_test_titles)\n",
    "cleansed_test_titles_contents_w2v.extend(cleansed_test_contents)\n",
    "\n",
    "cleansed_all_w2v.extend(cleansed_train_titles_contents_w2v)\n",
    "cleansed_all_w2v.extend(cleansed_test_titles_contents_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614673\n",
      "578227\n",
      "1192900\n"
     ]
    }
   ],
   "source": [
    "train_sentence_count = len(cleansed_train_titles_contents_w2v)\n",
    "test_sentence_count = len(cleansed_test_titles_contents_w2v)\n",
    "all_sentence_count = len(cleansed_all_w2v)\n",
    "print(train_sentence_count)\n",
    "print(test_sentence_count)\n",
    "print(all_sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### connect phrases by bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connect_phrases_bigram(word_seqs):\n",
    "    bigram_transformer = phrases.Phrases(word_seqs, min_count=20, threshold=1)\n",
    "    word_seqs_phrased_bigram = []\n",
    "    for word_seq in word_seqs:\n",
    "        word_seq_phrased = bigram_transformer[word_seq]\n",
    "        word_seq_phrased = [re.sub(r'_', '-', word) for word in word_seq_phrased]\n",
    "        word_seqs_phrased_bigram.append(word_seq_phrased)\n",
    "    \n",
    "    return bigram_transformer, word_seqs_phrased_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_bigram, test_phrased_bigram = connect_phrases_bigram(cleansed_test_titles_contents_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'electricity', 'instantaneous']\n",
      "['how-can', 'i', 'determine', 'transmission', 'reflection', 'coefficients', 'for', 'light']\n",
      "['the', 'principle-behind', 'door', 'peepholes']\n",
      "['physics', 'and', 'computer-science']\n",
      "['why-don', 't', 'electric', 'fish', 'shock', 'themselves']\n",
      "['why', 'were', 'the', 'si', 'base', 'quantities', 'chosen', 'as', 'such']\n",
      "['how-can', 'i', 'measure', 'the', 'mass', 'of', 'the', 'earth', 'at-home']\n",
      "['home', 'experiments', 'to-derive', 'the', 'speed-of', 'light']\n",
      "['symmetrical', 'twin-paradox']\n",
      "['getting', 'started', 'self-studying', 'general-relativity']\n"
     ]
    }
   ],
   "source": [
    "print_line(test_phrased_bigram[100:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_bigram.save('test_bigram_count20_threshold1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_bigram_vocab_dict = dict(test_bigram.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_test_bigram_vocab_dict = sorted(test_bigram_vocab_dict.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'no', 15814),\n",
       " (b'system', 15786),\n",
       " (b'could', 15610),\n",
       " (b'd', 15509),\n",
       " (b'particle', 15340),\n",
       " (b'c', 15248),\n",
       " (b'get', 15199),\n",
       " (b'for_the', 15194),\n",
       " (b'its', 15107),\n",
       " (b'what_is', 14863)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_test_bigram_vocab_dict[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stopwords then phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model/stopwords.txt') as f:\n",
    "    long_stopwords = f.read().splitlines()\n",
    "\n",
    "stopwords = set(long_stopwords) | nltk_stopwords\n",
    "\n",
    "for word in list(stopwords):\n",
    "    for subword in re.sub(r\"[^a-z]\", ' ', word).split():\n",
    "        stopwords.add(subword)\n",
    "    stopwords.add(re.sub(r\"'\", '-', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "722"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(word_seqs):\n",
    "    removed = []\n",
    "    for word_seq in word_seqs:\n",
    "        removed.append([word for word in word_seq if word not in stopwords])\n",
    "    return removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleansed_test_titles_contents_no_stopwords = remove_stopwords(cleansed_test_titles_contents_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spin', 'relates', 'subatomic', 'particles'],\n",
       " ['simplest', 'explanation', 'string', 'theory'],\n",
       " ['lie', 'theory', 'representations', 'particle', 'physics'],\n",
       " ['determinism'],\n",
       " ['hamilton', 'principle']]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansed_test_titles_contents_no_stopwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_bigram_nostop, test_phrased_bigram_nostop = connect_phrases_bigram(cleansed_test_titles_contents_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spin', 'relates', 'subatomic-particles'],\n",
       " ['simplest', 'explanation', 'string-theory'],\n",
       " ['lie', 'theory', 'representations', 'particle-physics'],\n",
       " ['determinism'],\n",
       " ['hamilton-principle'],\n",
       " ['sound-produced'],\n",
       " ['experiment', 'disprove', 'string-theory'],\n",
       " ['sky', 'change-color'],\n",
       " ['sky-blue', 'day', 'red', 'sunrise', 'set', 'black', 'night'],\n",
       " ['energy', 'particle', 'collisions', 'calculated'],\n",
       " ['monte-carlo'],\n",
       " ['leaning', 'banking', 'help', 'turning', 'bicycle'],\n",
       " ['velocity-object', 'electromagnetic-field'],\n",
       " ['difference', 'measurement', 'interaction', 'quantum-mechanics'],\n",
       " ['calculate-average', 'speed'],\n",
       " ['lay', 'explanation', 'special-theory', 'relativity'],\n",
       " ['coriolis', 'irrelevant', 'whirl', 'vortex', 'sink', 'bathtub'],\n",
       " ['magnets', 'energy', 'repel'],\n",
       " ['check', 'einstein-equations', 'correspondence', 'real'],\n",
       " ['impressions', 'topological', 'field-theories', 'mathematics'],\n",
       " ['capacitive', 'screen', 'sensing'],\n",
       " ['magnets', 'spin', 'positioned', 'precisely'],\n",
       " ['lhc', 'circular', 'long'],\n",
       " ['polarised', 'materials', 'change', 'colour', 'stress'],\n",
       " ['intuitive-explanation', 'gouy', 'phase'],\n",
       " ['proton', 'therapy', 'cancer', 'treatment'],\n",
       " ['physicists', 'solutions', 'yang', 'baxter', 'equation'],\n",
       " ['mnemonics', 'remember', 'properties-materials'],\n",
       " ['neutrons', 'repel'],\n",
       " ['quantum-entanglement', 'mediated', 'interaction']]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_phrased_bigram_nostop[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_titles_phrased_bigram_nostop = test_phrased_bigram_nostop[:len(cleansed_test_titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83757"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_titles_phrased_bigram_nostop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gravity', 'manipulation']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_titles_phrased_bigram_nostop[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_bigram_nostop.save('test_bigram_nostop_count20_threshold1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_bigram, all_phrased_bigram = connect_phrases_bigram(cleansed_all_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connect_phrases(word_seqs):\n",
    "    bigram_transformer = phrases.Phrases(word_seqs)\n",
    "    word_seqs_phrased_bigram = []\n",
    "    for word_seq in word_seqs:\n",
    "        word_seq_phrased = bigram_transformer[word_seq]\n",
    "        word_seq_phrased = [re.sub(r'_', '-', word) for word in word_seq_phrased]\n",
    "        word_seqs_phrased_bigram.append(word_seq_phrased)\n",
    "    \n",
    "    trigram_transformer = phrases.Phrases(word_seqs_phrased_bigram)\n",
    "    word_seqs_phrased_trigram = []\n",
    "    for word_seq in word_seqs_phrased_bigram:\n",
    "        word_seq_phrased = trigram_transformer[word_seq]\n",
    "        word_seq_phrased = [re.sub(r'_', '-', word) for word in word_seq_phrased]\n",
    "        word_seqs_phrased_trigram.append(word_seq_phrased)\n",
    "    return bigram_transformer, trigram_transformer, word_seqs_phrased_bigram, word_seqs_phrased_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_bigram, all_trigram_transformer, all_phrased_bigram, all_phrased_trigram = connect_phrases(cleansed_all_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'spin', 'as', 'it', 'relates', 'to', 'subatomic-particles']\n",
      "['what', 'is', 'your', 'simplest', 'explanation', 'of', 'the', 'string-theory']\n",
      "['lie', 'theory', 'representations', 'and', 'particle', 'physics']\n",
      "['will', 'determinism', 'be', 'ever', 'possible']\n",
      "['hamilton-s-principle']\n",
      "['what', 'is', 'sound', 'and', 'how', 'is', 'it', 'produced']\n",
      "['what', 'experiment', 'would', 'disprove-string-theory']\n",
      "['why', 'does', 'the', 'sky', 'change', 'color']\n",
      "['why', 'the', 'sky', 'is', 'blue', 'during', 'the', 'day', 'red', 'during', 'sunrise', 'set', 'and', 'black', 'during', 'the', 'night']\n",
      "['how', 's', 'the', 'energy', 'of', 'particle', 'collisions', 'calculated']\n"
     ]
    }
   ],
   "source": [
    "print_line(all_phrased_trigram[train_sentence_count:train_sentence_count+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_bigram, test_trigram, test_phrased_bigram, test_phrased_trigram = connect_phrases(cleansed_test_titles_contents_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print_line(test_phrased_bigram[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print_line(test_phrased_trigram[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_bigram_vocab = dict(test_bigram.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_bigram_vocab_words = list(test_bigram_vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1410768"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_bigram_vocab_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'photograph_was',\n",
       " b'visual_aspect',\n",
       " b't_torus',\n",
       " b'metric_correspond',\n",
       " b'fresnel_it',\n",
       " b'desperate_hand',\n",
       " b'made_thick',\n",
       " b'rearranging_s',\n",
       " b'generate_pulse',\n",
       " b'they_know']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bigram_vocab_words[100000:100000+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleansed_test_titles_for_tfidf = [cleanse_content_for_tfidf(title) for title in df_test['title'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['what', 'is', 'spin', 'as', 'it', 'relates', 'to', 'subatomic', 'particles'],\n",
       " ['what',\n",
       "  'is',\n",
       "  'your',\n",
       "  'simplest',\n",
       "  'explanation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'string',\n",
       "  'theory'],\n",
       " ['lie', 'theory', 'representations', 'and', 'particle', 'physics'],\n",
       " ['will', 'determinism', 'be', 'ever', 'possible'],\n",
       " ['hamilton', 's', 'principle']]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansed_test_titles_for_tfidf[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleansed_test_titles_bigram = connect_phrases_bigram(cleansed_test_titles_for_tfidf)\n",
    "cleansed_test_titles_trigram = connect_phrases_trigram(cleansed_test_titles_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'spin', 'as', 'it', 'relates', 'to', 'subatomic-particles']\n",
      "['what', 'is', 'your', 'simplest', 'explanation', 'of', 'the', 'string-theory']\n",
      "['lie', 'theory', 'representations', 'and', 'particle-physics']\n",
      "['will', 'determinism', 'be', 'ever', 'possible']\n",
      "['hamilton-s-principle']\n",
      "['what', 'is', 'sound', 'and', 'how', 'is', 'it', 'produced']\n",
      "['what', 'experiment', 'would', 'disprove-string-theory']\n",
      "['why', 'does', 'the', 'sky', 'change', 'color', 'why', 'the', 'sky', 'is', 'blue', 'during', 'the', 'day', 'red', 'during', 'sunrise', 'set', 'and', 'black', 'during', 'the', 'night']\n",
      "['how', 's', 'the', 'energy', 'of', 'particle', 'collisions', 'calculated']\n",
      "['monte-carlo', 'use']\n",
      "['does', 'leaning', 'banking', 'help', 'cause', 'turning', 'on', 'a', 'bicycle']\n",
      "['velocity', 'of', 'object', 'from', 'electromagnetic-field']\n",
      "['what', 'is', 'the', 'difference-between', 'a', 'measurement', 'and', 'any', 'other', 'interaction', 'in', 'quantum-mechanics']\n",
      "['how', 'to', 'calculate', 'average', 'speed']\n",
      "['lay', 'explanation', 'of', 'the', 'special-theory', 'of', 'relativity']\n",
      "['how', 'to', 'show', 'that', 'the', 'coriolis-effect', 'is', 'irrelevant', 'for', 'the', 'whirl', 'vortex', 'in', 'the', 'sink', 'bathtub']\n",
      "['where', 'do', 'magnets', 'get', 'the', 'energy', 'to', 'repel']\n",
      "['how', 'to', 'check', 'einstein-like', 'equations', 'on', 'their', 'correspondence', 'with', 'the', 'real-world']\n",
      "['impressions', 'of', 'topological-field-theories', 'in', 'mathematics']\n",
      "['what', 'is', 'a', 'capacitive', 'screen', 'sensing']\n"
     ]
    }
   ],
   "source": [
    "for ws in cleansed_test_titles_trigram[:20]:\n",
    "    print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleansed_test_contents_bigram = connect_phrases_bigram(cleansed_test_contents)\n",
    "cleansed_test_contents_trigram = connect_phrases_trigram(cleansed_test_contents_bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "elapsed: 90.07816433906555 seconds\n"
     ]
    }
   ],
   "source": [
    "# Set values for various parameters\n",
    "num_features = 500    # Word vector dimensionality                      \n",
    "min_word_count = 10   # Minimum word count                        \n",
    "num_workers = 3       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "num_iter = 1\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(w2v_training_data, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling, iter=num_iter)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = 'w2v_{}feature_{}minwords_{}iter'.format(num_features, min_word_count, num_iter)\n",
    "model.save(MODEL_FOLDER + model_name)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print('elapsed: {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29161, 500)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'molecular-biology' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-70770770af34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"molecular-biology\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                 \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot compute similarity with no input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'molecular-biology' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model.most_similar(\"molecular-biology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_0_unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mass-spectrometry',\n",
       " 'biological-networks',\n",
       " 'cancer',\n",
       " 'exercise',\n",
       " 'kidney',\n",
       " 'protein-expression',\n",
       " 'molecular-evolution',\n",
       " 'healing',\n",
       " 'vessel',\n",
       " 'chronic',\n",
       " 'gene-annotation',\n",
       " 'temperature',\n",
       " 'parasitism',\n",
       " 'mycology',\n",
       " 'synthetic-biology',\n",
       " 'growth-media',\n",
       " 'sex-ratio',\n",
       " 'macroevolution',\n",
       " 'sociobiology',\n",
       " 'development',\n",
       " 'vitamins',\n",
       " 'autoreceptor',\n",
       " 'host-pathogen-interaction',\n",
       " 'reptile',\n",
       " 'gel-electrophoresis',\n",
       " 'snp',\n",
       " 'peripheral-nervous-system',\n",
       " 'alcohol',\n",
       " 'small-rnaseq',\n",
       " 'sensation',\n",
       " 'gastroenterology',\n",
       " '3d-structure',\n",
       " 'plasmids',\n",
       " 'mouse',\n",
       " 'muscles',\n",
       " 'microarray',\n",
       " 'population-biology',\n",
       " 'units',\n",
       " 'reverse-transcription',\n",
       " 'artificial-selection',\n",
       " 'dna-methylation',\n",
       " 'proteins',\n",
       " 'homeostasis',\n",
       " 'anthropology',\n",
       " 'anaerobic-respiration',\n",
       " 'dna',\n",
       " 'bioinformatics',\n",
       " 'ebola',\n",
       " 'sexuality',\n",
       " 'gustation',\n",
       " 'electrical-stimulation',\n",
       " 'pedigree',\n",
       " 'biodiversity',\n",
       " 'hallucinogens',\n",
       " 'reproductive-biology',\n",
       " 'cell-based',\n",
       " 'altruism',\n",
       " 'amino-acids',\n",
       " 'blood-transfusion',\n",
       " 'chemistry',\n",
       " 'drosophila',\n",
       " 'vegetarianism',\n",
       " 'cytoskeleton',\n",
       " 'synestesia',\n",
       " 'information-theory',\n",
       " 'bile',\n",
       " 'rna',\n",
       " 'genetics',\n",
       " 'organic-chemistry',\n",
       " 'glucose',\n",
       " 'brain-stem',\n",
       " 'meiosis',\n",
       " 'event-related-potential',\n",
       " 'analgesia',\n",
       " 'carbohydrates',\n",
       " 'sexual-dimorphism',\n",
       " 'chromatin',\n",
       " 'homology',\n",
       " 'phosphorylation',\n",
       " 'cell-signaling',\n",
       " 'allometry',\n",
       " 'visualization',\n",
       " 'recombination',\n",
       " 'cell-biology',\n",
       " 'phylogenetics',\n",
       " 'calcium',\n",
       " 'literature',\n",
       " 'community-ecology',\n",
       " 'snake',\n",
       " 'scatology',\n",
       " 'gynecology',\n",
       " 'lepidoptera',\n",
       " 'biology-misconceptions',\n",
       " 'extremophiles',\n",
       " 'hybridization',\n",
       " 'quantitative-genetics',\n",
       " 'ecology',\n",
       " 'human-evolution',\n",
       " 'pets',\n",
       " 'nose',\n",
       " 'neurophysiology',\n",
       " 'sds-page',\n",
       " 'twins',\n",
       " 'biostatistics',\n",
       " 'sequence-assembly',\n",
       " 'cdna',\n",
       " 'classification',\n",
       " 'biofeedback',\n",
       " 'protocol',\n",
       " 'biogeography',\n",
       " 'xray-crystallography',\n",
       " 'histone-deacetylase',\n",
       " 'fruit',\n",
       " 'milk',\n",
       " 'terminology',\n",
       " 'species-distribution',\n",
       " 'renal-physiology',\n",
       " 'splicing',\n",
       " 'serotonin',\n",
       " 'underwater',\n",
       " 'dna-replication',\n",
       " 'regeneration',\n",
       " 'synapses',\n",
       " 'gene-regulation',\n",
       " 'lentivirus',\n",
       " 'human-genome',\n",
       " 'animal-husbandry',\n",
       " 'hypersensitivity',\n",
       " 'insulin',\n",
       " 'vaccination',\n",
       " 'arachnology',\n",
       " 'tissue',\n",
       " 'habitat',\n",
       " 'cilia',\n",
       " 'mri',\n",
       " 'autonomic-nervous-system',\n",
       " 'morphometry',\n",
       " 'invasive-species',\n",
       " 'human-genetics',\n",
       " 'dissociation-constant',\n",
       " 'homocysteine',\n",
       " 'transcription',\n",
       " 'taxonomy',\n",
       " 'treatment',\n",
       " 'neuroplasticity',\n",
       " 'protein-binding',\n",
       " 'cell-sorting',\n",
       " 'information',\n",
       " 'climate-change',\n",
       " 'autoimmune',\n",
       " 'experimental-design',\n",
       " 'soil',\n",
       " 'antibody',\n",
       " 'senescence',\n",
       " 'dreaming',\n",
       " 'human-physiology',\n",
       " 'genetic-diagrams',\n",
       " 'antihistamines',\n",
       " 'spliceosome',\n",
       " 'flight',\n",
       " 'ribosome',\n",
       " 'allele',\n",
       " 'bio-mechanics',\n",
       " 'melatonin',\n",
       " 'celiac-disease',\n",
       " 'microbiology',\n",
       " 'sequence-alignment',\n",
       " 'plasma-membrane',\n",
       " 'symbiosis',\n",
       " 'intracellular-transport',\n",
       " 'variant',\n",
       " 'biofilms',\n",
       " 'allelopathy',\n",
       " 'cytogenetics',\n",
       " 'movement',\n",
       " 'purification',\n",
       " 'hypothalamus',\n",
       " 'sex',\n",
       " 'pharmacokinetics',\n",
       " 'balance',\n",
       " 'enzymes',\n",
       " 'environment',\n",
       " 'methods',\n",
       " 'human-eye',\n",
       " 'congestion',\n",
       " 'dose',\n",
       " 'aids',\n",
       " 'mass-spec',\n",
       " 'phosphate',\n",
       " 'transfusion',\n",
       " 'neural-engineering',\n",
       " 'reference-request',\n",
       " 'digestive-system',\n",
       " 'landscape-ecology',\n",
       " 'antibiotics',\n",
       " 'review',\n",
       " 'thermodynamics',\n",
       " 'virus',\n",
       " 'speciation',\n",
       " 'bacteriology',\n",
       " 'optics',\n",
       " 'membrane',\n",
       " 'lipids',\n",
       " 'developmental-biology',\n",
       " 'indicator',\n",
       " 'limnology',\n",
       " 'decay',\n",
       " 'hematology',\n",
       " 'ecophysiology',\n",
       " 'evo-devo',\n",
       " 'zoology',\n",
       " 'smoking',\n",
       " 'abiogenesis',\n",
       " 'protein-engineering',\n",
       " 'energy',\n",
       " 'hair',\n",
       " 'plant-anatomy',\n",
       " 'olfaction',\n",
       " 'ovulation',\n",
       " 'theoretical-biology',\n",
       " 'natural-selection',\n",
       " 'rodents',\n",
       " 'behaviour',\n",
       " 'medium',\n",
       " 'odour',\n",
       " 'dogs',\n",
       " 'toxicology',\n",
       " 'gene-expression',\n",
       " 'cycle',\n",
       " 'saffron',\n",
       " 'injury',\n",
       " 'brain',\n",
       " 'experiment',\n",
       " 'biochemistry',\n",
       " 'mushroom',\n",
       " 'biophysics',\n",
       " 'homosexuality',\n",
       " 'antigen',\n",
       " 'immune-system',\n",
       " 'organs',\n",
       " 'western-blot',\n",
       " 'neuroscience',\n",
       " 'homework',\n",
       " 'mammals',\n",
       " 'dynorphin',\n",
       " 'marine-biology',\n",
       " 'hearing',\n",
       " 'epidemiology',\n",
       " 'genomes',\n",
       " 'life-history',\n",
       " 'cardiology',\n",
       " 'central-nervous-system',\n",
       " 'decomposition',\n",
       " 'eggs',\n",
       " 'lcr',\n",
       " 'food-web',\n",
       " 'opioid',\n",
       " 'tcga',\n",
       " 'coa',\n",
       " 'proteomics',\n",
       " 'trees',\n",
       " 'mitosis',\n",
       " 'immunosuppression',\n",
       " 'flowering',\n",
       " 'animal-models',\n",
       " 'gamete',\n",
       " 'genetic-code',\n",
       " 'cryonics',\n",
       " 'pseudogenes',\n",
       " 'chromatography',\n",
       " 'translation',\n",
       " 'pathophysiology',\n",
       " 'immunology',\n",
       " 'reproduction',\n",
       " 'ccp4',\n",
       " 'lungs',\n",
       " 'intelligence',\n",
       " 'implantation',\n",
       " 'circadian-rhythms',\n",
       " 'orf',\n",
       " 'biosynthesis',\n",
       " 'biomedical-technology',\n",
       " 'veterinary-medicine',\n",
       " 'sterilisation',\n",
       " 'lymphatic',\n",
       " 'statistics',\n",
       " 'cloning',\n",
       " 'staining',\n",
       " 'flow-cytometry',\n",
       " 'stomach',\n",
       " 'breathing',\n",
       " 'gwas',\n",
       " 'teratology',\n",
       " 'openaccess',\n",
       " 'sar',\n",
       " 'untagged',\n",
       " 'heart-output',\n",
       " 'biopython',\n",
       " 'antibiotic-resistance',\n",
       " 'action-potential',\n",
       " 'global-warming',\n",
       " 'dosage-compensation',\n",
       " 'software',\n",
       " 'touch',\n",
       " 'auxology',\n",
       " 'human-ear',\n",
       " 'endothelium',\n",
       " 'signal-processing',\n",
       " 'copy-number-variation',\n",
       " 'physiology',\n",
       " 'fatty-acid-synthase',\n",
       " 'history',\n",
       " 'sepsis',\n",
       " 'structural-biology',\n",
       " 'gene-therapy',\n",
       " 'chloroplasts',\n",
       " 'archaea',\n",
       " 'seeds',\n",
       " 'quorum-sensing',\n",
       " 'cognition',\n",
       " 'bone-biology',\n",
       " 'pharmacology',\n",
       " 'sex-chromosome',\n",
       " 'introns',\n",
       " 'liver',\n",
       " 'surgery',\n",
       " 'instinct',\n",
       " 'invertebrates',\n",
       " 'ligation',\n",
       " 'diabetes-mellitus',\n",
       " 'lifespan',\n",
       " 'microscopy',\n",
       " 'histopathology',\n",
       " 'nomenclature',\n",
       " 'photography',\n",
       " 'dna-isolation',\n",
       " 'children',\n",
       " 'influenza',\n",
       " 'enzyme-kinetics',\n",
       " 'vision',\n",
       " 'photoperiod',\n",
       " 'uv',\n",
       " 'plasticity',\n",
       " 'pdb',\n",
       " 'ecosystem',\n",
       " 'species-identification',\n",
       " 'excreta',\n",
       " 'aquaculture',\n",
       " 'inflammation',\n",
       " 'dissection',\n",
       " 'receptor',\n",
       " 'metabolomics',\n",
       " 'taste',\n",
       " 'circulatory-system',\n",
       " 'sleep',\n",
       " 'language',\n",
       " 'vegetation',\n",
       " 'apoptosis',\n",
       " 'protein-folding',\n",
       " 'palaeontology',\n",
       " 'book-recommendation',\n",
       " 'protein-structure',\n",
       " 'dendrology',\n",
       " 'neuromodulation',\n",
       " 'speculative',\n",
       " 'codon',\n",
       " 'systems-biology',\n",
       " 'cellular-respiration',\n",
       " 'chromosome',\n",
       " 'ethnobiology',\n",
       " 'bioenergetics',\n",
       " 'isoforms',\n",
       " 'linguistics',\n",
       " 'signalling',\n",
       " 'dehydration',\n",
       " 'publishing',\n",
       " 'immunity',\n",
       " 'mice',\n",
       " 'molluscs',\n",
       " 'ph',\n",
       " 'mycoplasma',\n",
       " 'tissue-repair',\n",
       " 'cpg',\n",
       " 'coot',\n",
       " 'nutrition',\n",
       " 'fret',\n",
       " 'inheritance',\n",
       " 'noncoding-rna',\n",
       " 'marsupials',\n",
       " 'immunoglobin',\n",
       " 'cranial-nerves',\n",
       " 'predation',\n",
       " 'gene',\n",
       " 'general-biology',\n",
       " 'iris',\n",
       " 'malaria',\n",
       " 'mrna',\n",
       " 'rrna',\n",
       " 'melanin',\n",
       " 'crossover',\n",
       " 'polymerase',\n",
       " 'embryology',\n",
       " 'yeast',\n",
       " 'photosynthesis',\n",
       " 'prokaryotes',\n",
       " 'safety',\n",
       " 'research-process',\n",
       " 'pharmacodynamics',\n",
       " 'ontology',\n",
       " 'thermophilia',\n",
       " 'astrobiology',\n",
       " 'stress',\n",
       " 'cas9',\n",
       " 'osmosis',\n",
       " 'psychology',\n",
       " 'collective-behaviour',\n",
       " 'sirs',\n",
       " 'human-anatomy',\n",
       " 'exons',\n",
       " 'golgi-body',\n",
       " 'pigmentation',\n",
       " 'echolocation',\n",
       " 'vestigial',\n",
       " 'ant',\n",
       " 'feline',\n",
       " 'radiation',\n",
       " 'structure-prediction',\n",
       " 'hiv',\n",
       " 'evolutionary-game-theory',\n",
       " 'prion',\n",
       " 'biotechnology',\n",
       " 'medicinal-chemistry',\n",
       " 'publication',\n",
       " 'hepatitis',\n",
       " 'molecular-genetics',\n",
       " 'minipreps',\n",
       " 'demography',\n",
       " 'lab-techniques',\n",
       " 'retrovirus',\n",
       " 'histone',\n",
       " 'mhc',\n",
       " 'benzodiazepine',\n",
       " 'light',\n",
       " 'primer',\n",
       " 'joints',\n",
       " 'lab-reagents',\n",
       " 'behavior',\n",
       " 'genomics',\n",
       " 'assay-development',\n",
       " 'ultrasound',\n",
       " 'pulmonology',\n",
       " 'chemical-communication',\n",
       " 'asexual-reproduction',\n",
       " 'pathology',\n",
       " 'cell-division',\n",
       " 'epigenetics',\n",
       " 'horizontal-gene-transfer',\n",
       " 'histone-modifications',\n",
       " 'death',\n",
       " 'cell-culture',\n",
       " 'germination',\n",
       " 'neuroanatomy',\n",
       " 'fat-metabolism',\n",
       " 'gene-synthesis',\n",
       " 'mutations',\n",
       " 'cladistics',\n",
       " 'sexual-reproduction',\n",
       " 'complexity',\n",
       " 'forward-genetics',\n",
       " 'bioluminescence',\n",
       " 'codon-usage',\n",
       " 'endocrinology',\n",
       " 'scales',\n",
       " 'electromuscular',\n",
       " 'protein-interaction',\n",
       " 'plant-physiology',\n",
       " 'heat',\n",
       " 'aspirin',\n",
       " 'tuberculosis',\n",
       " 'cell-membrane',\n",
       " 'growth',\n",
       " 'rna-sequencing',\n",
       " 'extinction',\n",
       " 'high-throughput',\n",
       " 'phenology',\n",
       " 'fluorescent-microscopy',\n",
       " 'locomotion',\n",
       " 'binding-sites',\n",
       " 'senses',\n",
       " 'artificial-life',\n",
       " 'kinetics',\n",
       " 'minerals',\n",
       " 'flowers',\n",
       " 'virology',\n",
       " 'scientific-literature',\n",
       " 'selection',\n",
       " 'poison',\n",
       " 'entomology',\n",
       " 'memory',\n",
       " 't7-promoter',\n",
       " 'digestion',\n",
       " 'blood-pressure',\n",
       " 'chip-seq',\n",
       " 'hygiene',\n",
       " 'migration',\n",
       " 'vertebrates',\n",
       " 'electroencephalography',\n",
       " 'pcr',\n",
       " 'forest',\n",
       " 'clinical-trial',\n",
       " 'fst',\n",
       " 'restriction-enzymes',\n",
       " 'elisa',\n",
       " 'blood-sugar',\n",
       " 'evolution',\n",
       " 'research-tools',\n",
       " 'dnapolymerase',\n",
       " 'human',\n",
       " 'psychoneuropharmacology',\n",
       " 'autophagy',\n",
       " 'recombinant',\n",
       " 'metabolism',\n",
       " 'research-design',\n",
       " 'anecdotal-evidence',\n",
       " 'eeg',\n",
       " 'psychophysics',\n",
       " 'experimental',\n",
       " 'green-fluorescent-protein',\n",
       " 'telomere',\n",
       " 'dna-helix',\n",
       " 'data',\n",
       " 'red-blood-cell',\n",
       " 'teeth',\n",
       " 'literature-search',\n",
       " 'ornithology',\n",
       " 'transplantation',\n",
       " 'addiction',\n",
       " 'definitions',\n",
       " 'sexual-selection',\n",
       " 'hyperplasia',\n",
       " 'blast',\n",
       " 'transdermal',\n",
       " 'pregnancy',\n",
       " 'cholesterol',\n",
       " 'population-dynamics',\n",
       " 'saliva',\n",
       " 'pathogenesis',\n",
       " 'ventricles',\n",
       " 'chip',\n",
       " 'neurotransmitter',\n",
       " 'morphology',\n",
       " 'menstrual-cycle',\n",
       " 'tumor',\n",
       " 'neurology',\n",
       " 'osmoregulation',\n",
       " 'territoriality',\n",
       " 'chronobiology',\n",
       " 'ncbi',\n",
       " 'sex-determination',\n",
       " 'biomedical-engineering',\n",
       " 'food',\n",
       " 'visual-system',\n",
       " 'ethology',\n",
       " 'bioinorganic-chemistry',\n",
       " 'genetic-linkage',\n",
       " 'diet',\n",
       " 'ichthyology',\n",
       " 'antipredator-adaptation',\n",
       " 'anatomy',\n",
       " 'network',\n",
       " 'ontogeny',\n",
       " 'measurement',\n",
       " 'eyes',\n",
       " 'waste-disposal',\n",
       " 'mimicry',\n",
       " 'icgc',\n",
       " 'medicine',\n",
       " 'respiration',\n",
       " 'membrane-transport',\n",
       " 'mitochondria',\n",
       " 'imaging',\n",
       " 'vegetable',\n",
       " 'blood-group',\n",
       " 'lymphoma',\n",
       " 'chimerism',\n",
       " 'neurodegerative-disorders',\n",
       " 'plant-perception',\n",
       " 'salt',\n",
       " 'competent-cells',\n",
       " 'hydration',\n",
       " 'community',\n",
       " 'blood-brain-barrier',\n",
       " 'mathematical-models',\n",
       " 'rna-interference',\n",
       " 'database',\n",
       " 'replication',\n",
       " 'histamine',\n",
       " 'operons',\n",
       " 'conservation-biology',\n",
       " 'transcription-factor',\n",
       " 'agriculture',\n",
       " 'sociality',\n",
       " 'dopamine',\n",
       " 'electrophysiology',\n",
       " 'cell-cycle',\n",
       " 'diy-biology',\n",
       " 'pymol',\n",
       " 'cocaine',\n",
       " 'dna-sequencing',\n",
       " 'cell',\n",
       " 'computational-model',\n",
       " 'communication',\n",
       " 'chirality',\n",
       " 'fermentation',\n",
       " 'chembl',\n",
       " 'hardy-weinberg',\n",
       " 'blood-circulation',\n",
       " 'transformation',\n",
       " 'dna-repair',\n",
       " 'allergies',\n",
       " 'forensics',\n",
       " 'chickens',\n",
       " 'learning',\n",
       " 'hla',\n",
       " 'polyploidy',\n",
       " 'molecular-biology',\n",
       " 'health',\n",
       " 'herpetology',\n",
       " 'extra-cellular-matrix',\n",
       " 'life',\n",
       " 'heart-failure',\n",
       " 'adaptation',\n",
       " 'crocus-sativus',\n",
       " 'reverse-genetics',\n",
       " 'cytokinesis',\n",
       " 'pain',\n",
       " 'ecoli',\n",
       " 'nucleic-acids',\n",
       " 'microbiome',\n",
       " 'parasitology',\n",
       " 'wasps',\n",
       " 'sensory-systems',\n",
       " 'prokaryotic-cells',\n",
       " 'eukaryotic-cells',\n",
       " 'gender',\n",
       " 'microrna',\n",
       " 'sugar',\n",
       " 'reflexes',\n",
       " 'skin',\n",
       " 'organelle',\n",
       " 'peer-review-journal',\n",
       " 'philosophy-of-science',\n",
       " 'fitness',\n",
       " 'protein-evolution',\n",
       " 'population-genetics',\n",
       " 'histology',\n",
       " 'biological-control',\n",
       " 'sequence-analysis',\n",
       " 'electrocardiography',\n",
       " 'differentiation',\n",
       " 'crispr',\n",
       " 'bacterial-toxins',\n",
       " 'veins',\n",
       " 'transfection',\n",
       " 'identification',\n",
       " 'dna-damage',\n",
       " 'infection',\n",
       " 'perception',\n",
       " 'centrifugation',\n",
       " 'stem-cells',\n",
       " 'species',\n",
       " 'lymph',\n",
       " 'oogenesis',\n",
       " 'human-biology',\n",
       " 'pathway',\n",
       " 'image-processing',\n",
       " 'pest-control',\n",
       " 'botany']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0_unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_0_unique_tags_with_hyphen = [tag for tag in train_0_unique_tags if '-' in tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_0_unique_tags_with_hyphen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_0_unique_tags_with_hyphen_occur_over_10 = [tag for tag in train_0_unique_tags_with_hyphen if tag in model.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_0_unique_tags_with_hyphen_occur_over_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "keyword = 'molecular-biology'\n",
    "counter_title = 0\n",
    "\n",
    "for word_seq in cleansed_train_domains_titles[0]:\n",
    "    for word in word_seq:\n",
    "        if word == keyword:\n",
    "            counter_title += 1\n",
    "print(counter_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "keyword = 'molecular-biology'\n",
    "counter_content = 0\n",
    "\n",
    "for word_seq in cleansed_train_domains_contents[0]:\n",
    "    for word in word_seq:\n",
    "        if word == keyword:\n",
    "            counter_content += 1\n",
    "print(counter_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "keywords = ['molecular', 'biology']\n",
    "counter = 0\n",
    "\n",
    "for word_seq in cleansed_train_domains_titles[0]:\n",
    "    for i in range(len(word_seq)-len(keywords)+1):\n",
    "        if word_seq[i] == keywords[0] and word_seq[i+1] == keywords[1]:\n",
    "            counter += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase then w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "bigram_transformer = phrases.Phrases(w2v_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_training_data_phrased = []\n",
    "for word_seq in w2v_training_data:\n",
    "    word_seq_phrased = bigram_transformer[word_seq]\n",
    "    word_seq_phrased = [re.sub(r'_', '-', word) for word in word_seq_phrased]\n",
    "    w2v_training_data_phrased.append(word_seq_phrased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['what',\n",
       "  'is',\n",
       "  'the',\n",
       "  'criticality',\n",
       "  'of',\n",
       "  'the',\n",
       "  'ribosome-binding',\n",
       "  'site',\n",
       "  'relative',\n",
       "  'to',\n",
       "  'the',\n",
       "  'start-codon',\n",
       "  'in',\n",
       "  'prokaryotic',\n",
       "  'translation'],\n",
       " ['how',\n",
       "  'is',\n",
       "  'rnase-contamination',\n",
       "  'in',\n",
       "  'rna',\n",
       "  'based',\n",
       "  'experiments',\n",
       "  'prevented'],\n",
       " ['are', 'lymphocyte', 'sizes', 'clustered', 'in', 'two', 'groups'],\n",
       " ['how',\n",
       "  'long',\n",
       "  'does',\n",
       "  'antibiotic-dosed',\n",
       "  'lb',\n",
       "  'maintain',\n",
       "  'good',\n",
       "  'selection'],\n",
       " ['is', 'exon', 'order', 'always', 'preserved', 'in', 'splicing'],\n",
       " ['how', 'can', 'i', 'avoid', 'digesting', 'protein-bound', 'dna'],\n",
       " ['under', 'what', 'conditions', 'do', 'dendritic', 'spines', 'form'],\n",
       " ['how', 'should', 'i', 'ship', 'plasmids'],\n",
       " ['what',\n",
       "  'is',\n",
       "  'the',\n",
       "  'reason-behind',\n",
       "  'choosing',\n",
       "  'the',\n",
       "  'reporter-gene',\n",
       "  'when',\n",
       "  'experimenting',\n",
       "  'on',\n",
       "  'your',\n",
       "  'gene',\n",
       "  'of',\n",
       "  'interest'],\n",
       " ['how', 'many-times', 'did', 'endosymbiosis', 'occur'],\n",
       " ['how',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'edge',\n",
       "  'effects',\n",
       "  'in',\n",
       "  'cell-based',\n",
       "  'high-throughput',\n",
       "  'experiments'],\n",
       " ['has', 'anyone', 'tried', 'gibson-assembly', 'optimizations'],\n",
       " ['what',\n",
       "  'is',\n",
       "  'the',\n",
       "  'optimal',\n",
       "  'frame',\n",
       "  'size',\n",
       "  'for',\n",
       "  'protein',\n",
       "  'secondary-structure',\n",
       "  'prediction',\n",
       "  'methods'],\n",
       " ['what',\n",
       "  'are',\n",
       "  'the',\n",
       "  'main',\n",
       "  'mechanisms',\n",
       "  'of',\n",
       "  'interaction-between',\n",
       "  'the',\n",
       "  'nervous',\n",
       "  'and',\n",
       "  'immune-systems'],\n",
       " ['what',\n",
       "  'are',\n",
       "  'the',\n",
       "  'mechanism',\n",
       "  'binding',\n",
       "  'histone-code',\n",
       "  'with',\n",
       "  'alternative-splicing'],\n",
       " ['what',\n",
       "  'are',\n",
       "  'the',\n",
       "  'limiting-factors',\n",
       "  'for',\n",
       "  'gene',\n",
       "  'length',\n",
       "  'and',\n",
       "  'number',\n",
       "  'of',\n",
       "  'exons'],\n",
       " ['how', 'to', 'understand', 'influenza', 'strain', 'designations'],\n",
       " ['transmission',\n",
       "  'of',\n",
       "  'epigenetic',\n",
       "  'regulation',\n",
       "  'through',\n",
       "  'surrogate',\n",
       "  'mother'],\n",
       " ['what',\n",
       "  'is',\n",
       "  'a',\n",
       "  'good',\n",
       "  'miniprep',\n",
       "  'protocol',\n",
       "  'for',\n",
       "  'the',\n",
       "  'class',\n",
       "  'room'],\n",
       " ['what',\n",
       "  'specific',\n",
       "  'membrane',\n",
       "  'adaptations',\n",
       "  'do',\n",
       "  'cells',\n",
       "  'have',\n",
       "  'for',\n",
       "  'saline-rich',\n",
       "  'environs']]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_training_data_phrased[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "elapsed: 320.4764587879181 seconds\n"
     ]
    }
   ],
   "source": [
    "# Set values for various parameters\n",
    "num_features = 500    # Word vector dimensionality                      \n",
    "min_word_count = 5   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "num_iter = 5\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(w2v_training_data_phrased, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling, iter=num_iter)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = 'w2v_phrase_{}feature_{}minwords_{}iter'.format(num_features, min_word_count, num_iter)\n",
    "model.save(MODEL_FOLDER + model_name)\n",
    "\n",
    "end = time.time()\n",
    "print('elapsed: {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_0_unique_tags_with_hyphen_in_model = [tag for tag in train_0_unique_tags_with_hyphen if tag in model.vocab]\n",
    "len(train_0_unique_tags_with_hyphen_in_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_transformer = phrases.Phrases(w2v_training_data_phrased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1163379"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_training_data_phrased_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_training_data_phrased_trigram = []\n",
    "for word_seq in w2v_training_data_phrased:\n",
    "    word_seq_phrased = trigram_transformer[word_seq]\n",
    "    word_seq_phrased = [re.sub(r'_', '-', word) for word in word_seq_phrased]\n",
    "    w2v_training_data_phrased_trigram.append(word_seq_phrased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "elapsed: 155.5711395740509 seconds\n"
     ]
    }
   ],
   "source": [
    "# Set values for various parameters\n",
    "num_features = 200    # Word vector dimensionality                      \n",
    "min_word_count = 5   # Minimum word count                        \n",
    "num_iter = 5\n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(w2v_training_data_phrased_trigram, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling, iter=num_iter)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = 'w2v_phrase_trigram_{}feature_{}minwords_{}iter'.format(num_features, min_word_count, num_iter)\n",
    "model.save(MODEL_FOLDER + model_name)\n",
    "\n",
    "end = time.time()\n",
    "print('elapsed: {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0_unique_tags_with_hyphen_in_model = [tag for tag in train_0_unique_tags_with_hyphen if tag in model.vocab]\n",
    "len(train_0_unique_tags_with_hyphen_in_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spins', 0.7283067107200623),\n",
       " ('orbital-angular-momentum', 0.6553120613098145),\n",
       " ('total-spin', 0.6381109952926636),\n",
       " ('magnetic-moment', 0.6370653510093689),\n",
       " ('helicity', 0.6061174869537354),\n",
       " ('spin-angular-momentum', 0.6009663343429565),\n",
       " ('angular-momentum', 0.5679385662078857),\n",
       " ('total-angular-momentum', 0.564512312412262),\n",
       " ('parity', 0.5601943135261536),\n",
       " ('spin-up', 0.550516664981842)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('spin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Tag Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678\n",
      "736\n",
      "392\n",
      "734\n",
      "231\n",
      "1645\n"
     ]
    }
   ],
   "source": [
    "train_domains_tag_set = []\n",
    "\n",
    "tag_set = set()\n",
    "\n",
    "for df in df_trains:\n",
    "    tag_set = set()\n",
    "    for tags in df['tags'].tolist():\n",
    "        for tag in tags.split():\n",
    "            tag_set.add(tag)\n",
    "    print(len(tag_set))\n",
    "    train_domains_tag_set.append(tag_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4416"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_count = 0\n",
    "for tag_set in train_domains_tag_set:\n",
    "    tag_count += len(tag_set)\n",
    "tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4268\n"
     ]
    }
   ],
   "source": [
    "train_tag_set = set()\n",
    "for tag_set in train_domains_tag_set:\n",
    "    train_tag_set |= tag_set\n",
    "print(len(train_tag_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentence_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563221\n",
      "600158\n",
      "1163379\n"
     ]
    }
   ],
   "source": [
    "test_sentence_count = len(cleansed_test_contents) + len(cleansed_test_titles)\n",
    "print(test_sentence_count)\n",
    "train_sentence_count = len(w2v_training_data_phrased_trigram) - test_sentence_count\n",
    "print(train_sentence_count)\n",
    "print(len(w2v_training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133804\n"
     ]
    }
   ],
   "source": [
    "train_not_tag_set = set()\n",
    "\n",
    "for sentence in w2v_training_data_phrased_trigram[:train_sentence_count]:\n",
    "    for word in sentence:\n",
    "        if word not in train_tag_set:\n",
    "            train_not_tag_set.add(word)\n",
    "\n",
    "print(len(train_not_tag_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16926\n"
     ]
    }
   ],
   "source": [
    "test_possible_tag_set = set()\n",
    "\n",
    "for sentence in w2v_training_data_phrased_trigram[train_sentence_count:]:\n",
    "    for word in sentence:\n",
    "        if (word not in train_not_tag_set) and (word in model.vocab):\n",
    "            test_possible_tag_set.add(word)\n",
    "\n",
    "print(len(test_possible_tag_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_possible_tag_list = list(test_possible_tag_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lie-group-g',\n",
       " 'shifman',\n",
       " 'mass-spectrometry',\n",
       " 'spin-spin-interaction',\n",
       " 'euclidean-ads',\n",
       " 'classical-electrodynamics',\n",
       " 'b-l',\n",
       " 'bragg-scattering',\n",
       " 'integrating-factor',\n",
       " 'freeman-dyson']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_possible_tag_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'quantum-mechanics' in test_possible_tag_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'quantum-mechanics' in train_not_tag_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phrase then tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cleansed_test_titles_trigram\n",
    "# cleansed_test_contents_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('model/stopwords.txt') as f:\n",
    "    long_stopwords = f.read().splitlines()\n",
    "\n",
    "stopwords = set(long_stopwords) | nltk_stopwords | set('question problem change point number size help definition equation proof physics state function derivation'.split())\n",
    "\n",
    "for word in list(stopwords):\n",
    "    for subword in re.sub(r\"[^a-z]\", ' ', word).split():\n",
    "        stopwords.add(subword)\n",
    "    stopwords.add(re.sub(r\"'\", '-', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_titles_phrased_bigram_nostop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_title_for_tfidf = []\n",
    "for word_seq in test_titles_phrased_bigram_nostop:\n",
    "    test_title_for_tfidf.append( ' '.join([word for word in word_seq if word not in stopwords]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_title_for_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_tags_from_cleansed_contents(cleansed_contents, max_features):\n",
    "    vectorizer = TfidfVectorizer(use_idf=False, stop_words = \"english\", \\\n",
    "                                 tokenizer = str.split,    \\\n",
    "                                 preprocessor = None, \\\n",
    "                                 max_features = max_features)\n",
    "    features = vectorizer.fit_transform(cleansed_contents)\n",
    "    feature_words = vectorizer.get_feature_names()\n",
    "    \n",
    "    predicted_tags = []\n",
    "\n",
    "    for feature in features:\n",
    "        values = feature.data\n",
    "        _, word_idxs = feature.nonzero()\n",
    "\n",
    "        index_sorted = np.argsort(values)[::-1]\n",
    "        keywords = [feature_words[wid] for wid in word_idxs[index_sorted]]\n",
    "        predicted_tags.append(' '.join(keywords))\n",
    "    \n",
    "    return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-88e42e23fb93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_title_predicted_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_tags_from_cleansed_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_title_for_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-186-d209cbc7be64>\u001b[0m in \u001b[0;36mpredict_tags_from_cleansed_contents\u001b[0;34m(cleansed_contents, max_features)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_tags_from_cleansed_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleansed_contents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"english\"\u001b[0m\u001b[0;34m,\u001b[0m                                  \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m                                     \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m                                  \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleansed_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mfeature_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0mTf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m         \"\"\"\n\u001b[0;32m-> 1332\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 824\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 241\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda3/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "test_title_predicted_tags = predict_tags_from_cleansed_contents(test_title_for_tfidf, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predicted_tags_noun = []\n",
    "\n",
    "for tags in test_title_predicted_tags:\n",
    "    pos_tagged = nltk.pos_tag(tags.split())\n",
    "    noun_tags = [i[0] for i in pos_tagged if i[1][0] in \"N\"]\n",
    "    noun_tags_str = ' '.join(noun_tags)\n",
    "    test_predicted_tags_noun.append(noun_tags_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spin subatomic-particles',\n",
       " 'explanation string-theory',\n",
       " 'lie representations particle-physics',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'experiment',\n",
       " 'sky',\n",
       " 'day night',\n",
       " 'energy particle collisions',\n",
       " 'monte-carlo',\n",
       " 'help bicycle',\n",
       " 'electromagnetic-field',\n",
       " 'difference interaction quantum-mechanics',\n",
       " 'speed',\n",
       " 'explanation relativity',\n",
       " 'coriolis vortex sink',\n",
       " 'energy magnets',\n",
       " 'einstein-equations correspondence',\n",
       " 'field-theories mathematics']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predicted_tags_noun[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_tags = []\n",
    "for tags in test_predicted_tags_noun:\n",
    "    all_tags.extend(tags.split())\n",
    "\n",
    "counter = Counter(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('question', 19422),\n",
       " ('time', 15321),\n",
       " ('energy', 14626),\n",
       " ('equation', 10696),\n",
       " ('mass', 10409),\n",
       " ('case', 9593),\n",
       " ('example', 9291),\n",
       " ('problem', 9245),\n",
       " ('field', 9059),\n",
       " ('point', 8701),\n",
       " ('particle', 7381),\n",
       " ('space', 7306),\n",
       " ('work', 7303),\n",
       " ('force', 7150),\n",
       " ('physics', 7055),\n",
       " ('velocity', 6575),\n",
       " ('state', 6119),\n",
       " ('particles', 5931),\n",
       " ('gravity', 5846),\n",
       " ('theory', 5466),\n",
       " ('distance', 5337),\n",
       " ('water', 5280),\n",
       " ('change', 5261),\n",
       " ('understand', 5080),\n",
       " ('speed', 5071),\n",
       " ('terms', 4827),\n",
       " ('difference', 4781),\n",
       " ('temperature', 4717),\n",
       " ('function', 4666),\n",
       " ('direction', 4615),\n",
       " ('form', 4575),\n",
       " ('surface', 4543),\n",
       " ('electrons', 4452),\n",
       " ('calculate', 4362),\n",
       " ('charge', 4361),\n",
       " ('equations', 4331),\n",
       " ('states', 4205),\n",
       " ('matter', 4202),\n",
       " ('answer', 4190),\n",
       " ('fact', 4010),\n",
       " ('motion', 3978),\n",
       " ('model', 3958),\n",
       " ('book', 3957),\n",
       " ('order', 3945),\n",
       " ('momentum', 3911),\n",
       " ('earth', 3902),\n",
       " ('result', 3868),\n",
       " ('acceleration', 3775),\n",
       " ('help', 3744),\n",
       " ('sense', 3704),\n",
       " ('solution', 3583),\n",
       " ('air', 3531),\n",
       " ('electron', 3514),\n",
       " ('term', 3474),\n",
       " ('photons', 3472),\n",
       " ('measure', 3430),\n",
       " ('questions', 3428),\n",
       " ('pressure', 3426),\n",
       " ('idea', 3408),\n",
       " ('times', 3376),\n",
       " ('body', 3344),\n",
       " ('number', 3335),\n",
       " ('reason', 3273),\n",
       " ('photon', 3219),\n",
       " ('definition', 3178),\n",
       " ('explain', 3144),\n",
       " ('formula', 3073),\n",
       " ('things', 3056),\n",
       " ('kind', 3054),\n",
       " ('quantum-mechanics', 3022),\n",
       " ('paper', 3012),\n",
       " ('source', 3002),\n",
       " ('density', 2970),\n",
       " ('course', 2948),\n",
       " ('explanation', 2934),\n",
       " ('forces', 2921),\n",
       " ('law', 2870),\n",
       " ('fields', 2849),\n",
       " ('thing', 2836),\n",
       " ('relation', 2815),\n",
       " ('heat', 2793),\n",
       " ('edit', 2781),\n",
       " ('frequency', 2761),\n",
       " ('vector', 2757),\n",
       " ('points', 2746),\n",
       " ('process', 2641),\n",
       " ('values', 2617),\n",
       " ('power', 2616),\n",
       " ('position', 2600),\n",
       " ('volume', 2585),\n",
       " ('objects', 2579),\n",
       " ('spin', 2528),\n",
       " ('suppose', 2494),\n",
       " ('area', 2471),\n",
       " ('gas', 2457),\n",
       " ('figure', 2428),\n",
       " ('atoms', 2393),\n",
       " ('size', 2340),\n",
       " ('vacuum', 2314),\n",
       " ('length', 2306)]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roger/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "output_file_name = 'output/w2v_trigram_title_feature5000_noun_correct_trigram.csv'\n",
    "\n",
    "df_output = df_test[['id']]\n",
    "df_output['tags'] = test_predicted_tags_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>spin subatomic-particles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>explanation string-theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>lie representations particle-physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>determinism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>hamilton-s-principle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>sound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>experiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>sky color day sunrise night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>energy particle collisions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>monte-carlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26</td>\n",
       "      <td>velocity electromagnetic-field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>interaction quantum-mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29</td>\n",
       "      <td>speed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>explanation relativity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32</td>\n",
       "      <td>vortex sink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35</td>\n",
       "      <td>energy magnets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>37</td>\n",
       "      <td>check equations real-world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>41</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                  tags\n",
       "0    1              spin subatomic-particles\n",
       "1    2             explanation string-theory\n",
       "2    3  lie representations particle-physics\n",
       "3    7                           determinism\n",
       "4    9                  hamilton-s-principle\n",
       "5   13                                 sound\n",
       "6   15                            experiment\n",
       "7   17           sky color day sunrise night\n",
       "8   19            energy particle collisions\n",
       "9   21                           monte-carlo\n",
       "10  24                               bicycle\n",
       "11  26        velocity electromagnetic-field\n",
       "12  27         interaction quantum-mechanics\n",
       "13  29                                 speed\n",
       "14  31                explanation relativity\n",
       "15  32                           vortex sink\n",
       "16  35                        energy magnets\n",
       "17  37            check equations real-world\n",
       "18  41                           mathematics\n",
       "19  49                                screen"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "df_output.to_csv(output_file_name, index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
