{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "METHOD = 'cnn_self-training'\n",
    "\n",
    "DATA_FOLDER_PATH = 'data/'\n",
    "MODEL_FILE_PATH = 'model/hw_' + METHOD\n",
    "\n",
    "LABELLED_DATA_FILE = DATA_FOLDER_PATH + 'all_label.p'\n",
    "UNLABELED_DATA_FILE = DATA_FOLDER_PATH + 'all_unlabel.p'\n",
    "TEST_DATA_FILE = DATA_FOLDER_PATH + 'test.p'\n",
    "\n",
    "OUTPUT_FOLDER = 'output/'\n",
    "MODEL_FOLDER = 'model/' + METHOD + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# if not os.path.exists(MODEL_FOLDER):\n",
    "#     os.makedirs(MODEL_FOLDER)\n",
    "# if not os.path.exists(OUTPUT_FOLDER):\n",
    "#     os.makedirs(OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelled_data = np.array(pickle.load(open(LABELLED_DATA_FILE, 'rb')))\n",
    "unlabeled_data = np.array(pickle.load(open(UNLABELED_DATA_FILE, 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "img_rows, img_cols, img_channels = 32, 32, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate x, y from data\n",
    "\n",
    "# reshape labelled data to (5000, 3, 32, 32)\n",
    "X_train_label = labelled_data.reshape((5000, img_channels, img_rows, img_cols)).astype('float32') / 255\n",
    "\n",
    "# reshape unlabeled data to (45000, 3, 32, 32)\n",
    "X_train_unlabel = unlabeled_data.reshape((unlabeled_data.shape[0], img_channels, img_rows, img_cols)).astype('float32') / 255\n",
    "\n",
    "y_train_label_class = np.array([classIdx for classIdx in range(len(labelled_data)) for i in range(len(labelled_data[classIdx]))])\n",
    "Y_train_label = np_utils.to_categorical(y_train_label_class, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # visualize\n",
    "# from scipy.misc import toimage\n",
    "# toimage(X_train_unlabel[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "def certainty(prob_arr):  # higher is more certain\n",
    "    return -entropy(prob_arr)\n",
    "\n",
    "def uncertainty(prob_arr):  # lower is better. for descending-ordered sorting\n",
    "    return entropy(prob_arr)\n",
    "\n",
    "#     sorted_arr = np.sort(prob_arr)\n",
    "#     return sorted_arr[-1] / sorted_arr[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first model\n",
    "batch_size = 64\n",
    "nb_epoch = 100\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=X_train_label.shape[1:], dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), dim_ordering=\"th\", border_mode='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())  # n * 8 * 8, for 64 -> 4096\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_label, Y_train_label,\n",
    "    batch_size=batch_size,\n",
    "    nb_epoch=nb_epoch,\n",
    "    shuffle=True)\n",
    "\n",
    "model_1 = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use the model to label unlabeled data\n",
    "Y_train_unlabel_proba = model.predict_proba(X_train_unlabel)  # same as model.predict\n",
    "Y_train_unlabel_uncertainty = np.apply_along_axis(uncertainty, 1, Y_train_unlabel_proba)\n",
    "\n",
    "Y_train_unlabel_class = model.predict_classes(X_train_unlabel)\n",
    "Y_train_unlabel = np_utils.to_categorical(Y_train_unlabel_class, nb_classes)\n",
    "\n",
    "# sort unlabeled data by uncertainty\n",
    "sorted_idxs = Y_train_unlabel_uncertainty.argsort()\n",
    "X_train_unlabel_sorted = X_train_unlabel[sorted_idxs]\n",
    "Y_train_unlabel_sorted = Y_train_unlabel[sorted_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extract_ratio = 0.4\n",
    "\n",
    "# extract high-certainty unlabeled data\n",
    "nb_extract = int(X_train_unlabel.shape[0] * extract_ratio)\n",
    "X_train_unlabel_certain, X_train_unlabel_uncertain = X_train_unlabel_sorted[:nb_extract], X_train_unlabel_sorted[nb_extract:]\n",
    "Y_train_unlabel_certain, Y_train_unlabel_uncertain = Y_train_unlabel_sorted[:nb_extract], Y_train_unlabel_sorted[nb_extract:]\n",
    "\n",
    "# update labelled dataset and unlabeled dataset\n",
    "X_train_label_pool = np.concatenate((X_train_label, X_train_unlabel_certain))\n",
    "Y_train_label_pool = np.concatenate((Y_train_label, Y_train_unlabel_certain))\n",
    "X_train_unlabel_pool = X_train_unlabel_uncertain\n",
    "Y_train_unlabel_pool = Y_train_unlabel_uncertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# second model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=X_train_label.shape[1:], dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), dim_ordering=\"th\", border_mode='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())  # n * 8 * 8, for 64 -> 4096\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_epoch = 30 # int(500000 / X_train_label_pool.shape[0])\n",
    "\n",
    "model.fit(X_train_label_pool, Y_train_label_pool,\n",
    "    batch_size=batch_size,\n",
    "    nb_epoch=nb_epoch,  # nb_epoch,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_second_6464MP6464APS512256128_extr45_epo23_acc8944_5280 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model_name = (METHOD\n",
    "#     + '_second-model'\n",
    "#     + '_filters-64-64-MP-64-64--512'\n",
    "#     + '_add-0.4'\n",
    "#     + '_epo-70' # + str(nb_epoch)\n",
    "#     + '_acc0.8823_0.4868' # + str(val_acc)[:6]\n",
    "# )\n",
    "model_name = \"hw_model_second_128128MP128128APS1024256128\"\n",
    "model.save(MODEL_FOLDER + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = pickle.load(open(TEST_DATA_FILE, 'rb'))  # dict\n",
    "X_test = np.array(test_data['data']).reshape((10000, 3, 32, 32)).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = model.predict_classes(X_test)\n",
    "csv_content = list(zip(test_data['ID'], result.tolist()))\n",
    "np.savetxt(OUTPUT_FOLDER + \"hw_self_model_2_ext0.45_restart\" + \".csv\", csv_content, fmt=\"%i\", header=\"ID,class\", comments=\"\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
