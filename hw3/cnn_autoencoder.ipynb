{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D, UpSampling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "METHOD = 'cnn_autoencoder'\n",
    "\n",
    "LABELLED_DATA_FILE = 'data/all_label.p'\n",
    "UNLABELED_DATA_FILE = 'data/all_unlabel.p'\n",
    "TEST_DATA_FILE = 'data/test.p'\n",
    "\n",
    "OUTPUT_FOLDER = 'output/'\n",
    "MODEL_FOLDER = 'model/' + METHOD + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(MODEL_FOLDER):\n",
    "    os.makedirs(MODEL_FOLDER)\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelled_data = np.array(pickle.load(open(LABELLED_DATA_FILE, 'rb')))\n",
    "unlabeled_data = np.array(pickle.load(open(UNLABELED_DATA_FILE, 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "img_rows, img_cols, img_channels = 32, 32, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate x, y from data\n",
    "\n",
    "# reshape labelled data to (5000, 3, 32, 32)\n",
    "X_train_label = labelled_data.reshape((5000, img_channels, img_rows, img_cols)).astype('float32') / 255\n",
    "\n",
    "# reshape unlabeled data to (45000, 3, 32, 32)\n",
    "nb_unlabeled_data = unlabeled_data.shape[0]\n",
    "X_train_unlabel = unlabeled_data.reshape((nb_unlabeled_data, img_channels, img_rows, img_cols)).astype('float32') / 255\n",
    "\n",
    "X_train_all = np.concatenate((X_train_label, X_train_unlabel))\n",
    "\n",
    "y_train_label_class = np.array([classIdx for classIdx in range(len(labelled_data)) for i in range(len(labelled_data[classIdx]))])\n",
    "Y_train_label = np_utils.to_categorical(y_train_label_class, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: remove\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# X_train_cifar = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_train]) / 255.0\n",
    "X_test_cifar = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_test]) / 255.0\n",
    "Y_test_cifar = np_utils.to_categorical(y_test.flatten(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJrElEQVR4nCXTW29cx2EA4LnPnDm3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\noyQO/gjApWe1WMMl7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FACEC4F9EF0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize\n",
    "from scipy.misc import toimage\n",
    "toimage(X_train_unlabel[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "\n",
    "input_img = Input(shape=(3, 32, 32))\n",
    "\n",
    "x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(input_img)\n",
    "x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(x)\n",
    "x = MaxPooling2D((2, 2), border_mode='same', dim_ordering=\"th\")(x)\n",
    "x = Convolution2D(32, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(x)\n",
    "x = Convolution2D(32, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(x)\n",
    "x = MaxPooling2D((2, 2), border_mode='same', dim_ordering=\"th\")(x)\n",
    "x = Convolution2D(16, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(x)\n",
    "\n",
    "encoded = x\n",
    "\n",
    "x = Convolution2D(16, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(x)\n",
    "x = UpSampling2D((2, 2), dim_ordering=\"th\")(x)\n",
    "x = Convolution2D(32, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(x)\n",
    "x = Convolution2D(32, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(x)\n",
    "x = UpSampling2D((2, 2), dim_ordering=\"th\")(x)\n",
    "x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(x)\n",
    "x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(x)\n",
    "# x = UpSampling2D((2, 2), dim_ordering=\"th\")(x)\n",
    "decoded = Convolution2D(3, 3, 3, activation='sigmoid', border_mode='same', dim_ordering=\"th\")(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_epoch = 5\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 42s - loss: 0.5827    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 41s - loss: 0.5651    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 41s - loss: 0.5616    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 41s - loss: 0.5596    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 40s - loss: 0.5584    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fab8ec60ba8>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train_all, X_train_all,\n",
    "                nb_epoch=nb_epoch,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Model(input=input_img, output=encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_label_encoded = encoder.predict(X_train_label)\n",
    "# TODO: remove cifar\n",
    "X_test_cifar_encoded = encoder.predict(X_test_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_label_decoded = autoencoder.predict(X_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAG80lEQVR4nD2W37NdR3GF1+ruvfc5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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FAB8F7DCE80>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toimage(X_train_label_decoded[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Flatten(input_shape=X_train_label_encoded.shape[1:]))\n",
    "\n",
    "classifier.add(Dense(256))  # 32 * \n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "classifier.add(Dense(256))  # 32 * \n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "classifier.add(Dense(nb_classes))\n",
    "classifier.add(Activation('softmax'))\n",
    "\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "classifier.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 0s - loss: 2.2340 - acc: 0.1838 - val_loss: 2.2140 - val_acc: 0.1902\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 0s - loss: 2.0884 - acc: 0.2394 - val_loss: 2.2016 - val_acc: 0.2038\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 0s - loss: 2.0303 - acc: 0.2624 - val_loss: 2.1979 - val_acc: 0.1922\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.9987 - acc: 0.2806 - val_loss: 2.2487 - val_acc: 0.1990\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.9663 - acc: 0.2960 - val_loss: 2.2906 - val_acc: 0.1994\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.9330 - acc: 0.3058 - val_loss: 2.2514 - val_acc: 0.2075\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.9156 - acc: 0.3168 - val_loss: 2.2800 - val_acc: 0.1958\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.8859 - acc: 0.3240 - val_loss: 2.2412 - val_acc: 0.2069\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.8758 - acc: 0.3324 - val_loss: 2.2918 - val_acc: 0.2078\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.8472 - acc: 0.3436 - val_loss: 2.3074 - val_acc: 0.2161\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.8387 - acc: 0.3452 - val_loss: 2.2675 - val_acc: 0.2052\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.8060 - acc: 0.3548 - val_loss: 2.3266 - val_acc: 0.1902\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.8013 - acc: 0.3510 - val_loss: 2.3393 - val_acc: 0.1911\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.7854 - acc: 0.3572 - val_loss: 2.2761 - val_acc: 0.1946\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.7813 - acc: 0.3608 - val_loss: 2.4203 - val_acc: 0.2035\n",
      "Epoch 16/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.7685 - acc: 0.3740 - val_loss: 2.3775 - val_acc: 0.1911\n",
      "Epoch 17/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.7470 - acc: 0.3812 - val_loss: 2.3580 - val_acc: 0.1926\n",
      "Epoch 18/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.7432 - acc: 0.3736 - val_loss: 2.3382 - val_acc: 0.1900\n",
      "Epoch 19/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.7325 - acc: 0.3780 - val_loss: 2.3087 - val_acc: 0.2031\n",
      "Epoch 20/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.7065 - acc: 0.3974 - val_loss: 2.4341 - val_acc: 0.1926\n",
      "Epoch 21/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.7149 - acc: 0.3892 - val_loss: 2.3600 - val_acc: 0.1867\n",
      "Epoch 22/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.6990 - acc: 0.3830 - val_loss: 2.4764 - val_acc: 0.1942\n",
      "Epoch 23/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.6788 - acc: 0.4030 - val_loss: 2.5606 - val_acc: 0.1832\n",
      "Epoch 24/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.6776 - acc: 0.3986 - val_loss: 2.4545 - val_acc: 0.1873\n",
      "Epoch 25/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.6745 - acc: 0.4002 - val_loss: 2.3863 - val_acc: 0.1967\n",
      "Epoch 26/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.6617 - acc: 0.4092 - val_loss: 2.5338 - val_acc: 0.2056\n",
      "Epoch 27/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.6667 - acc: 0.4034 - val_loss: 2.5963 - val_acc: 0.1899\n",
      "Epoch 28/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.6486 - acc: 0.4088 - val_loss: 2.6193 - val_acc: 0.1953\n",
      "Epoch 29/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.6354 - acc: 0.4208 - val_loss: 2.5551 - val_acc: 0.1969\n",
      "Epoch 30/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.6369 - acc: 0.4172 - val_loss: 2.5454 - val_acc: 0.1935\n",
      "Epoch 31/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.6349 - acc: 0.4072 - val_loss: 2.6738 - val_acc: 0.1863\n",
      "Epoch 32/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.6290 - acc: 0.4236 - val_loss: 2.5556 - val_acc: 0.1989\n",
      "Epoch 33/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.6100 - acc: 0.4286 - val_loss: 2.5339 - val_acc: 0.1957\n",
      "Epoch 34/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.6033 - acc: 0.4316 - val_loss: 2.6549 - val_acc: 0.1928\n",
      "Epoch 35/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5946 - acc: 0.4274 - val_loss: 2.5328 - val_acc: 0.2048\n",
      "Epoch 36/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.6070 - acc: 0.4276 - val_loss: 2.5322 - val_acc: 0.1957\n",
      "Epoch 37/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5898 - acc: 0.4336 - val_loss: 2.6020 - val_acc: 0.1973\n",
      "Epoch 38/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5680 - acc: 0.4374 - val_loss: 2.5515 - val_acc: 0.1929\n",
      "Epoch 39/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5773 - acc: 0.4334 - val_loss: 2.6453 - val_acc: 0.1922\n",
      "Epoch 40/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5506 - acc: 0.4530 - val_loss: 2.7013 - val_acc: 0.1929\n",
      "Epoch 41/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5473 - acc: 0.4424 - val_loss: 2.5900 - val_acc: 0.2035\n",
      "Epoch 42/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5553 - acc: 0.4438 - val_loss: 2.5849 - val_acc: 0.2093\n",
      "Epoch 43/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5470 - acc: 0.4446 - val_loss: 2.6559 - val_acc: 0.2024\n",
      "Epoch 44/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5323 - acc: 0.4518 - val_loss: 2.5791 - val_acc: 0.2007\n",
      "Epoch 45/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5347 - acc: 0.4534 - val_loss: 2.7962 - val_acc: 0.1937\n",
      "Epoch 46/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5574 - acc: 0.4390 - val_loss: 2.7003 - val_acc: 0.1940\n",
      "Epoch 47/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5333 - acc: 0.4454 - val_loss: 2.6241 - val_acc: 0.1945\n",
      "Epoch 48/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5171 - acc: 0.4486 - val_loss: 2.5859 - val_acc: 0.1962\n",
      "Epoch 49/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5252 - acc: 0.4522 - val_loss: 2.6098 - val_acc: 0.2044\n",
      "Epoch 50/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5155 - acc: 0.4610 - val_loss: 2.8181 - val_acc: 0.1919\n",
      "Epoch 51/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5292 - acc: 0.4572 - val_loss: 2.6279 - val_acc: 0.1888\n",
      "Epoch 52/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5078 - acc: 0.4612 - val_loss: 2.5314 - val_acc: 0.2033\n",
      "Epoch 53/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4976 - acc: 0.4686 - val_loss: 2.7095 - val_acc: 0.2086\n",
      "Epoch 54/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4875 - acc: 0.4688 - val_loss: 2.5662 - val_acc: 0.2014\n",
      "Epoch 55/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.5148 - acc: 0.4498 - val_loss: 2.6076 - val_acc: 0.1956\n",
      "Epoch 56/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4779 - acc: 0.4698 - val_loss: 2.6901 - val_acc: 0.2106\n",
      "Epoch 57/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4687 - acc: 0.4774 - val_loss: 2.7912 - val_acc: 0.2025\n",
      "Epoch 58/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4798 - acc: 0.4714 - val_loss: 2.6946 - val_acc: 0.2115\n",
      "Epoch 59/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4684 - acc: 0.4680 - val_loss: 2.8268 - val_acc: 0.2079\n",
      "Epoch 60/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4794 - acc: 0.4686 - val_loss: 2.6187 - val_acc: 0.2094\n",
      "Epoch 61/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4584 - acc: 0.4754 - val_loss: 2.7540 - val_acc: 0.1937\n",
      "Epoch 62/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4711 - acc: 0.4744 - val_loss: 2.6816 - val_acc: 0.2102\n",
      "Epoch 63/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4603 - acc: 0.4820 - val_loss: 2.6799 - val_acc: 0.2019\n",
      "Epoch 64/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4561 - acc: 0.4708 - val_loss: 2.8086 - val_acc: 0.2002\n",
      "Epoch 65/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4562 - acc: 0.4772 - val_loss: 2.7492 - val_acc: 0.2061\n",
      "Epoch 66/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4333 - acc: 0.4880 - val_loss: 2.8402 - val_acc: 0.2002\n",
      "Epoch 67/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4379 - acc: 0.4858 - val_loss: 2.7802 - val_acc: 0.2005\n",
      "Epoch 68/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4387 - acc: 0.4856 - val_loss: 2.7012 - val_acc: 0.1935\n",
      "Epoch 69/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4411 - acc: 0.4856 - val_loss: 2.8135 - val_acc: 0.2032\n",
      "Epoch 70/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4169 - acc: 0.4852 - val_loss: 2.6988 - val_acc: 0.2003\n",
      "Epoch 71/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4239 - acc: 0.4844 - val_loss: 2.8255 - val_acc: 0.2045\n",
      "Epoch 72/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4131 - acc: 0.5050 - val_loss: 2.9935 - val_acc: 0.1965\n",
      "Epoch 73/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4214 - acc: 0.4878 - val_loss: 2.8074 - val_acc: 0.2079\n",
      "Epoch 74/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4260 - acc: 0.4780 - val_loss: 2.9930 - val_acc: 0.1953\n",
      "Epoch 75/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4194 - acc: 0.4974 - val_loss: 2.7318 - val_acc: 0.2080\n",
      "Epoch 76/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4126 - acc: 0.4936 - val_loss: 2.7817 - val_acc: 0.2061\n",
      "Epoch 77/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4020 - acc: 0.5044 - val_loss: 2.8246 - val_acc: 0.2018\n",
      "Epoch 78/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4048 - acc: 0.4898 - val_loss: 2.9040 - val_acc: 0.1999\n",
      "Epoch 79/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4064 - acc: 0.4972 - val_loss: 2.7439 - val_acc: 0.2035\n",
      "Epoch 80/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.4084 - acc: 0.4960 - val_loss: 2.8779 - val_acc: 0.2044\n",
      "Epoch 81/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3760 - acc: 0.5032 - val_loss: 2.9561 - val_acc: 0.2055\n",
      "Epoch 82/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3970 - acc: 0.4968 - val_loss: 2.8183 - val_acc: 0.2052\n",
      "Epoch 83/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3730 - acc: 0.5042 - val_loss: 2.7527 - val_acc: 0.2136\n",
      "Epoch 84/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3656 - acc: 0.5112 - val_loss: 3.1075 - val_acc: 0.1954\n",
      "Epoch 85/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3552 - acc: 0.5094 - val_loss: 2.8644 - val_acc: 0.2104\n",
      "Epoch 86/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3672 - acc: 0.5116 - val_loss: 2.7436 - val_acc: 0.2064\n",
      "Epoch 87/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3677 - acc: 0.5076 - val_loss: 2.8919 - val_acc: 0.2074\n",
      "Epoch 88/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3722 - acc: 0.5112 - val_loss: 2.9055 - val_acc: 0.2016\n",
      "Epoch 89/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3631 - acc: 0.5154 - val_loss: 2.9542 - val_acc: 0.2068\n",
      "Epoch 90/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3441 - acc: 0.5158 - val_loss: 2.8929 - val_acc: 0.2055\n",
      "Epoch 91/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3612 - acc: 0.5108 - val_loss: 2.9140 - val_acc: 0.2061\n",
      "Epoch 92/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3364 - acc: 0.5196 - val_loss: 3.0365 - val_acc: 0.2130\n",
      "Epoch 93/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3384 - acc: 0.5194 - val_loss: 2.9419 - val_acc: 0.2043\n",
      "Epoch 94/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3499 - acc: 0.5170 - val_loss: 3.0778 - val_acc: 0.2058\n",
      "Epoch 95/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3329 - acc: 0.5186 - val_loss: 2.8863 - val_acc: 0.2023\n",
      "Epoch 96/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3211 - acc: 0.5212 - val_loss: 2.8803 - val_acc: 0.2109\n",
      "Epoch 97/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3325 - acc: 0.5254 - val_loss: 2.9728 - val_acc: 0.2013\n",
      "Epoch 98/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3242 - acc: 0.5200 - val_loss: 2.9824 - val_acc: 0.2052\n",
      "Epoch 99/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.2996 - acc: 0.5382 - val_loss: 3.3446 - val_acc: 0.2009\n",
      "Epoch 100/100\n",
      "5000/5000 [==============================] - 0s - loss: 1.3233 - acc: 0.5232 - val_loss: 3.1608 - val_acc: 0.2013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fab8f3562e8>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_label_encoded, Y_train_label,\n",
    "    batch_size=batch_size,\n",
    "    nb_epoch=nb_epoch,  # nb_epoch,\n",
    "    validation_data=(X_test_cifar_encoded, Y_test_cifar),\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_train_label_class_predict = model.predict_classes(X_train_ori_label, batch_size=5000)\n",
    "val_acc = np.sum(Y_train_label_class_predict == y_train_label_class) / float(len(y_train_label_class))\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = (METHOD\n",
    "    + '_filters-64x3x3-64x3x3-512'\n",
    "    + '_epo-100x5' # + str(nb_epoch)\n",
    "    + '_val-acc-' + str(val_acc)[:6]\n",
    ")\n",
    "model.save(MODEL_FOLDER + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = pickle.load(open(TEST_DATA_FILE, 'rb'))  # dict\n",
    "X_test = np.array(test_data['data']).reshape((10000, 3, 32, 32)).astype('float32')\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = model.predict_classes(X_test, batch_size=10000)\n",
    "csv_content = list(zip(test_data['ID'], result.tolist()))\n",
    "np.savetxt(OUTPUT_FOLDER + model_name + \".csv\", csv_content, fmt=\"%i\", header=\"ID,class\", comments=\"\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_reshaped = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_train])\n",
    "X_test_reshaped = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_test_class_predict = model.predict_classes(X_test_reshaped, batch_size=10000)\n",
    "np.sum(Y_test_class_predict == y_test.flatten()) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train_class_predict = model.predict_classes(X_train_reshaped, batch_size=10000)\n",
    "np.sum(Y_train_class_predict == y_train.flatten()) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toimage(X_train_reshaped[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train_class_predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toimage(X_train_reshaped[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
