{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# stops = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLUSTER_COUNT = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "METHOD = \"word2vec\"\n",
    "\n",
    "DATA_FOLDER = \"data/\"\n",
    "OUTPUT_FOLDER = \"output/\"\n",
    "MODEL_FOLDER = \"model/\"\n",
    "\n",
    "TITLE_FILE = DATA_FOLDER + \"title_StackOverflow.txt\"\n",
    "CHECK_INDEX_FILE = DATA_FOLDER + \"check_index.csv\"\n",
    "DOCS_FILE = DATA_FOLDER + \"docs.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "if not os.path.exists(MODEL_FOLDER):\n",
    "    os.makedirs(MODEL_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def isUselessLine(line):\n",
    "    # number of chars < 10\n",
    "    # number of words < 3\n",
    "    # start with whitespaces (usually are codes)\n",
    "    return (len(line) < 10) or (len(line.split()) < 3) or (line[0] == ' ')\n",
    "\n",
    "def lineToCleanWordSeqs(line):\n",
    "    # return a list of word sequences.\n",
    "    # e.g. [[\"i\", \"have\", \"an\", \"apple\"], [\"i\", \"have\", \"a\", \"pen\"]]\n",
    "    \n",
    "    # remove urls\n",
    "    line = re.sub(r\"\\S+:/\\S+\",\"\", line)  # \".../...\"\n",
    "    line = re.sub(r\"\\S+\\\\\\S+\",\"\", line)  # \"...\\...\"\n",
    "    \n",
    "    if isUselessLine(line):\n",
    "        return []\n",
    "    \n",
    "    sentences = tokenizer.tokenize(line)\n",
    "    wordSeqs = []\n",
    "    for s in sentences:\n",
    "        wordSeq = re.sub(r\"[^a-zA-Z]\",\" \", s).lower().split()\n",
    "        if len(wordSeq) >= 3:\n",
    "            wordSeqs.append(wordSeq)\n",
    "    return wordSeqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_word_seqs = []\n",
    "\n",
    "with open(DOCS_FILE, 'r') as f:\n",
    "    for line in f.read().splitlines():\n",
    "        clean_word_seqs.extend(lineToCleanWordSeqs(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115258"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_word_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['how',\n",
       "  'do',\n",
       "  'you',\n",
       "  'expose',\n",
       "  'a',\n",
       "  'linq',\n",
       "  'query',\n",
       "  'as',\n",
       "  'an',\n",
       "  'asmx',\n",
       "  'web',\n",
       "  'service'],\n",
       " ['usually',\n",
       "  'from',\n",
       "  'the',\n",
       "  'business',\n",
       "  'tier',\n",
       "  'i',\n",
       "  'can',\n",
       "  'return',\n",
       "  'a',\n",
       "  'typed',\n",
       "  'dataset',\n",
       "  'or',\n",
       "  'datatable',\n",
       "  'which',\n",
       "  'can',\n",
       "  'be',\n",
       "  'serialized',\n",
       "  'for',\n",
       "  'transport',\n",
       "  'over',\n",
       "  'asmx'],\n",
       " ['how', 'can', 'i', 'do', 'the', 'same', 'for', 'a', 'linq', 'query'],\n",
       " ['is',\n",
       "  'there',\n",
       "  'a',\n",
       "  'way',\n",
       "  'to',\n",
       "  'populate',\n",
       "  'a',\n",
       "  'typed',\n",
       "  'dataset',\n",
       "  'or',\n",
       "  'datatable',\n",
       "  'via',\n",
       "  'a',\n",
       "  'linq',\n",
       "  'query'],\n",
       " ['how',\n",
       "  'can',\n",
       "  'i',\n",
       "  'get',\n",
       "  'the',\n",
       "  'resultset',\n",
       "  'of',\n",
       "  'a',\n",
       "  'linq',\n",
       "  'query',\n",
       "  'into',\n",
       "  'a',\n",
       "  'dataset',\n",
       "  'or',\n",
       "  'datatable'],\n",
       " ['alternatively',\n",
       "  'is',\n",
       "  'the',\n",
       "  'linq',\n",
       "  'query',\n",
       "  'serializeable',\n",
       "  'so',\n",
       "  'that',\n",
       "  'i',\n",
       "  'can',\n",
       "  'expose',\n",
       "  'it',\n",
       "  'as',\n",
       "  'an',\n",
       "  'asmx',\n",
       "  'web',\n",
       "  'service'],\n",
       " ['how',\n",
       "  'do',\n",
       "  'you',\n",
       "  'page',\n",
       "  'through',\n",
       "  'a',\n",
       "  'collection',\n",
       "  'in',\n",
       "  'linq',\n",
       "  'given',\n",
       "  'that',\n",
       "  'you',\n",
       "  'have',\n",
       "  'a',\n",
       "  'startindex',\n",
       "  'and',\n",
       "  'a',\n",
       "  'count'],\n",
       " ['i',\n",
       "  've',\n",
       "  'been',\n",
       "  'using',\n",
       "  'tortoisesvn',\n",
       "  'in',\n",
       "  'a',\n",
       "  'windows',\n",
       "  'environment',\n",
       "  'for',\n",
       "  'quite',\n",
       "  'some',\n",
       "  'time'],\n",
       " ['it',\n",
       "  'seems',\n",
       "  'very',\n",
       "  'feature',\n",
       "  'complete',\n",
       "  'and',\n",
       "  'nicely',\n",
       "  'integrated',\n",
       "  'into',\n",
       "  'the',\n",
       "  'windows',\n",
       "  'shell',\n",
       "  'and',\n",
       "  'more',\n",
       "  'importantly',\n",
       "  'it',\n",
       "  's',\n",
       "  'fairly',\n",
       "  'painless',\n",
       "  'to',\n",
       "  'teach',\n",
       "  'to',\n",
       "  'colleagues',\n",
       "  'with',\n",
       "  'little',\n",
       "  'or',\n",
       "  'no',\n",
       "  'experience',\n",
       "  'with',\n",
       "  'source',\n",
       "  'control'],\n",
       " ['however',\n",
       "  'since',\n",
       "  'we',\n",
       "  'have',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'windows',\n",
       "  'vista',\n",
       "  'bit',\n",
       "  'tortoise',\n",
       "  'has',\n",
       "  'been',\n",
       "  'very',\n",
       "  'buggy',\n",
       "  'and',\n",
       "  'has',\n",
       "  'seemed',\n",
       "  'to',\n",
       "  'cause',\n",
       "  'lots',\n",
       "  'of',\n",
       "  'explorer',\n",
       "  'exe',\n",
       "  'abnormalities',\n",
       "  'and',\n",
       "  'crashes'],\n",
       " ['this',\n",
       "  'has',\n",
       "  'happened',\n",
       "  'both',\n",
       "  'with',\n",
       "  'older',\n",
       "  'versions',\n",
       "  'of',\n",
       "  'the',\n",
       "  'software',\n",
       "  'and',\n",
       "  'the',\n",
       "  'latest',\n",
       "  'version',\n",
       "  'build'],\n",
       " ['i',\n",
       "  'was',\n",
       "  'curious',\n",
       "  'if',\n",
       "  'anyone',\n",
       "  'has',\n",
       "  'suggestions',\n",
       "  'for',\n",
       "  'other',\n",
       "  'subversion',\n",
       "  'clients',\n",
       "  'that',\n",
       "  'will',\n",
       "  'run',\n",
       "  'on',\n",
       "  'windows',\n",
       "  'specifically',\n",
       "  'vista',\n",
       "  'bit'],\n",
       " ['developers',\n",
       "  'here',\n",
       "  'use',\n",
       "  'a',\n",
       "  'variety',\n",
       "  'of',\n",
       "  'text',\n",
       "  'editors',\n",
       "  'so',\n",
       "  'using',\n",
       "  'visual',\n",
       "  'studio',\n",
       "  'or',\n",
       "  'dreamweaver',\n",
       "  'for',\n",
       "  'svn',\n",
       "  'is',\n",
       "  'not',\n",
       "  'ideal'],\n",
       " ['i',\n",
       "  'have',\n",
       "  'heard',\n",
       "  'great',\n",
       "  'things',\n",
       "  'about',\n",
       "  'cornerstone',\n",
       "  'and',\n",
       "  'would',\n",
       "  'love',\n",
       "  'something',\n",
       "  'similar',\n",
       "  'for',\n",
       "  'windows',\n",
       "  'if',\n",
       "  'it',\n",
       "  'exists'],\n",
       " ['what',\n",
       "  'are',\n",
       "  'the',\n",
       "  'best',\n",
       "  'practices',\n",
       "  'for',\n",
       "  'checking',\n",
       "  'in',\n",
       "  'bin',\n",
       "  'directories',\n",
       "  'in',\n",
       "  'a',\n",
       "  'collaborative',\n",
       "  'development',\n",
       "  'environment',\n",
       "  'using',\n",
       "  'svn'],\n",
       " ['should',\n",
       "  'project',\n",
       "  'level',\n",
       "  'references',\n",
       "  'be',\n",
       "  'excluded',\n",
       "  'from',\n",
       "  'checkin'],\n",
       " ['is', 'it', 'easier', 'to', 'just', 'add', 'all', 'bin', 'directories'],\n",
       " ['i',\n",
       "  'develop',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'dotnetnuke',\n",
       "  'sites',\n",
       "  'and',\n",
       "  'it',\n",
       "  'seems',\n",
       "  'that',\n",
       "  'in',\n",
       "  'a',\n",
       "  'multi',\n",
       "  'developer',\n",
       "  'environment',\n",
       "  'it',\n",
       "  's',\n",
       "  'always',\n",
       "  'a',\n",
       "  'huge',\n",
       "  'task',\n",
       "  'to',\n",
       "  'get',\n",
       "  'the',\n",
       "  'environment',\n",
       "  'setup',\n",
       "  'correctly'],\n",
       " ['the',\n",
       "  'ultimate',\n",
       "  'goal',\n",
       "  'of',\n",
       "  'course',\n",
       "  'is',\n",
       "  'to',\n",
       "  'have',\n",
       "  'a',\n",
       "  'new',\n",
       "  'developer',\n",
       "  'checkout',\n",
       "  'the',\n",
       "  'trunk',\n",
       "  'from',\n",
       "  'svn',\n",
       "  'restore',\n",
       "  'the',\n",
       "  'dnn',\n",
       "  'database',\n",
       "  'and',\n",
       "  'have',\n",
       "  'it',\n",
       "  'all',\n",
       "  'just',\n",
       "  'work'],\n",
       " ['i',\n",
       "  'm',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'maintain',\n",
       "  'a',\n",
       "  'setup',\n",
       "  'project',\n",
       "  'in',\n",
       "  'visual',\n",
       "  'studio',\n",
       "  'yes',\n",
       "  'it',\n",
       "  's',\n",
       "  'a',\n",
       "  'legacy',\n",
       "  'application'],\n",
       " ['the',\n",
       "  'problem',\n",
       "  'we',\n",
       "  'have',\n",
       "  'at',\n",
       "  'the',\n",
       "  'moment',\n",
       "  'is',\n",
       "  'that',\n",
       "  'we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'write',\n",
       "  'registry',\n",
       "  'entries',\n",
       "  'to',\n",
       "  'hkcu',\n",
       "  'for',\n",
       "  'every',\n",
       "  'user',\n",
       "  'on',\n",
       "  'the',\n",
       "  'computer'],\n",
       " ['they',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'in',\n",
       "  'the',\n",
       "  'hkcu',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'hklm',\n",
       "  'because',\n",
       "  'they',\n",
       "  'are',\n",
       "  'the',\n",
       "  'default',\n",
       "  'user',\n",
       "  'settings',\n",
       "  'and',\n",
       "  'do',\n",
       "  'change',\n",
       "  'per',\n",
       "  'user'],\n",
       " ['my', 'feeling', 'is', 'that'],\n",
       " ['with',\n",
       "  'that',\n",
       "  'in',\n",
       "  'mind',\n",
       "  'i',\n",
       "  'still',\n",
       "  'want',\n",
       "  'to',\n",
       "  'change',\n",
       "  'as',\n",
       "  'little',\n",
       "  'as',\n",
       "  'possible',\n",
       "  'in',\n",
       "  'the',\n",
       "  'application',\n",
       "  'so',\n",
       "  'my',\n",
       "  'question',\n",
       "  'is',\n",
       "  'is',\n",
       "  'possible',\n",
       "  'to',\n",
       "  'add',\n",
       "  'registry',\n",
       "  'entries',\n",
       "  'for',\n",
       "  'every',\n",
       "  'user',\n",
       "  'in',\n",
       "  'a',\n",
       "  'visual',\n",
       "  'studio',\n",
       "  'setup',\n",
       "  'project'],\n",
       " ['and',\n",
       "  'at',\n",
       "  'the',\n",
       "  'moment',\n",
       "  'the',\n",
       "  'project',\n",
       "  'lists',\n",
       "  'five',\n",
       "  'registry',\n",
       "  'root',\n",
       "  'keys',\n",
       "  'hkey',\n",
       "  'classes',\n",
       "  'root',\n",
       "  'hkey',\n",
       "  'current',\n",
       "  'user',\n",
       "  'hkey',\n",
       "  'local',\n",
       "  'machine',\n",
       "  'hkey',\n",
       "  'users',\n",
       "  'and',\n",
       "  'user',\n",
       "  'machine',\n",
       "  'hive',\n",
       "  'i',\n",
       "  'don',\n",
       "  't',\n",
       "  'really',\n",
       "  'know',\n",
       "  'anything',\n",
       "  'about',\n",
       "  'the',\n",
       "  'users',\n",
       "  'root',\n",
       "  'key',\n",
       "  'and',\n",
       "  'haven',\n",
       "  't',\n",
       "  'seen',\n",
       "  'user',\n",
       "  'machine',\n",
       "  'hive'],\n",
       " ['can', 'anyone', 'enlighten', 'me', 'on', 'what', 'they', 'are'],\n",
       " ['perhapes', 'they', 'could', 'solve', 'my', 'problem', 'above'],\n",
       " ['is',\n",
       "  'there',\n",
       "  'an',\n",
       "  'easy',\n",
       "  'way',\n",
       "  'to',\n",
       "  'produce',\n",
       "  'msdn',\n",
       "  'style',\n",
       "  'documentation',\n",
       "  'from',\n",
       "  'the',\n",
       "  'visual',\n",
       "  'studio',\n",
       "  'xml',\n",
       "  'output'],\n",
       " ['i',\n",
       "  'm',\n",
       "  'not',\n",
       "  'patient',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'set',\n",
       "  'up',\n",
       "  'a',\n",
       "  'good',\n",
       "  'xslt',\n",
       "  'for',\n",
       "  'it',\n",
       "  'because',\n",
       "  'i',\n",
       "  'know',\n",
       "  'i',\n",
       "  'm',\n",
       "  'not',\n",
       "  'the',\n",
       "  'first',\n",
       "  'person',\n",
       "  'to',\n",
       "  'cross',\n",
       "  'this',\n",
       "  'bridge'],\n",
       " ['also',\n",
       "  'i',\n",
       "  'tried',\n",
       "  'setting',\n",
       "  'up',\n",
       "  'sandcastle',\n",
       "  'recently',\n",
       "  'but',\n",
       "  'it',\n",
       "  'really',\n",
       "  'made',\n",
       "  'my',\n",
       "  'eyes',\n",
       "  'cross']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineIdx = 0\n",
    "clean_word_seqs[lineIdx:lineIdx+30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Title Data and add to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentenceToCleanWordSeqs(s):\n",
    "    return re.sub(\"[^a-zA-Z]\", \" \", s).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(TITLE_FILE) as f:\n",
    "    titles = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_title_word_seqs = [sentenceToCleanWordSeqs(title) for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_word_seqs.extend(clean_title_word_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135258"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_word_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Set values for various parameters\n",
    "num_features = 1000    # Word vector dimensionality                      \n",
    "min_word_count = 10   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "num_iter = 10\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(clean_word_seqs, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling, iter=num_iter)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = 'w2v_with-title_{}feature_{}minwords_{}iter'.format(num_features, min_word_count, num_iter)\n",
    "model.save(MODEL_FOLDER + model_name)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6344, 1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hql', 0.6585182547569275),\n",
       " ('predicate', 0.6009401082992554),\n",
       " ('criteria', 0.5546219348907471),\n",
       " ('caml', 0.5519425868988037),\n",
       " ('hibernate', 0.5207352638244629),\n",
       " ('linqtosql', 0.5176195502281189),\n",
       " ('orderby', 0.5139288902282715),\n",
       " ('subquery', 0.48453181982040405),\n",
       " ('iqueryable', 0.48244035243988037),\n",
       " ('lambda', 0.47810477018356323)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"linq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vba', 0.5704120397567749),\n",
       " ('automation', 0.5156331062316895),\n",
       " ('macros', 0.5053470134735107),\n",
       " ('excel', 0.4900357127189636),\n",
       " ('conditional', 0.47260475158691406),\n",
       " ('udf', 0.4654103219509125),\n",
       " ('formula', 0.46455878019332886),\n",
       " ('vsto', 0.4503313899040222),\n",
       " ('word', 0.41569530963897705),\n",
       " ('vb', 0.4061427116394043)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"sql\", \"macro\"], negative=[\"database\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
