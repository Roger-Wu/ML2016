{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELLED_DATA_FILE = 'data/all_label.p'\n",
    "UNLABELED_DATA_FILE = 'data/all_unlabel.p'\n",
    "TEST_DATA_FILE = 'data/test.p'\n",
    "\n",
    "METHOD = 'cnn_supervised'\n",
    "\n",
    "OUTPUT_FOLDER = 'output/'\n",
    "MODEL_FOLDER = 'model/' + METHOD + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(MODEL_FOLDER):\n",
    "    os.makedirs(MODEL_FOLDER)\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelled_data = np.array(pickle.load(open(LABELLED_DATA_FILE, 'rb')))\n",
    "# unlabeled_data = np.array(pickle.load(open(UNLABELED_DATA_FILE, 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate x, y from data\n",
    "X_train_label = labelled_data.reshape((5000, 3, 32, 32)).astype('float32') / 255\n",
    "\n",
    "y_train_label_class = np.array([classIdx for classIdx in range(len(labelled_data)) for i in range(len(labelled_data[classIdx]))])\n",
    "Y_train_label = np_utils.to_categorical(y_train_label_class, len(labelled_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAIpUlEQVR4nC2VS49cZxmE67183znd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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F56386D6208>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.misc import toimage\n",
    "toimage(X_train_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: remove\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# X_train_reshaped = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_train]) / 255.0\n",
    "X_test_cifar = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_test]) / 255.0\n",
    "Y_test_cifar = np_utils.to_categorical(y_test.flatten(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_classes = 10\n",
    "nb_epoch = 100\n",
    "img_rows, img_cols, img_channels = 32, 32, 3\n",
    "# nb_filters = [32, 64]\n",
    "# nb_nodes = [512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=X_train_label.shape[1:], dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "# model.add(Activation('relu'))\n",
    "# # model.add(Convolution2D(64, 3, 3))\n",
    "# # model.add(Activation('relu'))\n",
    "# model.add(AveragePooling2D(pool_size=(2, 2), dim_ordering=\"th\", border_mode='same'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), dim_ordering=\"th\", border_mode='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), dim_ordering=\"th\", border_mode='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(AveragePooling2D(pool_size=(2, 2), dim_ordering=\"th\", border_mode='same'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())  # n * 8 * 8, for 64 -> 4096\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6990 - acc: 0.7672 - val_loss: 1.9000 - val_acc: 0.4695\n",
      "Epoch 2/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6751 - acc: 0.7758 - val_loss: 1.7678 - val_acc: 0.4974\n",
      "Epoch 3/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.7039 - acc: 0.7658 - val_loss: 1.8487 - val_acc: 0.4844\n",
      "Epoch 4/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6957 - acc: 0.7688 - val_loss: 1.7480 - val_acc: 0.4941\n",
      "Epoch 5/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6788 - acc: 0.7688 - val_loss: 1.8742 - val_acc: 0.4862\n",
      "Epoch 6/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6743 - acc: 0.7726 - val_loss: 1.8479 - val_acc: 0.4923\n",
      "Epoch 7/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6642 - acc: 0.7732 - val_loss: 1.7778 - val_acc: 0.4992\n",
      "Epoch 8/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6842 - acc: 0.7776 - val_loss: 1.8984 - val_acc: 0.4760\n",
      "Epoch 9/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6805 - acc: 0.7722 - val_loss: 1.7952 - val_acc: 0.4869\n",
      "Epoch 10/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.7595 - acc: 0.7396 - val_loss: 1.7736 - val_acc: 0.4920\n",
      "Epoch 11/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6590 - acc: 0.7798 - val_loss: 1.7967 - val_acc: 0.5076\n",
      "Epoch 12/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.7065 - acc: 0.7620 - val_loss: 1.7793 - val_acc: 0.4990\n",
      "Epoch 13/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6880 - acc: 0.7734 - val_loss: 1.7454 - val_acc: 0.5062\n",
      "Epoch 14/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6912 - acc: 0.7634 - val_loss: 1.8166 - val_acc: 0.4921\n",
      "Epoch 15/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6606 - acc: 0.7768 - val_loss: 1.8306 - val_acc: 0.4887\n",
      "Epoch 16/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6798 - acc: 0.7738 - val_loss: 1.7089 - val_acc: 0.5044\n",
      "Epoch 17/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6758 - acc: 0.7764 - val_loss: 1.7810 - val_acc: 0.4963\n",
      "Epoch 18/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6689 - acc: 0.7708 - val_loss: 1.7704 - val_acc: 0.5012\n",
      "Epoch 19/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.7007 - acc: 0.7604 - val_loss: 1.7369 - val_acc: 0.5022\n",
      "Epoch 20/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6873 - acc: 0.7728 - val_loss: 1.8360 - val_acc: 0.4867\n",
      "Epoch 21/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.7268 - acc: 0.7540 - val_loss: 1.9781 - val_acc: 0.4657\n",
      "Epoch 22/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6537 - acc: 0.7840 - val_loss: 2.0252 - val_acc: 0.4596\n",
      "Epoch 23/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6608 - acc: 0.7772 - val_loss: 1.8585 - val_acc: 0.4930\n",
      "Epoch 24/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6757 - acc: 0.7718 - val_loss: 2.0146 - val_acc: 0.4639\n",
      "Epoch 25/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6641 - acc: 0.7758 - val_loss: 1.8474 - val_acc: 0.4854\n",
      "Epoch 26/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6596 - acc: 0.7742 - val_loss: 1.7526 - val_acc: 0.5043\n",
      "Epoch 27/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6748 - acc: 0.7792 - val_loss: 1.8763 - val_acc: 0.4813\n",
      "Epoch 28/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6649 - acc: 0.7760 - val_loss: 2.0720 - val_acc: 0.4673\n",
      "Epoch 29/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6607 - acc: 0.7782 - val_loss: 1.8391 - val_acc: 0.4902\n",
      "Epoch 30/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6705 - acc: 0.7648 - val_loss: 1.8000 - val_acc: 0.5089\n",
      "Epoch 31/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6591 - acc: 0.7844 - val_loss: 1.8241 - val_acc: 0.4968\n",
      "Epoch 32/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6777 - acc: 0.7794 - val_loss: 1.8066 - val_acc: 0.4873\n",
      "Epoch 33/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6404 - acc: 0.7890 - val_loss: 1.7893 - val_acc: 0.5062\n",
      "Epoch 34/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6813 - acc: 0.7692 - val_loss: 1.7223 - val_acc: 0.5127\n",
      "Epoch 35/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6431 - acc: 0.7862 - val_loss: 1.7864 - val_acc: 0.5051\n",
      "Epoch 36/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6711 - acc: 0.7776 - val_loss: 1.7422 - val_acc: 0.5022\n",
      "Epoch 37/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6758 - acc: 0.7688 - val_loss: 1.7133 - val_acc: 0.5217\n",
      "Epoch 38/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6630 - acc: 0.7766 - val_loss: 1.7944 - val_acc: 0.4987\n",
      "Epoch 39/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6849 - acc: 0.7690 - val_loss: 1.6764 - val_acc: 0.5166\n",
      "Epoch 40/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6732 - acc: 0.7778 - val_loss: 1.7821 - val_acc: 0.4914\n",
      "Epoch 41/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6736 - acc: 0.7730 - val_loss: 1.9302 - val_acc: 0.4890\n",
      "Epoch 42/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6895 - acc: 0.7672 - val_loss: 1.8047 - val_acc: 0.4962\n",
      "Epoch 43/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6778 - acc: 0.7716 - val_loss: 1.8747 - val_acc: 0.4839\n",
      "Epoch 44/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6452 - acc: 0.7840 - val_loss: 1.8215 - val_acc: 0.5011\n",
      "Epoch 45/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6494 - acc: 0.7824 - val_loss: 1.8775 - val_acc: 0.4911\n",
      "Epoch 46/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6369 - acc: 0.7874 - val_loss: 1.7853 - val_acc: 0.5060\n",
      "Epoch 47/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6699 - acc: 0.7696 - val_loss: 1.9037 - val_acc: 0.4761\n",
      "Epoch 48/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6628 - acc: 0.7814 - val_loss: 1.8318 - val_acc: 0.5037\n",
      "Epoch 49/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6534 - acc: 0.7830 - val_loss: 1.8031 - val_acc: 0.4975\n",
      "Epoch 50/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6625 - acc: 0.7860 - val_loss: 1.7775 - val_acc: 0.4930\n",
      "Epoch 51/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6591 - acc: 0.7808 - val_loss: 1.7800 - val_acc: 0.5085\n",
      "Epoch 52/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6876 - acc: 0.7662 - val_loss: 1.8519 - val_acc: 0.4808\n",
      "Epoch 53/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6602 - acc: 0.7742 - val_loss: 1.7567 - val_acc: 0.5070\n",
      "Epoch 54/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6759 - acc: 0.7790 - val_loss: 1.7906 - val_acc: 0.4993\n",
      "Epoch 55/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.7079 - acc: 0.7602 - val_loss: 1.8489 - val_acc: 0.4817\n",
      "Epoch 56/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6490 - acc: 0.7756 - val_loss: 1.7508 - val_acc: 0.5074\n",
      "Epoch 57/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6567 - acc: 0.7758 - val_loss: 1.8134 - val_acc: 0.5000\n",
      "Epoch 58/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6580 - acc: 0.7844 - val_loss: 1.7774 - val_acc: 0.4943\n",
      "Epoch 59/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6832 - acc: 0.7744 - val_loss: 1.7576 - val_acc: 0.5039\n",
      "Epoch 60/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6745 - acc: 0.7702 - val_loss: 1.8562 - val_acc: 0.4788\n",
      "Epoch 61/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6526 - acc: 0.7750 - val_loss: 1.7019 - val_acc: 0.5185\n",
      "Epoch 62/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6513 - acc: 0.7790 - val_loss: 1.7810 - val_acc: 0.5188\n",
      "Epoch 63/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6675 - acc: 0.7694 - val_loss: 1.8243 - val_acc: 0.4954\n",
      "Epoch 64/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6730 - acc: 0.7770 - val_loss: 1.8646 - val_acc: 0.4764\n",
      "Epoch 65/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6517 - acc: 0.7876 - val_loss: 1.8010 - val_acc: 0.5010\n",
      "Epoch 66/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6619 - acc: 0.7704 - val_loss: 1.7581 - val_acc: 0.4999\n",
      "Epoch 67/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6757 - acc: 0.7704 - val_loss: 1.9263 - val_acc: 0.4853\n",
      "Epoch 68/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6401 - acc: 0.7850 - val_loss: 1.9385 - val_acc: 0.4894\n",
      "Epoch 69/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6879 - acc: 0.7784 - val_loss: 1.7613 - val_acc: 0.4959\n",
      "Epoch 70/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6294 - acc: 0.7872 - val_loss: 1.9311 - val_acc: 0.4775\n",
      "Epoch 71/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6964 - acc: 0.7710 - val_loss: 1.7066 - val_acc: 0.5062\n",
      "Epoch 72/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6613 - acc: 0.7718 - val_loss: 1.7899 - val_acc: 0.4949\n",
      "Epoch 73/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6407 - acc: 0.7778 - val_loss: 1.8364 - val_acc: 0.4884\n",
      "Epoch 74/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6800 - acc: 0.7746 - val_loss: 1.7255 - val_acc: 0.5049\n",
      "Epoch 75/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6459 - acc: 0.7820 - val_loss: 1.8142 - val_acc: 0.4986\n",
      "Epoch 76/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6731 - acc: 0.7694 - val_loss: 1.8552 - val_acc: 0.4897\n",
      "Epoch 77/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6538 - acc: 0.7848 - val_loss: 1.7492 - val_acc: 0.5015\n",
      "Epoch 78/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6891 - acc: 0.7680 - val_loss: 1.6787 - val_acc: 0.5128\n",
      "Epoch 79/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6670 - acc: 0.7690 - val_loss: 1.9223 - val_acc: 0.4807\n",
      "Epoch 80/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6600 - acc: 0.7774 - val_loss: 1.8758 - val_acc: 0.4684\n",
      "Epoch 81/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6699 - acc: 0.7756 - val_loss: 1.7914 - val_acc: 0.4903\n",
      "Epoch 82/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6261 - acc: 0.7928 - val_loss: 1.7697 - val_acc: 0.5087\n",
      "Epoch 83/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6751 - acc: 0.7756 - val_loss: 1.7688 - val_acc: 0.5027\n",
      "Epoch 84/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6927 - acc: 0.7698 - val_loss: 1.7600 - val_acc: 0.4996\n",
      "Epoch 85/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6524 - acc: 0.7832 - val_loss: 1.8972 - val_acc: 0.4768\n",
      "Epoch 86/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.7048 - acc: 0.7666 - val_loss: 1.7245 - val_acc: 0.5030\n",
      "Epoch 87/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6582 - acc: 0.7844 - val_loss: 1.7428 - val_acc: 0.5056\n",
      "Epoch 88/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6514 - acc: 0.7758 - val_loss: 1.8525 - val_acc: 0.4998\n",
      "Epoch 89/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6300 - acc: 0.7842 - val_loss: 1.8116 - val_acc: 0.5078\n",
      "Epoch 90/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6430 - acc: 0.7802 - val_loss: 1.7159 - val_acc: 0.5031\n",
      "Epoch 91/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6965 - acc: 0.7688 - val_loss: 1.7055 - val_acc: 0.4952\n",
      "Epoch 92/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6446 - acc: 0.7804 - val_loss: 1.7469 - val_acc: 0.5103\n",
      "Epoch 93/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.7015 - acc: 0.7658 - val_loss: 1.8085 - val_acc: 0.4925\n",
      "Epoch 94/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6923 - acc: 0.7734 - val_loss: 1.7465 - val_acc: 0.4987\n",
      "Epoch 95/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6785 - acc: 0.7738 - val_loss: 1.7470 - val_acc: 0.5018\n",
      "Epoch 96/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6601 - acc: 0.7720 - val_loss: 1.7735 - val_acc: 0.4993\n",
      "Epoch 97/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6647 - acc: 0.7784 - val_loss: 1.8779 - val_acc: 0.4803\n",
      "Epoch 98/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6733 - acc: 0.7768 - val_loss: 1.7772 - val_acc: 0.4964\n",
      "Epoch 99/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6412 - acc: 0.7834 - val_loss: 1.8813 - val_acc: 0.4915\n",
      "Epoch 100/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6534 - acc: 0.7806 - val_loss: 1.7314 - val_acc: 0.5080\n",
      "Epoch 101/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6523 - acc: 0.7842 - val_loss: 1.9805 - val_acc: 0.4781\n",
      "Epoch 102/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6411 - acc: 0.7910 - val_loss: 1.8051 - val_acc: 0.5072\n",
      "Epoch 103/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6651 - acc: 0.7762 - val_loss: 1.8340 - val_acc: 0.5005\n",
      "Epoch 104/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6321 - acc: 0.7786 - val_loss: 1.9671 - val_acc: 0.4669\n",
      "Epoch 105/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6428 - acc: 0.7882 - val_loss: 1.7850 - val_acc: 0.5009\n",
      "Epoch 106/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6650 - acc: 0.7734 - val_loss: 1.8897 - val_acc: 0.4875\n",
      "Epoch 107/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6522 - acc: 0.7864 - val_loss: 1.8262 - val_acc: 0.4931\n",
      "Epoch 108/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6597 - acc: 0.7806 - val_loss: 1.8409 - val_acc: 0.4845\n",
      "Epoch 109/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6765 - acc: 0.7778 - val_loss: 1.7193 - val_acc: 0.5154\n",
      "Epoch 110/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6557 - acc: 0.7760 - val_loss: 1.8225 - val_acc: 0.4951\n",
      "Epoch 111/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6379 - acc: 0.7836 - val_loss: 1.7636 - val_acc: 0.4935\n",
      "Epoch 112/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6915 - acc: 0.7722 - val_loss: 1.6860 - val_acc: 0.5168\n",
      "Epoch 113/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6494 - acc: 0.7818 - val_loss: 1.8579 - val_acc: 0.5051\n",
      "Epoch 114/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6483 - acc: 0.7808 - val_loss: 1.8317 - val_acc: 0.5063\n",
      "Epoch 115/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6433 - acc: 0.7878 - val_loss: 1.8959 - val_acc: 0.4898\n",
      "Epoch 116/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6137 - acc: 0.7918 - val_loss: 1.7573 - val_acc: 0.5165\n",
      "Epoch 117/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6463 - acc: 0.7882 - val_loss: 1.8330 - val_acc: 0.5117\n",
      "Epoch 118/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6358 - acc: 0.7842 - val_loss: 1.9450 - val_acc: 0.4970\n",
      "Epoch 119/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6393 - acc: 0.7860 - val_loss: 1.7685 - val_acc: 0.5124\n",
      "Epoch 120/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6513 - acc: 0.7852 - val_loss: 1.8481 - val_acc: 0.5005\n",
      "Epoch 121/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6456 - acc: 0.7806 - val_loss: 1.8506 - val_acc: 0.4986\n",
      "Epoch 122/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6657 - acc: 0.7786 - val_loss: 1.9416 - val_acc: 0.4735\n",
      "Epoch 123/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6403 - acc: 0.7854 - val_loss: 1.8548 - val_acc: 0.4974\n",
      "Epoch 124/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6889 - acc: 0.7674 - val_loss: 1.8172 - val_acc: 0.4938\n",
      "Epoch 125/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6621 - acc: 0.7826 - val_loss: 1.7809 - val_acc: 0.4955\n",
      "Epoch 126/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6697 - acc: 0.7738 - val_loss: 1.7384 - val_acc: 0.4970\n",
      "Epoch 127/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6870 - acc: 0.7702 - val_loss: 1.7613 - val_acc: 0.4927\n",
      "Epoch 128/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6500 - acc: 0.7862 - val_loss: 1.7875 - val_acc: 0.4970\n",
      "Epoch 129/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6608 - acc: 0.7828 - val_loss: 1.7527 - val_acc: 0.4983\n",
      "Epoch 130/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6888 - acc: 0.7686 - val_loss: 1.7562 - val_acc: 0.4959\n",
      "Epoch 131/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6386 - acc: 0.7894 - val_loss: 1.9523 - val_acc: 0.4763\n",
      "Epoch 132/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6069 - acc: 0.7966 - val_loss: 1.9407 - val_acc: 0.4900\n",
      "Epoch 133/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6617 - acc: 0.7860 - val_loss: 1.8671 - val_acc: 0.4872\n",
      "Epoch 134/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6307 - acc: 0.7908 - val_loss: 1.9274 - val_acc: 0.4857\n",
      "Epoch 135/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6887 - acc: 0.7670 - val_loss: 1.8595 - val_acc: 0.4975\n",
      "Epoch 136/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6344 - acc: 0.7816 - val_loss: 1.8651 - val_acc: 0.5026\n",
      "Epoch 137/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6526 - acc: 0.7830 - val_loss: 1.8623 - val_acc: 0.4871\n",
      "Epoch 138/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6434 - acc: 0.7792 - val_loss: 2.0342 - val_acc: 0.4744\n",
      "Epoch 139/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6654 - acc: 0.7792 - val_loss: 1.8616 - val_acc: 0.4788\n",
      "Epoch 140/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6574 - acc: 0.7778 - val_loss: 1.8792 - val_acc: 0.4776\n",
      "Epoch 141/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6288 - acc: 0.7834 - val_loss: 1.9138 - val_acc: 0.4706\n",
      "Epoch 142/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6491 - acc: 0.7862 - val_loss: 1.8763 - val_acc: 0.4825\n",
      "Epoch 143/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6379 - acc: 0.7900 - val_loss: 1.8181 - val_acc: 0.4864\n",
      "Epoch 144/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6524 - acc: 0.7852 - val_loss: 1.8329 - val_acc: 0.4840\n",
      "Epoch 145/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6662 - acc: 0.7834 - val_loss: 1.8488 - val_acc: 0.4723\n",
      "Epoch 146/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6453 - acc: 0.7790 - val_loss: 1.8534 - val_acc: 0.4852\n",
      "Epoch 147/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6858 - acc: 0.7802 - val_loss: 1.8310 - val_acc: 0.4834\n",
      "Epoch 148/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6947 - acc: 0.7646 - val_loss: 1.9196 - val_acc: 0.4725\n",
      "Epoch 149/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6900 - acc: 0.7742 - val_loss: 1.8091 - val_acc: 0.4933\n",
      "Epoch 150/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6742 - acc: 0.7810 - val_loss: 1.7891 - val_acc: 0.4961\n",
      "Epoch 151/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6235 - acc: 0.7896 - val_loss: 1.9264 - val_acc: 0.4772\n",
      "Epoch 152/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6623 - acc: 0.7832 - val_loss: 1.8448 - val_acc: 0.4873\n",
      "Epoch 153/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6457 - acc: 0.7896 - val_loss: 1.7955 - val_acc: 0.4921\n",
      "Epoch 154/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6511 - acc: 0.7830 - val_loss: 1.7803 - val_acc: 0.4923\n",
      "Epoch 155/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6264 - acc: 0.7852 - val_loss: 1.7228 - val_acc: 0.5095\n",
      "Epoch 156/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6244 - acc: 0.7922 - val_loss: 1.9526 - val_acc: 0.4866\n",
      "Epoch 157/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6344 - acc: 0.7916 - val_loss: 1.7593 - val_acc: 0.5126\n",
      "Epoch 158/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6948 - acc: 0.7752 - val_loss: 1.7137 - val_acc: 0.5136\n",
      "Epoch 159/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6225 - acc: 0.7916 - val_loss: 1.8259 - val_acc: 0.4994\n",
      "Epoch 160/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6507 - acc: 0.7902 - val_loss: 1.8672 - val_acc: 0.4809\n",
      "Epoch 161/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6447 - acc: 0.7864 - val_loss: 1.8181 - val_acc: 0.4905\n",
      "Epoch 162/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6433 - acc: 0.7940 - val_loss: 1.7788 - val_acc: 0.5029\n",
      "Epoch 163/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6574 - acc: 0.7836 - val_loss: 1.7865 - val_acc: 0.5009\n",
      "Epoch 164/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6313 - acc: 0.7884 - val_loss: 1.8422 - val_acc: 0.4980\n",
      "Epoch 165/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6425 - acc: 0.7856 - val_loss: 1.8028 - val_acc: 0.4998\n",
      "Epoch 166/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6295 - acc: 0.7938 - val_loss: 1.8366 - val_acc: 0.4865\n",
      "Epoch 167/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6876 - acc: 0.7630 - val_loss: 1.7489 - val_acc: 0.5043\n",
      "Epoch 168/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6332 - acc: 0.7878 - val_loss: 1.7731 - val_acc: 0.5030\n",
      "Epoch 169/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6275 - acc: 0.7870 - val_loss: 1.8096 - val_acc: 0.5069\n",
      "Epoch 170/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6135 - acc: 0.7982 - val_loss: 1.8183 - val_acc: 0.5001\n",
      "Epoch 171/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6285 - acc: 0.7850 - val_loss: 1.8774 - val_acc: 0.4917\n",
      "Epoch 172/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6450 - acc: 0.7790 - val_loss: 1.8335 - val_acc: 0.4967\n",
      "Epoch 173/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6364 - acc: 0.7906 - val_loss: 1.7372 - val_acc: 0.5031\n",
      "Epoch 174/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6350 - acc: 0.7874 - val_loss: 1.7759 - val_acc: 0.5086\n",
      "Epoch 175/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6091 - acc: 0.7912 - val_loss: 1.7748 - val_acc: 0.5042\n",
      "Epoch 176/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6795 - acc: 0.7714 - val_loss: 1.7142 - val_acc: 0.5147\n",
      "Epoch 177/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6254 - acc: 0.7906 - val_loss: 1.9180 - val_acc: 0.4792\n",
      "Epoch 178/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6490 - acc: 0.7896 - val_loss: 1.8472 - val_acc: 0.4919\n",
      "Epoch 179/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6559 - acc: 0.7750 - val_loss: 1.7900 - val_acc: 0.5007\n",
      "Epoch 180/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6348 - acc: 0.7880 - val_loss: 2.0410 - val_acc: 0.4573\n",
      "Epoch 181/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6291 - acc: 0.7924 - val_loss: 1.8745 - val_acc: 0.4902\n",
      "Epoch 182/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6712 - acc: 0.7748 - val_loss: 1.8120 - val_acc: 0.4925\n",
      "Epoch 183/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6287 - acc: 0.7850 - val_loss: 1.7436 - val_acc: 0.5132\n",
      "Epoch 184/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.5972 - acc: 0.7922 - val_loss: 1.8286 - val_acc: 0.4966\n",
      "Epoch 185/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6584 - acc: 0.7876 - val_loss: 1.8244 - val_acc: 0.4816\n",
      "Epoch 186/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6111 - acc: 0.8006 - val_loss: 1.8347 - val_acc: 0.4903\n",
      "Epoch 187/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6161 - acc: 0.7874 - val_loss: 1.7233 - val_acc: 0.5164\n",
      "Epoch 188/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6563 - acc: 0.7850 - val_loss: 1.7890 - val_acc: 0.4936\n",
      "Epoch 189/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6733 - acc: 0.7794 - val_loss: 1.9297 - val_acc: 0.4731\n",
      "Epoch 190/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6449 - acc: 0.7888 - val_loss: 1.8311 - val_acc: 0.4932\n",
      "Epoch 191/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6322 - acc: 0.7870 - val_loss: 1.7539 - val_acc: 0.5018\n",
      "Epoch 192/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6125 - acc: 0.7904 - val_loss: 1.8081 - val_acc: 0.5057\n",
      "Epoch 193/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6259 - acc: 0.7954 - val_loss: 1.8746 - val_acc: 0.4890\n",
      "Epoch 194/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6061 - acc: 0.7936 - val_loss: 1.9191 - val_acc: 0.4926\n",
      "Epoch 195/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6554 - acc: 0.7818 - val_loss: 1.8695 - val_acc: 0.4967\n",
      "Epoch 196/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6264 - acc: 0.7916 - val_loss: 1.8581 - val_acc: 0.4977\n",
      "Epoch 197/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6653 - acc: 0.7736 - val_loss: 2.0159 - val_acc: 0.4767\n",
      "Epoch 198/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.7293 - acc: 0.7546 - val_loss: 1.8420 - val_acc: 0.4925\n",
      "Epoch 199/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6741 - acc: 0.7736 - val_loss: 1.8462 - val_acc: 0.4877\n",
      "Epoch 200/200\n",
      "5000/5000 [==============================] - 3s - loss: 0.6709 - acc: 0.7772 - val_loss: 1.8102 - val_acc: 0.4956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f556d68a5c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_label, Y_train_label,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=200,\n",
    "          validation_data=(X_test_cifar, Y_test_cifar),\n",
    "#           validation_split=0.1,  # (X_train_label, Y_train_label),\n",
    "          shuffle=True)\n",
    "\n",
    "# TODO: remove (X_test_reshaped, Y_test_categ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = (METHOD\n",
    "    + '_filter-64-64-MP-64-APS-64-APS-64-APS-512-256-128'\n",
    "    + '_epo-300' # + str(nb_epoch)\n",
    "    + '_acc0.7772_test-0.50'\n",
    ")\n",
    "\n",
    "model.save(MODEL_FOLDER + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = pickle.load(open(TEST_DATA_FILE, 'rb'))  # dict\n",
    "X_test = np.array(test_data['data']).reshape((10000, 3, 32, 32)).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "result = model.predict_classes(X_test, batch_size=10000)\n",
    "csv_content = list(zip(test_data['ID'], result.tolist()))\n",
    "np.savetxt(OUTPUT_FOLDER + model_name + \".csv\", csv_content, fmt=\"%i\", header=\"ID,class\", comments=\"\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
