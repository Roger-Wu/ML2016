{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELLED_DATA_FILE = 'data/all_label.p'\n",
    "UNLABELED_DATA_FILE = 'data/all_unlabel.p'\n",
    "TEST_DATA_FILE = 'data/test.p'\n",
    "\n",
    "METHOD = 'cnn_supervised'\n",
    "\n",
    "OUTPUT_FOLDER = 'output/'\n",
    "MODEL_FOLDER = 'model/' + METHOD + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(MODEL_FOLDER):\n",
    "    os.makedirs(MODEL_FOLDER)\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelled_data = np.array(pickle.load(open(LABELLED_DATA_FILE, 'rb')))\n",
    "# unlabeled_data = np.array(pickle.load(open(UNLABELED_DATA_FILE, 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate x, y from data\n",
    "X_train_label = labelled_data.reshape((5000, 3, 32, 32)).astype('float32') / 255\n",
    "\n",
    "y_train_label_class = np.array([classIdx for classIdx in range(len(labelled_data)) for i in range(len(labelled_data[classIdx]))])\n",
    "Y_train_label = np_utils.to_categorical(y_train_label_class, len(labelled_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAIpUlEQVR4nC2VS49cZxmE67183znd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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F56386D6208>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.misc import toimage\n",
    "toimage(X_train_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: remove\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# X_train_reshaped = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_train]) / 255.0\n",
    "X_test_cifar = np.array([[img[:, :, 0], img[:, :, 1], img[:, :, 2]] for img in X_test]) / 255.0\n",
    "Y_test_cifar = np_utils.to_categorical(y_test.flatten(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_classes = 10\n",
    "nb_epoch = 100\n",
    "img_rows, img_cols, img_channels = 32, 32, 3\n",
    "# nb_filters = [32, 64]\n",
    "# nb_nodes = [512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=X_train_label.shape[1:], dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "# model.add(Activation('relu'))\n",
    "# # model.add(Convolution2D(64, 3, 3))\n",
    "# # model.add(Activation('relu'))\n",
    "# model.add(AveragePooling2D(pool_size=(2, 2), dim_ordering=\"th\", border_mode='same'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), dim_ordering=\"th\", border_mode='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), dim_ordering=\"th\", border_mode='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering=\"th\"))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(AveragePooling2D(pool_size=(2, 2), dim_ordering=\"th\", border_mode='same'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())  # n * 8 * 8, for 64 -> 4096\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "5000/5000 [==============================] - 5s - loss: 2.2884 - acc: 0.1060 - val_loss: 2.3735 - val_acc: 0.0920\n",
      "Epoch 2/200\n",
      "5000/5000 [==============================] - 4s - loss: 2.1688 - acc: 0.1654 - val_loss: 2.6300 - val_acc: 0.0795\n",
      "Epoch 3/200\n",
      "5000/5000 [==============================] - 4s - loss: 2.0523 - acc: 0.1898 - val_loss: 2.4460 - val_acc: 0.1044\n",
      "Epoch 4/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.9582 - acc: 0.2218 - val_loss: 2.5723 - val_acc: 0.1528\n",
      "Epoch 5/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.8933 - acc: 0.2530 - val_loss: 2.2073 - val_acc: 0.1848\n",
      "Epoch 6/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.8334 - acc: 0.2844 - val_loss: 2.4206 - val_acc: 0.1933\n",
      "Epoch 7/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.7793 - acc: 0.3090 - val_loss: 2.1746 - val_acc: 0.2130\n",
      "Epoch 8/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.7327 - acc: 0.3336 - val_loss: 2.1203 - val_acc: 0.2350\n",
      "Epoch 9/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.7139 - acc: 0.3362 - val_loss: 2.2673 - val_acc: 0.2234\n",
      "Epoch 10/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.6858 - acc: 0.3570 - val_loss: 2.0897 - val_acc: 0.2568\n",
      "Epoch 11/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.6281 - acc: 0.3732 - val_loss: 2.1738 - val_acc: 0.2185\n",
      "Epoch 12/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.6216 - acc: 0.3888 - val_loss: 2.0043 - val_acc: 0.2500\n",
      "Epoch 13/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.6022 - acc: 0.4004 - val_loss: 2.0944 - val_acc: 0.2567\n",
      "Epoch 14/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.5309 - acc: 0.4232 - val_loss: 1.9040 - val_acc: 0.3075\n",
      "Epoch 15/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.5457 - acc: 0.4180 - val_loss: 2.1229 - val_acc: 0.2726\n",
      "Epoch 16/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.5048 - acc: 0.4352 - val_loss: 2.0082 - val_acc: 0.2827\n",
      "Epoch 17/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.4761 - acc: 0.4502 - val_loss: 2.0635 - val_acc: 0.2897\n",
      "Epoch 18/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.4453 - acc: 0.4576 - val_loss: 1.9358 - val_acc: 0.3327\n",
      "Epoch 19/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.4246 - acc: 0.4742 - val_loss: 1.9018 - val_acc: 0.3304\n",
      "Epoch 20/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.4003 - acc: 0.4726 - val_loss: 1.9020 - val_acc: 0.3348\n",
      "Epoch 21/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.3889 - acc: 0.4868 - val_loss: 2.0265 - val_acc: 0.3065\n",
      "Epoch 22/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.3641 - acc: 0.4994 - val_loss: 1.9222 - val_acc: 0.3222\n",
      "Epoch 23/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.3827 - acc: 0.4936 - val_loss: 1.7934 - val_acc: 0.3569\n",
      "Epoch 24/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.3500 - acc: 0.5070 - val_loss: 1.8835 - val_acc: 0.3379\n",
      "Epoch 25/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.3541 - acc: 0.5048 - val_loss: 1.8955 - val_acc: 0.3253\n",
      "Epoch 26/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.3073 - acc: 0.5190 - val_loss: 1.9629 - val_acc: 0.3304\n",
      "Epoch 27/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.2882 - acc: 0.5252 - val_loss: 1.9174 - val_acc: 0.3458\n",
      "Epoch 28/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.2713 - acc: 0.5340 - val_loss: 2.1273 - val_acc: 0.3266\n",
      "Epoch 29/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.3081 - acc: 0.5228 - val_loss: 1.8437 - val_acc: 0.3705\n",
      "Epoch 30/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.2587 - acc: 0.5438 - val_loss: 1.8785 - val_acc: 0.3745\n",
      "Epoch 31/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.2313 - acc: 0.5460 - val_loss: 1.8837 - val_acc: 0.3715\n",
      "Epoch 32/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.2005 - acc: 0.5608 - val_loss: 1.8376 - val_acc: 0.3772\n",
      "Epoch 33/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.2285 - acc: 0.5486 - val_loss: 1.9876 - val_acc: 0.3366\n",
      "Epoch 34/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.2101 - acc: 0.5648 - val_loss: 1.7688 - val_acc: 0.3933\n",
      "Epoch 35/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.1755 - acc: 0.5710 - val_loss: 1.9359 - val_acc: 0.3579\n",
      "Epoch 36/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.1694 - acc: 0.5776 - val_loss: 2.0244 - val_acc: 0.3496\n",
      "Epoch 37/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.1786 - acc: 0.5788 - val_loss: 1.8289 - val_acc: 0.3969\n",
      "Epoch 38/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.1872 - acc: 0.5696 - val_loss: 1.7292 - val_acc: 0.3991\n",
      "Epoch 39/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.1408 - acc: 0.5842 - val_loss: 1.8322 - val_acc: 0.3978\n",
      "Epoch 40/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.1184 - acc: 0.5820 - val_loss: 1.7348 - val_acc: 0.4128\n",
      "Epoch 41/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.1093 - acc: 0.5960 - val_loss: 1.8021 - val_acc: 0.3998\n",
      "Epoch 42/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.1153 - acc: 0.5892 - val_loss: 1.8651 - val_acc: 0.3805\n",
      "Epoch 43/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.0923 - acc: 0.5928 - val_loss: 1.8536 - val_acc: 0.4001\n",
      "Epoch 44/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.1513 - acc: 0.5878 - val_loss: 1.7678 - val_acc: 0.4230\n",
      "Epoch 45/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.0916 - acc: 0.6054 - val_loss: 1.7719 - val_acc: 0.4148\n",
      "Epoch 46/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.0559 - acc: 0.6130 - val_loss: 1.8715 - val_acc: 0.4088\n",
      "Epoch 47/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.0532 - acc: 0.6146 - val_loss: 1.8432 - val_acc: 0.4290\n",
      "Epoch 48/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.0587 - acc: 0.6238 - val_loss: 1.9047 - val_acc: 0.4041\n",
      "Epoch 49/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.0586 - acc: 0.6116 - val_loss: 1.8689 - val_acc: 0.4089\n",
      "Epoch 50/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.0326 - acc: 0.6314 - val_loss: 1.8906 - val_acc: 0.3927\n",
      "Epoch 51/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.0622 - acc: 0.6126 - val_loss: 1.8252 - val_acc: 0.4358\n",
      "Epoch 52/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.0151 - acc: 0.6416 - val_loss: 1.8039 - val_acc: 0.4468\n",
      "Epoch 53/200\n",
      "5000/5000 [==============================] - 4s - loss: 1.0329 - acc: 0.6340 - val_loss: 1.7908 - val_acc: 0.4207\n",
      "Epoch 54/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.9853 - acc: 0.6476 - val_loss: 1.7863 - val_acc: 0.4207\n",
      "Epoch 55/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.9806 - acc: 0.6516 - val_loss: 1.7985 - val_acc: 0.4280\n",
      "Epoch 56/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.9912 - acc: 0.6440 - val_loss: 1.8429 - val_acc: 0.4310\n",
      "Epoch 57/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.9504 - acc: 0.6610 - val_loss: 1.8126 - val_acc: 0.4397\n",
      "Epoch 58/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.9483 - acc: 0.6586 - val_loss: 1.8316 - val_acc: 0.4232\n",
      "Epoch 59/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.9972 - acc: 0.6430 - val_loss: 1.7275 - val_acc: 0.4433\n",
      "Epoch 60/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.9674 - acc: 0.6532 - val_loss: 1.7827 - val_acc: 0.4378\n",
      "Epoch 61/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.9342 - acc: 0.6672 - val_loss: 1.6708 - val_acc: 0.4649\n",
      "Epoch 62/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.9833 - acc: 0.6484 - val_loss: 1.8008 - val_acc: 0.4127\n",
      "Epoch 63/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.9323 - acc: 0.6708 - val_loss: 1.8017 - val_acc: 0.4474\n",
      "Epoch 64/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.9454 - acc: 0.6694 - val_loss: 1.6324 - val_acc: 0.4600\n",
      "Epoch 65/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.9443 - acc: 0.6656 - val_loss: 1.8367 - val_acc: 0.4253\n",
      "Epoch 66/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8876 - acc: 0.6742 - val_loss: 1.7921 - val_acc: 0.4499\n",
      "Epoch 67/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.9062 - acc: 0.6750 - val_loss: 1.7314 - val_acc: 0.4652\n",
      "Epoch 68/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.9013 - acc: 0.6814 - val_loss: 2.0440 - val_acc: 0.4112\n",
      "Epoch 69/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.9090 - acc: 0.6722 - val_loss: 1.8715 - val_acc: 0.4223\n",
      "Epoch 70/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8924 - acc: 0.6826 - val_loss: 1.9406 - val_acc: 0.4182\n",
      "Epoch 71/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8946 - acc: 0.6862 - val_loss: 2.0128 - val_acc: 0.3978\n",
      "Epoch 72/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8859 - acc: 0.6826 - val_loss: 1.8669 - val_acc: 0.4535\n",
      "Epoch 73/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8642 - acc: 0.6978 - val_loss: 1.8922 - val_acc: 0.4526\n",
      "Epoch 74/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8676 - acc: 0.6950 - val_loss: 1.7305 - val_acc: 0.4720\n",
      "Epoch 75/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8757 - acc: 0.6826 - val_loss: 1.7448 - val_acc: 0.4629\n",
      "Epoch 76/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8439 - acc: 0.6972 - val_loss: 1.8184 - val_acc: 0.4435\n",
      "Epoch 77/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8543 - acc: 0.7002 - val_loss: 1.9142 - val_acc: 0.4427\n",
      "Epoch 78/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8472 - acc: 0.6954 - val_loss: 1.7127 - val_acc: 0.4772\n",
      "Epoch 79/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8203 - acc: 0.7086 - val_loss: 1.6686 - val_acc: 0.4824\n",
      "Epoch 80/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8424 - acc: 0.6980 - val_loss: 1.7231 - val_acc: 0.4667\n",
      "Epoch 81/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8217 - acc: 0.6978 - val_loss: 1.8930 - val_acc: 0.4399\n",
      "Epoch 82/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8241 - acc: 0.7090 - val_loss: 1.7364 - val_acc: 0.4701\n",
      "Epoch 83/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8292 - acc: 0.7130 - val_loss: 1.7969 - val_acc: 0.4430\n",
      "Epoch 84/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7992 - acc: 0.7180 - val_loss: 1.7688 - val_acc: 0.4717\n",
      "Epoch 85/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8101 - acc: 0.7078 - val_loss: 1.9732 - val_acc: 0.4451\n",
      "Epoch 86/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8019 - acc: 0.7280 - val_loss: 1.7993 - val_acc: 0.4551\n",
      "Epoch 87/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.8016 - acc: 0.7084 - val_loss: 1.7704 - val_acc: 0.4703\n",
      "Epoch 88/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7778 - acc: 0.7226 - val_loss: 1.8098 - val_acc: 0.4773\n",
      "Epoch 89/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7881 - acc: 0.7246 - val_loss: 1.9191 - val_acc: 0.4538\n",
      "Epoch 90/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7828 - acc: 0.7252 - val_loss: 2.0456 - val_acc: 0.4562\n",
      "Epoch 91/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7798 - acc: 0.7266 - val_loss: 1.6591 - val_acc: 0.4937\n",
      "Epoch 92/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7705 - acc: 0.7314 - val_loss: 1.7602 - val_acc: 0.4827\n",
      "Epoch 93/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7898 - acc: 0.7236 - val_loss: 1.8896 - val_acc: 0.4515\n",
      "Epoch 94/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7577 - acc: 0.7324 - val_loss: 1.8306 - val_acc: 0.4698\n",
      "Epoch 95/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7906 - acc: 0.7224 - val_loss: 1.7505 - val_acc: 0.4743\n",
      "Epoch 96/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7873 - acc: 0.7260 - val_loss: 1.7844 - val_acc: 0.4756\n",
      "Epoch 97/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7394 - acc: 0.7340 - val_loss: 1.7840 - val_acc: 0.4723\n",
      "Epoch 98/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7429 - acc: 0.7348 - val_loss: 1.7900 - val_acc: 0.4960\n",
      "Epoch 99/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7251 - acc: 0.7404 - val_loss: 1.9326 - val_acc: 0.4704\n",
      "Epoch 100/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7414 - acc: 0.7372 - val_loss: 1.8314 - val_acc: 0.4783\n",
      "Epoch 101/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7511 - acc: 0.7394 - val_loss: 1.9866 - val_acc: 0.4481\n",
      "Epoch 102/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7840 - acc: 0.7244 - val_loss: 1.8094 - val_acc: 0.4723\n",
      "Epoch 103/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7137 - acc: 0.7456 - val_loss: 1.8876 - val_acc: 0.4679\n",
      "Epoch 104/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7107 - acc: 0.7446 - val_loss: 1.9116 - val_acc: 0.4626\n",
      "Epoch 105/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7131 - acc: 0.7472 - val_loss: 2.0145 - val_acc: 0.4639\n",
      "Epoch 106/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7087 - acc: 0.7510 - val_loss: 1.7217 - val_acc: 0.4988\n",
      "Epoch 107/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6777 - acc: 0.7626 - val_loss: 2.0797 - val_acc: 0.4553\n",
      "Epoch 108/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7157 - acc: 0.7538 - val_loss: 1.6765 - val_acc: 0.4988\n",
      "Epoch 109/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6971 - acc: 0.7604 - val_loss: 1.8584 - val_acc: 0.4785\n",
      "Epoch 110/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7067 - acc: 0.7576 - val_loss: 1.9212 - val_acc: 0.4742\n",
      "Epoch 111/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7117 - acc: 0.7490 - val_loss: 2.0732 - val_acc: 0.4515\n",
      "Epoch 112/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7002 - acc: 0.7552 - val_loss: 2.0709 - val_acc: 0.4481\n",
      "Epoch 113/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6794 - acc: 0.7636 - val_loss: 1.9546 - val_acc: 0.4674\n",
      "Epoch 114/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6950 - acc: 0.7528 - val_loss: 1.8731 - val_acc: 0.4861\n",
      "Epoch 115/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6713 - acc: 0.7730 - val_loss: 1.9782 - val_acc: 0.4703\n",
      "Epoch 116/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.7014 - acc: 0.7670 - val_loss: 1.7139 - val_acc: 0.4962\n",
      "Epoch 117/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6682 - acc: 0.7608 - val_loss: 1.9635 - val_acc: 0.4772\n",
      "Epoch 118/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6813 - acc: 0.7590 - val_loss: 1.8417 - val_acc: 0.4920\n",
      "Epoch 119/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6783 - acc: 0.7660 - val_loss: 2.0734 - val_acc: 0.4355\n",
      "Epoch 120/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6753 - acc: 0.7676 - val_loss: 1.9658 - val_acc: 0.4540\n",
      "Epoch 121/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6957 - acc: 0.7654 - val_loss: 2.0684 - val_acc: 0.4759\n",
      "Epoch 122/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6863 - acc: 0.7596 - val_loss: 1.9590 - val_acc: 0.4850\n",
      "Epoch 123/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6758 - acc: 0.7734 - val_loss: 1.8424 - val_acc: 0.4975\n",
      "Epoch 124/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6556 - acc: 0.7740 - val_loss: 2.1595 - val_acc: 0.4563\n",
      "Epoch 125/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6565 - acc: 0.7752 - val_loss: 1.8905 - val_acc: 0.4820\n",
      "Epoch 126/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6863 - acc: 0.7596 - val_loss: 1.8352 - val_acc: 0.4959\n",
      "Epoch 127/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6390 - acc: 0.7776 - val_loss: 1.8392 - val_acc: 0.4909\n",
      "Epoch 128/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6375 - acc: 0.7826 - val_loss: 2.1715 - val_acc: 0.4682\n",
      "Epoch 129/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6566 - acc: 0.7722 - val_loss: 2.0819 - val_acc: 0.4678\n",
      "Epoch 130/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6159 - acc: 0.7844 - val_loss: 2.1708 - val_acc: 0.4670\n",
      "Epoch 131/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6391 - acc: 0.7782 - val_loss: 2.0425 - val_acc: 0.4756\n",
      "Epoch 132/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6208 - acc: 0.7788 - val_loss: 1.9613 - val_acc: 0.4633\n",
      "Epoch 133/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6715 - acc: 0.7750 - val_loss: 2.0899 - val_acc: 0.4642\n",
      "Epoch 134/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6174 - acc: 0.7850 - val_loss: 1.8764 - val_acc: 0.4965\n",
      "Epoch 135/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6274 - acc: 0.7842 - val_loss: 1.9894 - val_acc: 0.4744\n",
      "Epoch 136/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6234 - acc: 0.7794 - val_loss: 2.2016 - val_acc: 0.4517\n",
      "Epoch 137/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6019 - acc: 0.7884 - val_loss: 2.1646 - val_acc: 0.4526\n",
      "Epoch 138/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6507 - acc: 0.7740 - val_loss: 1.9657 - val_acc: 0.4681\n",
      "Epoch 139/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6057 - acc: 0.7936 - val_loss: 2.2046 - val_acc: 0.4706\n",
      "Epoch 140/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5979 - acc: 0.7900 - val_loss: 2.0089 - val_acc: 0.4777\n",
      "Epoch 141/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5984 - acc: 0.7894 - val_loss: 1.9361 - val_acc: 0.4870\n",
      "Epoch 142/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6196 - acc: 0.7838 - val_loss: 2.1285 - val_acc: 0.4734\n",
      "Epoch 143/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6062 - acc: 0.7820 - val_loss: 2.2849 - val_acc: 0.4603\n",
      "Epoch 144/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5743 - acc: 0.7952 - val_loss: 2.3219 - val_acc: 0.4287\n",
      "Epoch 145/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6216 - acc: 0.7898 - val_loss: 2.0953 - val_acc: 0.4760\n",
      "Epoch 146/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6079 - acc: 0.7886 - val_loss: 2.0022 - val_acc: 0.4854\n",
      "Epoch 147/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6050 - acc: 0.7856 - val_loss: 1.9147 - val_acc: 0.4888\n",
      "Epoch 148/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5905 - acc: 0.7984 - val_loss: 2.2187 - val_acc: 0.4561\n",
      "Epoch 149/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6114 - acc: 0.7896 - val_loss: 1.9979 - val_acc: 0.4728\n",
      "Epoch 150/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6006 - acc: 0.7968 - val_loss: 2.1103 - val_acc: 0.4574\n",
      "Epoch 151/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5869 - acc: 0.7964 - val_loss: 2.0739 - val_acc: 0.4597\n",
      "Epoch 152/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6387 - acc: 0.7874 - val_loss: 1.9952 - val_acc: 0.4845\n",
      "Epoch 153/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6004 - acc: 0.7984 - val_loss: 1.9181 - val_acc: 0.4793\n",
      "Epoch 154/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5757 - acc: 0.8006 - val_loss: 2.1560 - val_acc: 0.4620\n",
      "Epoch 155/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5717 - acc: 0.8030 - val_loss: 2.1580 - val_acc: 0.4606\n",
      "Epoch 156/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6369 - acc: 0.7864 - val_loss: 2.1753 - val_acc: 0.4624\n",
      "Epoch 157/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.6790 - acc: 0.7692 - val_loss: 1.7737 - val_acc: 0.4981\n",
      "Epoch 158/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5864 - acc: 0.8012 - val_loss: 1.8865 - val_acc: 0.4916\n",
      "Epoch 159/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5472 - acc: 0.8096 - val_loss: 2.0920 - val_acc: 0.4796\n",
      "Epoch 160/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5826 - acc: 0.8074 - val_loss: 2.0750 - val_acc: 0.4899\n",
      "Epoch 161/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5591 - acc: 0.8048 - val_loss: 2.0708 - val_acc: 0.5041\n",
      "Epoch 162/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5444 - acc: 0.8114 - val_loss: 2.1706 - val_acc: 0.4696\n",
      "Epoch 163/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5445 - acc: 0.8154 - val_loss: 1.9074 - val_acc: 0.4909\n",
      "Epoch 164/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5563 - acc: 0.8144 - val_loss: 2.0547 - val_acc: 0.4826\n",
      "Epoch 165/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5527 - acc: 0.8126 - val_loss: 2.1597 - val_acc: 0.4513\n",
      "Epoch 166/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5603 - acc: 0.8070 - val_loss: 1.9387 - val_acc: 0.4823\n",
      "Epoch 167/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5424 - acc: 0.8114 - val_loss: 2.0258 - val_acc: 0.4857\n",
      "Epoch 168/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5815 - acc: 0.8014 - val_loss: 2.0538 - val_acc: 0.4715\n",
      "Epoch 169/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5526 - acc: 0.8144 - val_loss: 2.1782 - val_acc: 0.4772\n",
      "Epoch 170/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5441 - acc: 0.8120 - val_loss: 2.0450 - val_acc: 0.4795\n",
      "Epoch 171/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5163 - acc: 0.8152 - val_loss: 2.0553 - val_acc: 0.4798\n",
      "Epoch 172/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5530 - acc: 0.8128 - val_loss: 2.0320 - val_acc: 0.4727\n",
      "Epoch 173/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5696 - acc: 0.8142 - val_loss: 1.9868 - val_acc: 0.4785\n",
      "Epoch 174/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5688 - acc: 0.8034 - val_loss: 1.8707 - val_acc: 0.4942\n",
      "Epoch 175/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5393 - acc: 0.8094 - val_loss: 1.9467 - val_acc: 0.4944\n",
      "Epoch 176/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5240 - acc: 0.8214 - val_loss: 2.0784 - val_acc: 0.4864\n",
      "Epoch 177/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5443 - acc: 0.8150 - val_loss: 1.9757 - val_acc: 0.4953\n",
      "Epoch 178/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5376 - acc: 0.8116 - val_loss: 1.8203 - val_acc: 0.5135\n",
      "Epoch 179/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5171 - acc: 0.8226 - val_loss: 2.2353 - val_acc: 0.4463\n",
      "Epoch 180/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5443 - acc: 0.8202 - val_loss: 2.0673 - val_acc: 0.4799\n",
      "Epoch 181/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5339 - acc: 0.8210 - val_loss: 2.0815 - val_acc: 0.4790\n",
      "Epoch 182/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5346 - acc: 0.8246 - val_loss: 2.0349 - val_acc: 0.4876\n",
      "Epoch 183/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5260 - acc: 0.8244 - val_loss: 2.0796 - val_acc: 0.4769\n",
      "Epoch 184/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5448 - acc: 0.8158 - val_loss: 2.4205 - val_acc: 0.4588\n",
      "Epoch 185/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5149 - acc: 0.8244 - val_loss: 2.1759 - val_acc: 0.4839\n",
      "Epoch 186/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5284 - acc: 0.8274 - val_loss: 2.2311 - val_acc: 0.4812\n",
      "Epoch 187/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5599 - acc: 0.8080 - val_loss: 1.8366 - val_acc: 0.5092\n",
      "Epoch 188/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5414 - acc: 0.8156 - val_loss: 2.2148 - val_acc: 0.4844\n",
      "Epoch 189/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5482 - acc: 0.8192 - val_loss: 2.0653 - val_acc: 0.4793\n",
      "Epoch 190/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5404 - acc: 0.8148 - val_loss: 2.0316 - val_acc: 0.4910\n",
      "Epoch 191/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5163 - acc: 0.8298 - val_loss: 1.9884 - val_acc: 0.4876\n",
      "Epoch 192/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5479 - acc: 0.8216 - val_loss: 2.1454 - val_acc: 0.4759\n",
      "Epoch 193/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.4997 - acc: 0.8326 - val_loss: 2.1895 - val_acc: 0.4831\n",
      "Epoch 194/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5311 - acc: 0.8238 - val_loss: 2.2662 - val_acc: 0.4720\n",
      "Epoch 195/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5151 - acc: 0.8272 - val_loss: 2.1310 - val_acc: 0.4852\n",
      "Epoch 196/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5073 - acc: 0.8280 - val_loss: 2.0047 - val_acc: 0.4926\n",
      "Epoch 197/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.4967 - acc: 0.8294 - val_loss: 2.1181 - val_acc: 0.4763\n",
      "Epoch 198/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.4964 - acc: 0.8342 - val_loss: 2.0551 - val_acc: 0.5007\n",
      "Epoch 199/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5021 - acc: 0.8338 - val_loss: 2.1864 - val_acc: 0.4771\n",
      "Epoch 200/200\n",
      "5000/5000 [==============================] - 4s - loss: 0.5036 - acc: 0.8296 - val_loss: 2.3814 - val_acc: 0.4659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f556ce22a20>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_label, Y_train_label,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=200,\n",
    "          validation_data=(X_test_cifar, Y_test_cifar),\n",
    "#           validation_split=0.1,  # (X_train_label, Y_train_label),\n",
    "          shuffle=True)\n",
    "\n",
    "# TODO: remove (X_test_reshaped, Y_test_categ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = (METHOD\n",
    "    + '_filter-64-64-MP-64-APS-64-APS-64-APS-512-256-128'\n",
    "    + '_epo-300' # + str(nb_epoch)\n",
    "    + '_acc0.7772_test-0.50'\n",
    ")\n",
    "\n",
    "model.save(MODEL_FOLDER + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = pickle.load(open(TEST_DATA_FILE, 'rb'))  # dict\n",
    "X_test = np.array(test_data['data']).reshape((10000, 3, 32, 32)).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "result = model.predict_classes(X_test, batch_size=10000)\n",
    "csv_content = list(zip(test_data['ID'], result.tolist()))\n",
    "np.savetxt(OUTPUT_FOLDER + model_name + \".csv\", csv_content, fmt=\"%i\", header=\"ID,class\", comments=\"\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
