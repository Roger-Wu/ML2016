{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import brown\n",
    "from gensim.models import word2vec\n",
    "import time\n",
    "from gensim.models import phrases\n",
    "\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "nltk_stopwords = set(stopwords.words(\"english\"))\n",
    "# frequency_list = FreqDist(i.lower() for i in brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "MODEL_FOLDER = 'model/'\n",
    "OUTPUT_FOLDER = 'output/'\n",
    "TRAIN_FILES = ['biology.csv', 'cooking.csv', 'crypto.csv', 'diy.csv', 'robotics.csv', 'travel.csv']\n",
    "TEST_FILE = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOMAIN_COUNT = len(TRAIN_FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_trains = [pd.read_csv(DATA_FOLDER + filename) for filename in TRAIN_FILES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13196, 4)\n",
      "(15404, 4)\n",
      "(10432, 4)\n",
      "(25918, 4)\n",
      "(2771, 4)\n",
      "(19279, 4)\n"
     ]
    }
   ],
   "source": [
    "for df in df_trains:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([df.shape[0] for df in df_trains])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the criticality of the ribosome bindin...</td>\n",
       "      <td>&lt;p&gt;In prokaryotic translation, how critical fo...</td>\n",
       "      <td>ribosome binding-sites translation synthetic-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>How is RNAse contamination in RNA based experi...</td>\n",
       "      <td>&lt;p&gt;Does anyone have any suggestions to prevent...</td>\n",
       "      <td>rna biochemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Are lymphocyte sizes clustered in two groups?</td>\n",
       "      <td>&lt;p&gt;Tortora writes in &lt;em&gt;Principles of Anatomy...</td>\n",
       "      <td>immunology cell-biology hematology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>How long does antibiotic-dosed LB maintain goo...</td>\n",
       "      <td>&lt;p&gt;Various people in our lab will prepare a li...</td>\n",
       "      <td>cell-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Is exon order always preserved in splicing?</td>\n",
       "      <td>&lt;p&gt;Are there any cases in which the splicing m...</td>\n",
       "      <td>splicing mrna spliceosome introns exons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  What is the criticality of the ribosome bindin...   \n",
       "1   2  How is RNAse contamination in RNA based experi...   \n",
       "2   3      Are lymphocyte sizes clustered in two groups?   \n",
       "3   4  How long does antibiotic-dosed LB maintain goo...   \n",
       "4   5        Is exon order always preserved in splicing?   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>In prokaryotic translation, how critical fo...   \n",
       "1  <p>Does anyone have any suggestions to prevent...   \n",
       "2  <p>Tortora writes in <em>Principles of Anatomy...   \n",
       "3  <p>Various people in our lab will prepare a li...   \n",
       "4  <p>Are there any cases in which the splicing m...   \n",
       "\n",
       "                                                tags  \n",
       "0  ribosome binding-sites translation synthetic-b...  \n",
       "1                                   rna biochemistry  \n",
       "2                 immunology cell-biology hematology  \n",
       "3                                       cell-culture  \n",
       "4            splicing mrna spliceosome introns exons  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trains[0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ribosome binding-sites translation synthetic-biology',\n",
       " 'rna biochemistry',\n",
       " 'immunology cell-biology hematology',\n",
       " 'cell-culture',\n",
       " 'splicing mrna spliceosome introns exons']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0_tags = df_trains[0]['tags'].tolist()\n",
    "train_0_tags[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678\n",
      "['sex', 'translation', 'exons', 'dopamine', 'cellular-respiration', 'proteins', 'joints', 'mass-spec', 'hiv', 'menstrual-cycle']\n"
     ]
    }
   ],
   "source": [
    "train_0_tag_set = set()\n",
    "for tags in train_0_tags:\n",
    "    for tag in tags.split():\n",
    "        train_0_tag_set.add(tag)\n",
    "print(len(train_0_tag_set))\n",
    "\n",
    "train_0_unique_tags = list(train_0_tag_set)\n",
    "\n",
    "print(train_0_unique_tags[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_domains_tags = []\n",
    "\n",
    "for df in df_trains:\n",
    "    tags = df['tags'].tolist()\n",
    "    split_tags = [tag_string.split() for tag_string in tags]\n",
    "    train_domains_tags.append(split_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ribosome', 'binding-sites', 'translation', 'synthetic-biology'],\n",
       " ['rna', 'biochemistry'],\n",
       " ['immunology', 'cell-biology', 'hematology'],\n",
       " ['cell-culture'],\n",
       " ['splicing', 'mrna', 'spliceosome', 'introns', 'exons'],\n",
       " ['dna', 'biochemistry', 'molecular-biology'],\n",
       " ['neuroscience', 'synapses'],\n",
       " ['plasmids'],\n",
       " ['molecular-genetics', 'gene-expression', 'experimental-design'],\n",
       " ['evolution', 'mitochondria', 'chloroplasts']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_domains_tags[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.510533495\n",
      "2.30732277331\n",
      "2.44286809816\n",
      "2.28138745274\n",
      "2.35294117647\n",
      "3.38886871726\n"
     ]
    }
   ],
   "source": [
    "tag_count_list = []\n",
    "for domain_tags in train_domains_tags:\n",
    "    print(np.mean([len(tags) for tags in domain_tags]))\n",
    "    tag_count_list.extend([len(tags) for tags in domain_tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5877931034482757"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tag_count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "domains_tag_sets = [set() for i in range(len(df_trains))]\n",
    "\n",
    "for i in range(len(df_trains)):\n",
    "    domain_tags = train_domains_tags[i]\n",
    "    for tags in domain_tags:\n",
    "        for tag in tags:\n",
    "            domains_tag_sets[i].add(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3d-structure',\n",
       " 'abiogenesis',\n",
       " 'action-potential',\n",
       " 'adaptation',\n",
       " 'addiction',\n",
       " 'agriculture',\n",
       " 'aids',\n",
       " 'allele',\n",
       " 'allelopathy',\n",
       " 'allergies',\n",
       " 'allometry',\n",
       " 'altruism',\n",
       " 'amino-acids',\n",
       " 'anaerobic-respiration',\n",
       " 'analgesia',\n",
       " 'anatomy',\n",
       " 'anecdotal-evidence',\n",
       " 'animal-husbandry',\n",
       " 'animal-models',\n",
       " 'ant',\n",
       " 'anthropology',\n",
       " 'antibiotic-resistance',\n",
       " 'antibiotics',\n",
       " 'antibody',\n",
       " 'antigen',\n",
       " 'antihistamines',\n",
       " 'antipredator-adaptation',\n",
       " 'apoptosis',\n",
       " 'aquaculture',\n",
       " 'arachnology',\n",
       " 'archaea',\n",
       " 'artificial-life',\n",
       " 'artificial-selection',\n",
       " 'asexual-reproduction',\n",
       " 'aspirin',\n",
       " 'assay-development',\n",
       " 'astrobiology',\n",
       " 'autoimmune',\n",
       " 'autonomic-nervous-system',\n",
       " 'autophagy',\n",
       " 'autoreceptor',\n",
       " 'auxology',\n",
       " 'bacterial-toxins',\n",
       " 'bacteriology',\n",
       " 'balance',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'benzodiazepine',\n",
       " 'bile',\n",
       " 'binding-sites',\n",
       " 'bio-mechanics',\n",
       " 'biochemistry',\n",
       " 'biodiversity',\n",
       " 'bioenergetics',\n",
       " 'biofeedback',\n",
       " 'biofilms',\n",
       " 'biogeography',\n",
       " 'bioinformatics',\n",
       " 'bioinorganic-chemistry',\n",
       " 'biological-control',\n",
       " 'biological-networks',\n",
       " 'biology-misconceptions',\n",
       " 'bioluminescence',\n",
       " 'biomedical-engineering',\n",
       " 'biomedical-technology',\n",
       " 'biophysics',\n",
       " 'biopython',\n",
       " 'biostatistics',\n",
       " 'biosynthesis',\n",
       " 'biotechnology',\n",
       " 'blast',\n",
       " 'blood-brain-barrier',\n",
       " 'blood-circulation',\n",
       " 'blood-group',\n",
       " 'blood-pressure',\n",
       " 'blood-sugar',\n",
       " 'blood-transfusion',\n",
       " 'bone-biology',\n",
       " 'book-recommendation',\n",
       " 'botany',\n",
       " 'brain',\n",
       " 'brain-stem',\n",
       " 'breathing',\n",
       " 'calcium',\n",
       " 'cancer',\n",
       " 'carbohydrates',\n",
       " 'cardiology',\n",
       " 'cas9',\n",
       " 'ccp4',\n",
       " 'cdna',\n",
       " 'celiac-disease',\n",
       " 'cell',\n",
       " 'cell-based',\n",
       " 'cell-biology',\n",
       " 'cell-culture',\n",
       " 'cell-cycle',\n",
       " 'cell-division',\n",
       " 'cell-membrane',\n",
       " 'cell-signaling',\n",
       " 'cell-sorting',\n",
       " 'cellular-respiration',\n",
       " 'central-nervous-system',\n",
       " 'centrifugation',\n",
       " 'chembl',\n",
       " 'chemical-communication',\n",
       " 'chickens',\n",
       " 'chimerism',\n",
       " 'chip',\n",
       " 'chip-seq',\n",
       " 'chirality',\n",
       " 'chloroplasts',\n",
       " 'cholesterol',\n",
       " 'chromatin',\n",
       " 'chromatography',\n",
       " 'chromosome',\n",
       " 'chronic',\n",
       " 'chronobiology',\n",
       " 'cilia',\n",
       " 'circadian-rhythms',\n",
       " 'circulatory-system',\n",
       " 'cladistics',\n",
       " 'climate-change',\n",
       " 'clinical-trial',\n",
       " 'cloning',\n",
       " 'coa',\n",
       " 'cocaine',\n",
       " 'codon',\n",
       " 'codon-usage',\n",
       " 'cognition',\n",
       " 'collective-behaviour',\n",
       " 'communication',\n",
       " 'community',\n",
       " 'community-ecology',\n",
       " 'competent-cells',\n",
       " 'complexity',\n",
       " 'computational-model',\n",
       " 'congestion',\n",
       " 'conservation-biology',\n",
       " 'coot',\n",
       " 'copy-number-variation',\n",
       " 'cpg',\n",
       " 'cranial-nerves',\n",
       " 'crispr',\n",
       " 'crocus-sativus',\n",
       " 'crossover',\n",
       " 'cryonics',\n",
       " 'cycle',\n",
       " 'cytogenetics',\n",
       " 'cytokinesis',\n",
       " 'cytoskeleton',\n",
       " 'data',\n",
       " 'database',\n",
       " 'death',\n",
       " 'decay',\n",
       " 'decomposition',\n",
       " 'definitions',\n",
       " 'dehydration',\n",
       " 'demography',\n",
       " 'dendrology',\n",
       " 'development',\n",
       " 'developmental-biology',\n",
       " 'diabetes-mellitus',\n",
       " 'diet',\n",
       " 'differentiation',\n",
       " 'digestion',\n",
       " 'digestive-system',\n",
       " 'dissection',\n",
       " 'dissociation-constant',\n",
       " 'diy-biology',\n",
       " 'dna',\n",
       " 'dna-damage',\n",
       " 'dna-helix',\n",
       " 'dna-isolation',\n",
       " 'dna-methylation',\n",
       " 'dna-repair',\n",
       " 'dna-replication',\n",
       " 'dna-sequencing',\n",
       " 'dnapolymerase',\n",
       " 'dogs',\n",
       " 'dopamine',\n",
       " 'dosage-compensation',\n",
       " 'dose',\n",
       " 'dreaming',\n",
       " 'drosophila',\n",
       " 'dynorphin',\n",
       " 'ebola',\n",
       " 'echolocation',\n",
       " 'ecoli',\n",
       " 'ecology',\n",
       " 'ecophysiology',\n",
       " 'ecosystem',\n",
       " 'eeg',\n",
       " 'electrical-stimulation',\n",
       " 'electrocardiography',\n",
       " 'electroencephalography',\n",
       " 'electromuscular',\n",
       " 'electrophysiology',\n",
       " 'elisa',\n",
       " 'embryology',\n",
       " 'endocrinology',\n",
       " 'endothelium',\n",
       " 'energy',\n",
       " 'entomology',\n",
       " 'environment',\n",
       " 'enzyme-kinetics',\n",
       " 'enzymes',\n",
       " 'epidemiology',\n",
       " 'epigenetics',\n",
       " 'ethnobiology',\n",
       " 'ethology',\n",
       " 'eukaryotic-cells',\n",
       " 'event-related-potential',\n",
       " 'evo-devo',\n",
       " 'evolution',\n",
       " 'evolutionary-game-theory',\n",
       " 'excreta',\n",
       " 'exercise',\n",
       " 'exons',\n",
       " 'experiment',\n",
       " 'experimental-design',\n",
       " 'extinction',\n",
       " 'extra-cellular-matrix',\n",
       " 'extremophiles',\n",
       " 'eyes',\n",
       " 'fat-metabolism',\n",
       " 'fatty-acid-synthase',\n",
       " 'feline',\n",
       " 'fitness',\n",
       " 'flight',\n",
       " 'flow-cytometry',\n",
       " 'flowering',\n",
       " 'fluorescent-microscopy',\n",
       " 'food',\n",
       " 'food-web',\n",
       " 'forensics',\n",
       " 'forest',\n",
       " 'forward-genetics',\n",
       " 'fret',\n",
       " 'fst',\n",
       " 'gamete',\n",
       " 'gastroenterology',\n",
       " 'gel-electrophoresis',\n",
       " 'gender',\n",
       " 'gene',\n",
       " 'gene-annotation',\n",
       " 'gene-expression',\n",
       " 'gene-regulation',\n",
       " 'gene-synthesis',\n",
       " 'gene-therapy',\n",
       " 'general-biology',\n",
       " 'genetic-code',\n",
       " 'genetic-diagrams',\n",
       " 'genetic-linkage',\n",
       " 'genetics',\n",
       " 'genomes',\n",
       " 'genomics',\n",
       " 'germination',\n",
       " 'global-warming',\n",
       " 'glucose',\n",
       " 'golgi-body',\n",
       " 'green-fluorescent-protein',\n",
       " 'growth',\n",
       " 'growth-media',\n",
       " 'gustation',\n",
       " 'gwas',\n",
       " 'gynecology',\n",
       " 'habitat',\n",
       " 'hair',\n",
       " 'hallucinogens',\n",
       " 'hardy-weinberg',\n",
       " 'healing',\n",
       " 'health',\n",
       " 'hearing',\n",
       " 'heart-failure',\n",
       " 'heart-output',\n",
       " 'hematology',\n",
       " 'hepatitis',\n",
       " 'herpetology',\n",
       " 'high-throughput',\n",
       " 'histamine',\n",
       " 'histology',\n",
       " 'histone',\n",
       " 'histone-deacetylase',\n",
       " 'histone-modifications',\n",
       " 'histopathology',\n",
       " 'hiv',\n",
       " 'hla',\n",
       " 'homeostasis',\n",
       " 'homework',\n",
       " 'homocysteine',\n",
       " 'homology',\n",
       " 'homosexuality',\n",
       " 'horizontal-gene-transfer',\n",
       " 'host-pathogen-interaction',\n",
       " 'human',\n",
       " 'human-anatomy',\n",
       " 'human-biology',\n",
       " 'human-ear',\n",
       " 'human-evolution',\n",
       " 'human-eye',\n",
       " 'human-genetics',\n",
       " 'human-genome',\n",
       " 'human-physiology',\n",
       " 'hybridization',\n",
       " 'hydration',\n",
       " 'hygiene',\n",
       " 'hyperplasia',\n",
       " 'hypersensitivity',\n",
       " 'hypothalamus',\n",
       " 'icgc',\n",
       " 'ichthyology',\n",
       " 'identification',\n",
       " 'image-processing',\n",
       " 'imaging',\n",
       " 'immune-system',\n",
       " 'immunity',\n",
       " 'immunoglobin',\n",
       " 'immunology',\n",
       " 'immunosuppression',\n",
       " 'implantation',\n",
       " 'indicator',\n",
       " 'infection',\n",
       " 'inflammation',\n",
       " 'influenza',\n",
       " 'information',\n",
       " 'information-theory',\n",
       " 'inheritance',\n",
       " 'injury',\n",
       " 'instinct',\n",
       " 'insulin',\n",
       " 'intelligence',\n",
       " 'intracellular-transport',\n",
       " 'introns',\n",
       " 'invasive-species',\n",
       " 'invertebrates',\n",
       " 'iris',\n",
       " 'isoforms',\n",
       " 'joints',\n",
       " 'kidney',\n",
       " 'kinetics',\n",
       " 'lab-reagents',\n",
       " 'lab-techniques',\n",
       " 'landscape-ecology',\n",
       " 'lcr',\n",
       " 'lentivirus',\n",
       " 'lepidoptera',\n",
       " 'life',\n",
       " 'life-history',\n",
       " 'lifespan',\n",
       " 'ligation',\n",
       " 'light',\n",
       " 'limnology',\n",
       " 'linguistics',\n",
       " 'lipids',\n",
       " 'literature',\n",
       " 'literature-search',\n",
       " 'locomotion',\n",
       " 'lungs',\n",
       " 'lymph',\n",
       " 'lymphatic',\n",
       " 'lymphoma',\n",
       " 'macroevolution',\n",
       " 'malaria',\n",
       " 'mammals',\n",
       " 'marine-biology',\n",
       " 'marsupials',\n",
       " 'mass-spec',\n",
       " 'mass-spectrometry',\n",
       " 'mathematical-models',\n",
       " 'measurement',\n",
       " 'medicinal-chemistry',\n",
       " 'medicine',\n",
       " 'medium',\n",
       " 'meiosis',\n",
       " 'melanin',\n",
       " 'melatonin',\n",
       " 'membrane',\n",
       " 'membrane-transport',\n",
       " 'memory',\n",
       " 'menstrual-cycle',\n",
       " 'metabolism',\n",
       " 'metabolomics',\n",
       " 'methods',\n",
       " 'mhc',\n",
       " 'mice',\n",
       " 'microarray',\n",
       " 'microbiology',\n",
       " 'microbiome',\n",
       " 'microrna',\n",
       " 'microscopy',\n",
       " 'migration',\n",
       " 'mimicry',\n",
       " 'minerals',\n",
       " 'minipreps',\n",
       " 'mitochondria',\n",
       " 'mitosis',\n",
       " 'molecular-biology',\n",
       " 'molecular-evolution',\n",
       " 'molecular-genetics',\n",
       " 'molluscs',\n",
       " 'morphology',\n",
       " 'morphometry',\n",
       " 'mouse',\n",
       " 'movement',\n",
       " 'mri',\n",
       " 'mrna',\n",
       " 'muscles',\n",
       " 'mushroom',\n",
       " 'mutations',\n",
       " 'mycology',\n",
       " 'mycoplasma',\n",
       " 'natural-selection',\n",
       " 'ncbi',\n",
       " 'network',\n",
       " 'neural-engineering',\n",
       " 'neuroanatomy',\n",
       " 'neurodegerative-disorders',\n",
       " 'neurology',\n",
       " 'neuromodulation',\n",
       " 'neurophysiology',\n",
       " 'neuroplasticity',\n",
       " 'neuroscience',\n",
       " 'neurotransmitter',\n",
       " 'nomenclature',\n",
       " 'noncoding-rna',\n",
       " 'nose',\n",
       " 'nucleic-acids',\n",
       " 'nutrition',\n",
       " 'odour',\n",
       " 'olfaction',\n",
       " 'ontogeny',\n",
       " 'ontology',\n",
       " 'oogenesis',\n",
       " 'openaccess',\n",
       " 'operons',\n",
       " 'opioid',\n",
       " 'optics',\n",
       " 'orf',\n",
       " 'organelle',\n",
       " 'organic-chemistry',\n",
       " 'organs',\n",
       " 'ornithology',\n",
       " 'osmoregulation',\n",
       " 'osmosis',\n",
       " 'ovulation',\n",
       " 'pain',\n",
       " 'palaeontology',\n",
       " 'parasitism',\n",
       " 'parasitology',\n",
       " 'pathogenesis',\n",
       " 'pathology',\n",
       " 'pathophysiology',\n",
       " 'pathway',\n",
       " 'pcr',\n",
       " 'pdb',\n",
       " 'pedigree',\n",
       " 'peer-review-journal',\n",
       " 'perception',\n",
       " 'peripheral-nervous-system',\n",
       " 'pest-control',\n",
       " 'pets',\n",
       " 'ph',\n",
       " 'pharmacodynamics',\n",
       " 'pharmacokinetics',\n",
       " 'pharmacology',\n",
       " 'phenology',\n",
       " 'philosophy-of-science',\n",
       " 'phosphate',\n",
       " 'phosphorylation',\n",
       " 'photography',\n",
       " 'photoperiod',\n",
       " 'photosynthesis',\n",
       " 'phylogenetics',\n",
       " 'physiology',\n",
       " 'pigmentation',\n",
       " 'plant-anatomy',\n",
       " 'plant-perception',\n",
       " 'plant-physiology',\n",
       " 'plasma-membrane',\n",
       " 'plasmids',\n",
       " 'plasticity',\n",
       " 'poison',\n",
       " 'polymerase',\n",
       " 'polyploidy',\n",
       " 'population-biology',\n",
       " 'population-dynamics',\n",
       " 'population-genetics',\n",
       " 'predation',\n",
       " 'pregnancy',\n",
       " 'primer',\n",
       " 'prion',\n",
       " 'prokaryotes',\n",
       " 'prokaryotic-cells',\n",
       " 'protein-binding',\n",
       " 'protein-engineering',\n",
       " 'protein-evolution',\n",
       " 'protein-expression',\n",
       " 'protein-folding',\n",
       " 'protein-interaction',\n",
       " 'protein-structure',\n",
       " 'proteins',\n",
       " 'proteomics',\n",
       " 'protocol',\n",
       " 'pseudogenes',\n",
       " 'psychology',\n",
       " 'psychoneuropharmacology',\n",
       " 'psychophysics',\n",
       " 'publication',\n",
       " 'publishing',\n",
       " 'pulmonology',\n",
       " 'purification',\n",
       " 'pymol',\n",
       " 'quantitative-genetics',\n",
       " 'quorum-sensing',\n",
       " 'radiation',\n",
       " 'receptor',\n",
       " 'recombinant',\n",
       " 'recombination',\n",
       " 'red-blood-cell',\n",
       " 'reference-request',\n",
       " 'reflexes',\n",
       " 'regeneration',\n",
       " 'renal-physiology',\n",
       " 'replication',\n",
       " 'reproduction',\n",
       " 'reproductive-biology',\n",
       " 'reptile',\n",
       " 'research-design',\n",
       " 'research-process',\n",
       " 'research-tools',\n",
       " 'respiration',\n",
       " 'restriction-enzymes',\n",
       " 'retrovirus',\n",
       " 'reverse-genetics',\n",
       " 'reverse-transcription',\n",
       " 'review',\n",
       " 'ribosome',\n",
       " 'rna',\n",
       " 'rna-interference',\n",
       " 'rna-sequencing',\n",
       " 'rodents',\n",
       " 'rrna',\n",
       " 'saliva',\n",
       " 'sar',\n",
       " 'scales',\n",
       " 'scatology',\n",
       " 'scientific-literature',\n",
       " 'sds-page',\n",
       " 'selection',\n",
       " 'senescence',\n",
       " 'sensation',\n",
       " 'senses',\n",
       " 'sensory-systems',\n",
       " 'sepsis',\n",
       " 'sequence-alignment',\n",
       " 'sequence-analysis',\n",
       " 'sequence-assembly',\n",
       " 'serotonin',\n",
       " 'sex',\n",
       " 'sex-chromosome',\n",
       " 'sex-determination',\n",
       " 'sex-ratio',\n",
       " 'sexual-dimorphism',\n",
       " 'sexual-reproduction',\n",
       " 'sexual-selection',\n",
       " 'sexuality',\n",
       " 'signal-processing',\n",
       " 'signalling',\n",
       " 'sirs',\n",
       " 'sleep',\n",
       " 'small-rnaseq',\n",
       " 'snake',\n",
       " 'snp',\n",
       " 'sociality',\n",
       " 'sociobiology',\n",
       " 'soil',\n",
       " 'speciation',\n",
       " 'species',\n",
       " 'species-distribution',\n",
       " 'species-identification',\n",
       " 'speculative',\n",
       " 'spliceosome',\n",
       " 'splicing',\n",
       " 'staining',\n",
       " 'statistics',\n",
       " 'stem-cells',\n",
       " 'sterilisation',\n",
       " 'stomach',\n",
       " 'stress',\n",
       " 'structural-biology',\n",
       " 'structure-prediction',\n",
       " 'surgery',\n",
       " 'symbiosis',\n",
       " 'synapses',\n",
       " 'synestesia',\n",
       " 'synthetic-biology',\n",
       " 'systems-biology',\n",
       " 't7-promoter',\n",
       " 'taste',\n",
       " 'taxonomy',\n",
       " 'tcga',\n",
       " 'teeth',\n",
       " 'telomere',\n",
       " 'teratology',\n",
       " 'terminology',\n",
       " 'territoriality',\n",
       " 'theoretical-biology',\n",
       " 'thermodynamics',\n",
       " 'thermophilia',\n",
       " 'tissue',\n",
       " 'tissue-repair',\n",
       " 'touch',\n",
       " 'toxicology',\n",
       " 'transcription',\n",
       " 'transcription-factor',\n",
       " 'transdermal',\n",
       " 'transfection',\n",
       " 'transformation',\n",
       " 'transfusion',\n",
       " 'translation',\n",
       " 'transplantation',\n",
       " 'treatment',\n",
       " 'trees',\n",
       " 'tuberculosis',\n",
       " 'tumor',\n",
       " 'twins',\n",
       " 'ultrasound',\n",
       " 'underwater',\n",
       " 'units',\n",
       " 'uv',\n",
       " 'vaccination',\n",
       " 'variant',\n",
       " 'vegetable',\n",
       " 'vegetarianism',\n",
       " 'vegetation',\n",
       " 'veins',\n",
       " 'ventricles',\n",
       " 'vertebrates',\n",
       " 'vessel',\n",
       " 'vestigial',\n",
       " 'veterinary-medicine',\n",
       " 'virology',\n",
       " 'virus',\n",
       " 'vision',\n",
       " 'visual-system',\n",
       " 'visualization',\n",
       " 'wasps',\n",
       " 'waste-disposal',\n",
       " 'western-blot',\n",
       " 'xray-crystallography',\n",
       " 'zoology'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains_tag_sets[0] - domains_tag_sets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81926, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is spin as it relates to subatomic partic...</td>\n",
       "      <td>&lt;p&gt;I often hear about subatomic particles havi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What is your simplest explanation of the strin...</td>\n",
       "      <td>&lt;p&gt;How would you explain string theory to non ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Lie theory, Representations and particle physics</td>\n",
       "      <td>&lt;p&gt;This is a question that has been posted at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Will Determinism be ever possible?</td>\n",
       "      <td>&lt;p&gt;What are the main problems that we need to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Hamilton's Principle</td>\n",
       "      <td>&lt;p&gt;Hamilton's principle states that a dynamic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>What is sound and how is it produced?</td>\n",
       "      <td>&lt;p&gt;I've been using the term \"sound\" all my lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>What experiment would disprove string theory?</td>\n",
       "      <td>&lt;p&gt;I know that there's big controversy between...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>Why does the sky change color? Why the sky is ...</td>\n",
       "      <td>&lt;p&gt;Why does the sky change color? Why the sky ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>How's the energy of particle collisions calcul...</td>\n",
       "      <td>&lt;p&gt;Physicists often refer to the energy of col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>Monte Carlo use</td>\n",
       "      <td>&lt;p&gt;Where is the Monte Carlo method used in phy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  What is spin as it relates to subatomic partic...   \n",
       "1   2  What is your simplest explanation of the strin...   \n",
       "2   3   Lie theory, Representations and particle physics   \n",
       "3   7                 Will Determinism be ever possible?   \n",
       "4   9                               Hamilton's Principle   \n",
       "5  13              What is sound and how is it produced?   \n",
       "6  15      What experiment would disprove string theory?   \n",
       "7  17  Why does the sky change color? Why the sky is ...   \n",
       "8  19  How's the energy of particle collisions calcul...   \n",
       "9  21                                    Monte Carlo use   \n",
       "\n",
       "                                             content  \n",
       "0  <p>I often hear about subatomic particles havi...  \n",
       "1  <p>How would you explain string theory to non ...  \n",
       "2  <p>This is a question that has been posted at ...  \n",
       "3  <p>What are the main problems that we need to ...  \n",
       "4  <p>Hamilton's principle states that a dynamic ...  \n",
       "5  <p>I've been using the term \"sound\" all my lif...  \n",
       "6  <p>I know that there's big controversy between...  \n",
       "7  <p>Why does the sky change color? Why the sky ...  \n",
       "8  <p>Physicists often refer to the energy of col...  \n",
       "9  <p>Where is the Monte Carlo method used in phy...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(DATA_FOLDER + TEST_FILE)\n",
    "print(df_test.shape)\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_contents = df_test['content'].tolist()\n",
    "test_titles = df_test['title'].tolist()\n",
    "test_titles_contents = (df_test['title'] + ' ' + df_test['content']).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove [n]\n",
    "# remove pure numbers, don't remove letter+number words, like CO2\n",
    "\n",
    "# remove stopwords\n",
    "# consider µL?\n",
    "# remove formulas\n",
    "\n",
    "\n",
    "numbers = set('0123456789-')\n",
    "\n",
    "def is_useful_word(word):\n",
    "    return (word not in useless_words) and (len(word) > 2) and (re.search('[a-z]', word)) and (word[0] not in numbers)\n",
    "    \n",
    "\n",
    "def cleanse_html(content):\n",
    "    content = BeautifulSoup(content, \"lxml\").get_text()\n",
    "\n",
    "    # remove urls\n",
    "    content = re.sub(r\"\\S+:/\\S+\",\"\", content)  # \"xxx:/xxx\"\n",
    "    content = re.sub(r\"\\S+\\\\\\S+\",\"\", content)  # \"xxx\\xxx\"\n",
    "    \n",
    "    return content\n",
    "    \n",
    "\n",
    "def cleanse_lower_split(content):\n",
    "    # remove html tags\n",
    "    content = BeautifulSoup(content, \"lxml\").get_text()\n",
    "    \n",
    "    # remove urls\n",
    "    content = re.sub(r\"\\S+:/\\S+\",\"\", content)  # \"xxx:/xxx\"\n",
    "    content = re.sub(r\"\\S+\\\\\\S+\",\"\", content)  # \"xxx\\xxx\"\n",
    "    \n",
    "    # replace punctuations and numbers with whitespaces\n",
    "    content = re.sub(r\"[^a-zA-Z0-9\\-]\",\" \", content)\n",
    "        \n",
    "    # convert to lowercase\n",
    "    content = content.lower()\n",
    "    \n",
    "    words = content.split()\n",
    "    \n",
    "    # remove useless words\n",
    "    # stopwords, pure numbers, short words\n",
    "    words = [word for word in words if is_useful_word(word)]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# only reserve words.\n",
    "def cleanse(content):\n",
    "    # remove html tags\n",
    "    content = BeautifulSoup(content, \"lxml\").get_text()\n",
    "    \n",
    "    # remove urls\n",
    "    content = re.sub(r\"\\S+:/\\S+\",\"\", content)  # \"xxx:/xxx\"\n",
    "    content = re.sub(r\"\\S+\\\\\\S+\",\"\", content)  # \"xxx\\xxx\"\n",
    "    \n",
    "    # replace punctuations and numbers with whitespaces\n",
    "    content = re.sub(r\"[^a-zA-Z0-9\\-]\",\" \", content)\n",
    "        \n",
    "    # convert to lowercase\n",
    "    content = content.lower()\n",
    "    \n",
    "    words = content.split()\n",
    "    \n",
    "    # remove useless words\n",
    "    # stopwords, pure numbers, short words\n",
    "    words = [word for word in words if is_useful_word(word)]\n",
    "    \n",
    "    # concat words to a string\n",
    "    content = ' '.join(words)\n",
    "    \n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_word(s):\n",
    "    # if s start with english letter \n",
    "    return (re.search('[a-z]', s[0]))\n",
    "\n",
    "def cleanse_and_split_sentence(s):\n",
    "    # input a sentence, output a list of words\n",
    "    s = re.sub(r\"[^a-zA-Z0-9]\",\" \", s)\n",
    "    word_seq = s.lower().split()\n",
    "    word_seq = [word for word in word_seq if is_word(word)]\n",
    "        \n",
    "    return word_seq\n",
    "    \n",
    "# cleanse and cut sentences\n",
    "def cleanse_content_for_w2v(content):\n",
    "    # output format: [['i', 'don', 't', 'have', 'an', 'apple-pen'], ['there', 's', 'co2', 'in']]\n",
    "    content = BeautifulSoup(content, \"lxml\").get_text()\n",
    "    \n",
    "    content = re.sub(r\"\\S+:/\\S+\",\"\", content)  # \"xxx:/xxx\"\n",
    "    content = re.sub(r\"\\S+\\\\\\S+\",\"\", content)  # \"xxx\\xxx\"\n",
    "    \n",
    "    sentences = tokenizer.tokenize(content)\n",
    "    \n",
    "    word_seqs = []\n",
    "    for s in sentences:\n",
    "        word_seq = cleanse_and_split_sentence(s)\n",
    "        # if len(word_seq) >= 3:\n",
    "        word_seqs.append(word_seq)\n",
    "    \n",
    "    return word_seqs\n",
    "\n",
    "# not removing stopwords here\n",
    "def cleanse_content_for_tfidf(content):\n",
    "    # output format: [['i', 'don', 't', 'have', 'an', 'apple-pen'], ['there', 's', 'co2', 'in']]\n",
    "    content = BeautifulSoup(content, \"lxml\").get_text()\n",
    "    \n",
    "    content = re.sub(r\"\\S+:/\\S+\",\"\", content)  # \"xxx:/xxx\"\n",
    "    content = re.sub(r\"\\S+\\\\\\S+\",\"\", content)  # \"xxx\\xxx\"\n",
    "    \n",
    "    word_seq = cleanse_and_split_sentence(content)\n",
    "    \n",
    "    return word_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'don', 't', 'have', 'an', 'apple', 'pen'], ['there', 's', 'co2', 'in']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = \"I don't 'have' an apple-pen. There's 256 CO2 in 10km^3!\"\n",
    "cleanse_content_for_w2v(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'often', 'hear', 'about', 'subatomic', 'particles', 'having', 'a', 'property', 'called', 'spin', 'but', 'also', 'that', 'it', 'doesn', 't', 'actually', 'relate', 'to', 'spinning', 'about', 'an', 'axis', 'like', 'you', 'would', 'think'], ['which', 'particles', 'have', 'spin'], ['what', 'does', 'spin', 'mean', 'if', 'not', 'an', 'actual', 'spinning', 'motion']]\n",
      "----\n",
      "[['how', 'would', 'you', 'explain', 'string', 'theory', 'to', 'non', 'physicists', 'such', 'as', 'myself'], ['i', 'm', 'specially', 'interested', 'on', 'how', 'plausible', 'is', 'it', 'and', 'what', 'is', 'needed', 'to', 'successfully', 'prove', 'it']]\n",
      "----\n",
      "[['this', 'is', 'a', 'question', 'that', 'has', 'been', 'posted', 'at', 'many', 'different', 'forums', 'i', 'thought', 'maybe', 'someone', 'here', 'would', 'have', 'a', 'better', 'or', 'more', 'conceptual', 'answer', 'than', 'i', 'have', 'seen', 'before', 'why', 'do', 'physicists', 'care', 'about', 'representations', 'of', 'lie', 'groups'], ['for', 'myself', 'when', 'i', 'think', 'about', 'a', 'representation', 'that', 'means', 'there', 'is', 'some', 'sort', 'of', 'group', 'acting', 'on', 'a', 'vector', 'space', 'what', 'is', 'the', 'vector', 'space', 'that', 'this', 'lie', 'group', 'is', 'acting', 'on'], ['or', 'is', 'it', 'that', 'certain', 'things', 'have', 'to', 'be', 'invariant', 'under', 'a', 'group', 'action'], ['maybe', 'this', 'is', 'a', 'dumb', 'question', 'but', 'i', 'thought', 'it', 'might', 'be', 'a', 'good', 'start', 'to', 'clarify', 'i', 'am', 'specifically', 'thinking', 'of', 'the', 'symmetry', 'groups', 'that', 'people', 'think', 'about', 'in', 'relation', 'to', 'the', 'standard', 'model'], ['i', 'do', 'not', 'care', 'why', 'it', 'might', 'be', 'a', 'certain', 'group', 'but', 'more', 'how', 'we', 'see', 'the', 'group', 'acting', 'what', 'is', 'it', 'acting', 'on'], ['etc']]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for content in test_contents[:3]:\n",
    "    print(cleanse_content_for_w2v(content))\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare w2v training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_line(lst):\n",
    "    for s in lst:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleansed_train_domains_titles = []\n",
    "for df in df_trains:\n",
    "    word_seqs = []\n",
    "    for title in df['title'].tolist():\n",
    "        word_seqs.extend(cleanse_content_for_w2v(title))\n",
    "    cleansed_train_domains_titles.append(word_seqs)\n",
    "\n",
    "cleansed_train_domains_contents = []\n",
    "for df in df_trains:\n",
    "    word_seqs = []\n",
    "    for content in df['content'].tolist():\n",
    "        word_seqs.extend(cleanse_content_for_w2v(content))\n",
    "    cleansed_train_domains_contents.append(word_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13518\n",
      "15786\n",
      "10614\n",
      "26574\n",
      "2824\n",
      "20001\n",
      "\n",
      "69511\n",
      "82281\n",
      "69281\n",
      "180431\n",
      "19551\n",
      "104301\n",
      "[['what', 'are', 'some', 'caribbean', 'cruises', 'for', 'october'], ['how', 'can', 'i', 'find', 'a', 'guide', 'that', 'will', 'take', 'me', 'safely', 'through', 'the', 'amazon', 'jungle'], ['does', 'singapore', 'airlines', 'offer', 'any', 'reward', 'seats', 'on', 'their', 'ewr', 'sin', 'route']]\n",
      "[['my', 'fianc', 'e', 'and', 'i', 'are', 'looking', 'for', 'a', 'good', 'caribbean', 'cruise', 'in', 'october', 'and', 'were', 'wondering', 'which', 'islands', 'are', 'best', 'to', 'see', 'and', 'which', 'cruise', 'line', 'to', 'take'], ['it', 'seems', 'like', 'a', 'lot', 'of', 'the', 'cruises', 'don', 't', 'run', 'in', 'this', 'month', 'due', 'to', 'hurricane', 'season', 'so', 'i', 'm', 'looking', 'for', 'other', 'good', 'options'], ['edit', 'we', 'll', 'be', 'travelling', 'in']]\n"
     ]
    }
   ],
   "source": [
    "for cleansed_train_titles in cleansed_train_domains_titles:\n",
    "    print(len(cleansed_train_titles))\n",
    "print()\n",
    "for cleansed_train_contents in cleansed_train_domains_contents:\n",
    "    print(len(cleansed_train_contents))\n",
    "print(cleansed_train_domains_titles[5][:3])\n",
    "print(cleansed_train_domains_contents[5][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df_test\n",
    "\n",
    "cleansed_test_titles = []\n",
    "for title in df['title'].tolist():\n",
    "    cleansed_test_titles.extend(cleanse_content_for_w2v(title))\n",
    "\n",
    "cleansed_test_contents = []\n",
    "for content in df['content'].tolist():\n",
    "    cleansed_test_contents.extend(cleanse_content_for_w2v(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83757\n",
      "494470\n",
      "[['what', 'is', 'spin', 'as', 'it', 'relates', 'to', 'subatomic', 'particles'], ['what', 'is', 'your', 'simplest', 'explanation', 'of', 'the', 'string', 'theory'], ['lie', 'theory', 'representations', 'and', 'particle', 'physics']]\n",
      "[['i', 'often', 'hear', 'about', 'subatomic', 'particles', 'having', 'a', 'property', 'called', 'spin', 'but', 'also', 'that', 'it', 'doesn', 't', 'actually', 'relate', 'to', 'spinning', 'about', 'an', 'axis', 'like', 'you', 'would', 'think'], ['which', 'particles', 'have', 'spin'], ['what', 'does', 'spin', 'mean', 'if', 'not', 'an', 'actual', 'spinning', 'motion']]\n"
     ]
    }
   ],
   "source": [
    "print(len(cleansed_test_titles))\n",
    "print(len(cleansed_test_contents))\n",
    "print(cleansed_test_titles[:3])\n",
    "print(cleansed_test_contents[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleansed_all_w2v = []\n",
    "cleansed_train_titles_contents_w2v = []\n",
    "cleansed_test_titles_contents_w2v = []\n",
    "\n",
    "for cleansed_train_titles in cleansed_train_domains_titles:\n",
    "    cleansed_train_titles_contents_w2v.extend(cleansed_train_titles)\n",
    "for cleansed_train_contents in cleansed_train_domains_contents:\n",
    "    cleansed_train_titles_contents_w2v.extend(cleansed_train_contents)\n",
    "    \n",
    "cleansed_test_titles_contents_w2v.extend(cleansed_test_titles)\n",
    "cleansed_test_titles_contents_w2v.extend(cleansed_test_contents)\n",
    "\n",
    "cleansed_all_w2v.extend(cleansed_train_titles_contents_w2v)\n",
    "cleansed_all_w2v.extend(cleansed_test_titles_contents_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614673\n",
      "578227\n",
      "1192900\n"
     ]
    }
   ],
   "source": [
    "train_sentence_count = len(cleansed_train_titles_contents_w2v)\n",
    "test_sentence_count = len(cleansed_test_titles_contents_w2v)\n",
    "all_sentence_count = len(cleansed_all_w2v)\n",
    "print(train_sentence_count)\n",
    "print(test_sentence_count)\n",
    "print(all_sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['what', 'is', 'spin', 'as', 'it', 'relates', 'to', 'subatomic', 'particles'],\n",
       " ['what',\n",
       "  'is',\n",
       "  'your',\n",
       "  'simplest',\n",
       "  'explanation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'string',\n",
       "  'theory'],\n",
       " ['lie', 'theory', 'representations', 'and', 'particle', 'physics'],\n",
       " ['will', 'determinism', 'be', 'ever', 'possible'],\n",
       " ['hamilton', 's', 'principle'],\n",
       " ['what', 'is', 'sound', 'and', 'how', 'is', 'it', 'produced'],\n",
       " ['what', 'experiment', 'would', 'disprove', 'string', 'theory'],\n",
       " ['why',\n",
       "  'does',\n",
       "  'the',\n",
       "  'sky',\n",
       "  'change',\n",
       "  'color',\n",
       "  'why',\n",
       "  'the',\n",
       "  'sky',\n",
       "  'is',\n",
       "  'blue',\n",
       "  'during',\n",
       "  'the',\n",
       "  'day',\n",
       "  'red',\n",
       "  'during',\n",
       "  'sunrise',\n",
       "  'set',\n",
       "  'and',\n",
       "  'black',\n",
       "  'during',\n",
       "  'the',\n",
       "  'night'],\n",
       " ['how', 's', 'the', 'energy', 'of', 'particle', 'collisions', 'calculated'],\n",
       " ['monte', 'carlo', 'use']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_test\n",
    "\n",
    "cleansed_test_titles_tfidf = []\n",
    "for title in df['title'].tolist():\n",
    "    cleansed_test_titles_tfidf.append(cleanse_content_for_tfidf(title))\n",
    "\n",
    "print(len(cleansed_test_titles_tfidf))\n",
    "cleansed_test_titles_tfidf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### connect phrases by bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connect_phrases_bigram(word_seqs):\n",
    "    bigram_transformer = phrases.Phrases(word_seqs, min_count=20, threshold=1)\n",
    "    word_seqs_phrased_bigram = []\n",
    "    for word_seq in word_seqs:\n",
    "        word_seq_phrased = bigram_transformer[word_seq]\n",
    "        word_seq_phrased = [re.sub(r'_', '-', word) for word in word_seq_phrased]\n",
    "        word_seqs_phrased_bigram.append(word_seq_phrased)\n",
    "    \n",
    "    return bigram_transformer, word_seqs_phrased_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connect_phrases_with_bigram(word_seqs, bigram_transformer):\n",
    "    word_seqs_phrased_bigram = []\n",
    "    for word_seq in word_seqs:\n",
    "        word_seq_phrased = bigram_transformer[word_seq]\n",
    "        word_seq_phrased = [re.sub(r'_', '-', word) for word in word_seq_phrased]\n",
    "        word_seqs_phrased_bigram.append(word_seq_phrased)\n",
    "    return word_seqs_phrased_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_bigram, test_phrased_bigram = connect_phrases_bigram(cleansed_test_titles_contents_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'electricity', 'instantaneous']\n",
      "['how-can', 'i', 'determine', 'transmission', 'reflection', 'coefficients', 'for', 'light']\n",
      "['the', 'principle-behind', 'door', 'peepholes']\n",
      "['physics', 'and', 'computer-science']\n",
      "['why-don', 't', 'electric', 'fish', 'shock', 'themselves']\n",
      "['why', 'were', 'the', 'si', 'base', 'quantities', 'chosen', 'as', 'such']\n",
      "['how-can', 'i', 'measure', 'the', 'mass', 'of', 'the', 'earth', 'at-home']\n",
      "['home', 'experiments', 'to-derive', 'the', 'speed-of', 'light']\n",
      "['symmetrical', 'twin-paradox']\n",
      "['getting', 'started', 'self-studying', 'general-relativity']\n"
     ]
    }
   ],
   "source": [
    "# print_line(test_phrased_bigram[100:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_bigram.save('test_bigram_count20_threshold1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_bigram_vocab_dict = dict(test_bigram.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import operator\n",
    "# sorted_test_bigram_vocab_dict = sorted(test_bigram_vocab_dict.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'no', 15814),\n",
       " (b'system', 15786),\n",
       " (b'could', 15610),\n",
       " (b'd', 15509),\n",
       " (b'particle', 15340),\n",
       " (b'c', 15248),\n",
       " (b'get', 15199),\n",
       " (b'for_the', 15194),\n",
       " (b'its', 15107),\n",
       " (b'what_is', 14863)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorted_test_bigram_vocab_dict[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stopwords then phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model/stopwords.txt') as f:\n",
    "    long_stopwords = f.read().splitlines()\n",
    "\n",
    "stopwords = set(long_stopwords) | nltk_stopwords\n",
    "\n",
    "for word in list(stopwords):\n",
    "    for subword in re.sub(r\"[^a-z]\", ' ', word).split():\n",
    "        stopwords.add(subword)\n",
    "    stopwords.add(re.sub(r\"'\", '-', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "722"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(word_seqs):\n",
    "    removed = []\n",
    "    for word_seq in word_seqs:\n",
    "        removed.append([word for word in word_seq if word not in stopwords])\n",
    "    return removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleansed_test_titles_contents_no_stopwords = remove_stopwords(cleansed_test_titles_contents_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spin', 'relates', 'subatomic', 'particles'],\n",
       " ['simplest', 'explanation', 'string', 'theory'],\n",
       " ['lie', 'theory', 'representations', 'particle', 'physics'],\n",
       " ['determinism'],\n",
       " ['hamilton', 'principle']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansed_test_titles_contents_no_stopwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_bigram_nostop, test_phrased_bigram_nostop = connect_phrases_bigram(cleansed_test_titles_contents_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spin', 'relates', 'subatomic-particles'],\n",
       " ['simplest', 'explanation', 'string-theory'],\n",
       " ['lie', 'theory', 'representations', 'particle-physics'],\n",
       " ['determinism'],\n",
       " ['hamilton-principle'],\n",
       " ['sound-produced'],\n",
       " ['experiment', 'disprove', 'string-theory'],\n",
       " ['sky', 'change-color'],\n",
       " ['sky-blue', 'day', 'red', 'sunrise', 'set', 'black', 'night'],\n",
       " ['energy', 'particle', 'collisions', 'calculated'],\n",
       " ['monte-carlo'],\n",
       " ['leaning', 'banking', 'help', 'turning', 'bicycle'],\n",
       " ['velocity-object', 'electromagnetic-field'],\n",
       " ['difference', 'measurement', 'interaction', 'quantum-mechanics'],\n",
       " ['calculate-average', 'speed'],\n",
       " ['lay', 'explanation', 'special-theory', 'relativity'],\n",
       " ['coriolis', 'irrelevant', 'whirl', 'vortex', 'sink', 'bathtub'],\n",
       " ['magnets', 'energy', 'repel'],\n",
       " ['check', 'einstein-equations', 'correspondence', 'real'],\n",
       " ['impressions', 'topological', 'field-theories', 'mathematics'],\n",
       " ['capacitive', 'screen', 'sensing'],\n",
       " ['magnets', 'spin', 'positioned', 'precisely'],\n",
       " ['lhc', 'circular', 'long'],\n",
       " ['polarised', 'materials', 'change', 'colour', 'stress'],\n",
       " ['intuitive-explanation', 'gouy', 'phase'],\n",
       " ['proton', 'therapy', 'cancer', 'treatment'],\n",
       " ['physicists', 'solutions', 'yang', 'baxter', 'equation'],\n",
       " ['mnemonics', 'remember', 'properties-materials'],\n",
       " ['neutrons', 'repel'],\n",
       " ['quantum-entanglement', 'mediated', 'interaction']]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_phrased_bigram_nostop[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['what', 'is', 'spin', 'as', 'it', 'relates', 'to', 'subatomic', 'particles'],\n",
       " ['what',\n",
       "  'is',\n",
       "  'your',\n",
       "  'simplest',\n",
       "  'explanation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'string',\n",
       "  'theory'],\n",
       " ['lie', 'theory', 'representations', 'and', 'particle', 'physics'],\n",
       " ['will', 'determinism', 'be', 'ever', 'possible'],\n",
       " ['hamilton', 's', 'principle'],\n",
       " ['what', 'is', 'sound', 'and', 'how', 'is', 'it', 'produced'],\n",
       " ['what', 'experiment', 'would', 'disprove', 'string', 'theory'],\n",
       " ['why',\n",
       "  'does',\n",
       "  'the',\n",
       "  'sky',\n",
       "  'change',\n",
       "  'color',\n",
       "  'why',\n",
       "  'the',\n",
       "  'sky',\n",
       "  'is',\n",
       "  'blue',\n",
       "  'during',\n",
       "  'the',\n",
       "  'day',\n",
       "  'red',\n",
       "  'during',\n",
       "  'sunrise',\n",
       "  'set',\n",
       "  'and',\n",
       "  'black',\n",
       "  'during',\n",
       "  'the',\n",
       "  'night'],\n",
       " ['how', 's', 'the', 'energy', 'of', 'particle', 'collisions', 'calculated'],\n",
       " ['monte', 'carlo', 'use']]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansed_test_titles_tfidf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleansed_test_titles_tfidf_nostop = remove_stopwords(cleansed_test_titles_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spin', 'relates', 'subatomic', 'particles'],\n",
       " ['simplest', 'explanation', 'string', 'theory'],\n",
       " ['lie', 'theory', 'representations', 'particle', 'physics'],\n",
       " ['determinism'],\n",
       " ['hamilton', 'principle'],\n",
       " ['sound', 'produced'],\n",
       " ['experiment', 'disprove', 'string', 'theory'],\n",
       " ['sky',\n",
       "  'change',\n",
       "  'color',\n",
       "  'sky',\n",
       "  'blue',\n",
       "  'day',\n",
       "  'red',\n",
       "  'sunrise',\n",
       "  'set',\n",
       "  'black',\n",
       "  'night'],\n",
       " ['energy', 'particle', 'collisions', 'calculated'],\n",
       " ['monte', 'carlo']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansed_test_titles_tfidf_nostop[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cleansed_test_titles_tfidf\n",
    "\n",
    "cleansed_test_titles_tfidf_nostop_phrased = connect_phrases_with_bigram(cleansed_test_titles_tfidf_nostop, test_bigram_nostop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81926"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleansed_test_titles_tfidf_nostop_phrased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spin', 'relates', 'subatomic-particles'],\n",
       " ['simplest', 'explanation', 'string-theory'],\n",
       " ['lie', 'theory', 'representations', 'particle-physics'],\n",
       " ['determinism'],\n",
       " ['hamilton-principle'],\n",
       " ['sound-produced'],\n",
       " ['experiment', 'disprove', 'string-theory'],\n",
       " ['sky',\n",
       "  'change-color',\n",
       "  'sky-blue',\n",
       "  'day',\n",
       "  'red',\n",
       "  'sunrise',\n",
       "  'set',\n",
       "  'black',\n",
       "  'night'],\n",
       " ['energy', 'particle', 'collisions', 'calculated'],\n",
       " ['monte-carlo']]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansed_test_titles_tfidf_nostop_phrased[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connect_phrases(word_seqs):\n",
    "    bigram_transformer = phrases.Phrases(word_seqs)\n",
    "    word_seqs_phrased_bigram = []\n",
    "    for word_seq in word_seqs:\n",
    "        word_seq_phrased = bigram_transformer[word_seq]\n",
    "        word_seq_phrased = [re.sub(r'_', '-', word) for word in word_seq_phrased]\n",
    "        word_seqs_phrased_bigram.append(word_seq_phrased)\n",
    "    \n",
    "    trigram_transformer = phrases.Phrases(word_seqs_phrased_bigram)\n",
    "    word_seqs_phrased_trigram = []\n",
    "    for word_seq in word_seqs_phrased_bigram:\n",
    "        word_seq_phrased = trigram_transformer[word_seq]\n",
    "        word_seq_phrased = [re.sub(r'_', '-', word) for word in word_seq_phrased]\n",
    "        word_seqs_phrased_trigram.append(word_seq_phrased)\n",
    "    return bigram_transformer, trigram_transformer, word_seqs_phrased_bigram, word_seqs_phrased_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_bigram, all_trigram_transformer, all_phrased_bigram, all_phrased_trigram = connect_phrases(cleansed_all_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'spin', 'as', 'it', 'relates', 'to', 'subatomic-particles']\n",
      "['what', 'is', 'your', 'simplest', 'explanation', 'of', 'the', 'string-theory']\n",
      "['lie', 'theory', 'representations', 'and', 'particle', 'physics']\n",
      "['will', 'determinism', 'be', 'ever', 'possible']\n",
      "['hamilton-s-principle']\n",
      "['what', 'is', 'sound', 'and', 'how', 'is', 'it', 'produced']\n",
      "['what', 'experiment', 'would', 'disprove-string-theory']\n",
      "['why', 'does', 'the', 'sky', 'change', 'color']\n",
      "['why', 'the', 'sky', 'is', 'blue', 'during', 'the', 'day', 'red', 'during', 'sunrise', 'set', 'and', 'black', 'during', 'the', 'night']\n",
      "['how', 's', 'the', 'energy', 'of', 'particle', 'collisions', 'calculated']\n"
     ]
    }
   ],
   "source": [
    "print_line(all_phrased_trigram[train_sentence_count:train_sentence_count+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_bigram, test_trigram, test_phrased_bigram, test_phrased_trigram = connect_phrases(cleansed_test_titles_contents_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print_line(test_phrased_bigram[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print_line(test_phrased_trigram[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_bigram_vocab = dict(test_bigram.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_bigram_vocab_words = list(test_bigram_vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1410768"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_bigram_vocab_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'photograph_was',\n",
       " b'visual_aspect',\n",
       " b't_torus',\n",
       " b'metric_correspond',\n",
       " b'fresnel_it',\n",
       " b'desperate_hand',\n",
       " b'made_thick',\n",
       " b'rearranging_s',\n",
       " b'generate_pulse',\n",
       " b'they_know']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bigram_vocab_words[100000:100000+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleansed_test_titles_for_tfidf = [cleanse_content_for_tfidf(title) for title in df_test['title'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['what', 'is', 'spin', 'as', 'it', 'relates', 'to', 'subatomic', 'particles'],\n",
       " ['what',\n",
       "  'is',\n",
       "  'your',\n",
       "  'simplest',\n",
       "  'explanation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'string',\n",
       "  'theory'],\n",
       " ['lie', 'theory', 'representations', 'and', 'particle', 'physics'],\n",
       " ['will', 'determinism', 'be', 'ever', 'possible'],\n",
       " ['hamilton', 's', 'principle']]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansed_test_titles_for_tfidf[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleansed_test_titles_bigram = connect_phrases_bigram(cleansed_test_titles_for_tfidf)\n",
    "cleansed_test_titles_trigram = connect_phrases_trigram(cleansed_test_titles_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'spin', 'as', 'it', 'relates', 'to', 'subatomic-particles']\n",
      "['what', 'is', 'your', 'simplest', 'explanation', 'of', 'the', 'string-theory']\n",
      "['lie', 'theory', 'representations', 'and', 'particle-physics']\n",
      "['will', 'determinism', 'be', 'ever', 'possible']\n",
      "['hamilton-s-principle']\n",
      "['what', 'is', 'sound', 'and', 'how', 'is', 'it', 'produced']\n",
      "['what', 'experiment', 'would', 'disprove-string-theory']\n",
      "['why', 'does', 'the', 'sky', 'change', 'color', 'why', 'the', 'sky', 'is', 'blue', 'during', 'the', 'day', 'red', 'during', 'sunrise', 'set', 'and', 'black', 'during', 'the', 'night']\n",
      "['how', 's', 'the', 'energy', 'of', 'particle', 'collisions', 'calculated']\n",
      "['monte-carlo', 'use']\n",
      "['does', 'leaning', 'banking', 'help', 'cause', 'turning', 'on', 'a', 'bicycle']\n",
      "['velocity', 'of', 'object', 'from', 'electromagnetic-field']\n",
      "['what', 'is', 'the', 'difference-between', 'a', 'measurement', 'and', 'any', 'other', 'interaction', 'in', 'quantum-mechanics']\n",
      "['how', 'to', 'calculate', 'average', 'speed']\n",
      "['lay', 'explanation', 'of', 'the', 'special-theory', 'of', 'relativity']\n",
      "['how', 'to', 'show', 'that', 'the', 'coriolis-effect', 'is', 'irrelevant', 'for', 'the', 'whirl', 'vortex', 'in', 'the', 'sink', 'bathtub']\n",
      "['where', 'do', 'magnets', 'get', 'the', 'energy', 'to', 'repel']\n",
      "['how', 'to', 'check', 'einstein-like', 'equations', 'on', 'their', 'correspondence', 'with', 'the', 'real-world']\n",
      "['impressions', 'of', 'topological-field-theories', 'in', 'mathematics']\n",
      "['what', 'is', 'a', 'capacitive', 'screen', 'sensing']\n"
     ]
    }
   ],
   "source": [
    "for ws in cleansed_test_titles_trigram[:20]:\n",
    "    print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleansed_test_contents_bigram = connect_phrases_bigram(cleansed_test_contents)\n",
    "cleansed_test_contents_trigram = connect_phrases_trigram(cleansed_test_contents_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phrase then tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cleansed_test_titles_trigram\n",
    "# cleansed_test_contents_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('model/stopwords.txt') as f:\n",
    "    long_stopwords = f.read().splitlines()\n",
    "\n",
    "temp_stopwords = set('nan sky change color circuits wire phase explanation resistance solution solutions source principle properties questions calculation mechanics confusion determine car states formula direction fields object terms law quantum equations surface body spin measure form operator objects relationship field difference theory motion calculate relation objects difference question problem change point number size help equation proof physics state function derivation'.split())\n",
    "    \n",
    "stopwords = set(long_stopwords) | nltk_stopwords | temp_stopwords\n",
    "\n",
    "for word in list(stopwords):\n",
    "    for subword in re.sub(r\"[^a-z]\", ' ', word).split():\n",
    "        stopwords.add(subword)\n",
    "    stopwords.add(re.sub(r\"'\", '-', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cleansed_test_titles_tfidf_nostop_phrased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_title_for_tfidf = []\n",
    "for word_seq in cleansed_test_titles_tfidf_nostop_phrased:\n",
    "    test_title_for_tfidf.append( ' '.join([word for word in word_seq if word not in stopwords]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['relates subatomic-particles',\n",
       " 'simplest string-theory',\n",
       " 'lie representations particle-physics',\n",
       " 'determinism',\n",
       " 'hamilton-principle',\n",
       " 'sound-produced',\n",
       " 'experiment disprove string-theory',\n",
       " 'sky change-color sky-blue day red sunrise set black night',\n",
       " 'energy particle collisions calculated',\n",
       " 'monte-carlo']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_title_for_tfidf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_tags_from_cleansed_contents(cleansed_contents, max_features):\n",
    "    vectorizer = TfidfVectorizer(use_idf=False, stop_words = \"english\", \\\n",
    "                                 tokenizer = str.split,    \\\n",
    "                                 preprocessor = None, \\\n",
    "                                 max_features = max_features)\n",
    "    features = vectorizer.fit_transform(cleansed_contents)\n",
    "    feature_words = vectorizer.get_feature_names()\n",
    "    \n",
    "    predicted_tags = []\n",
    "\n",
    "    for feature in features:\n",
    "        values = feature.data\n",
    "        _, word_idxs = feature.nonzero()\n",
    "\n",
    "        index_sorted = np.argsort(values)[::-1]\n",
    "        keywords = [feature_words[wid] for wid in word_idxs[index_sorted]]\n",
    "        predicted_tags.append(' '.join(keywords))\n",
    "    \n",
    "    return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_title_predicted_tags = predict_tags_from_cleansed_contents(test_title_for_tfidf, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predicted_tags_noun = []\n",
    "\n",
    "for tags in test_title_predicted_tags:\n",
    "    pos_tagged = nltk.pos_tag(tags.split())\n",
    "    noun_tags = [i[0] for i in pos_tagged if i[1][0] in \"N\"]\n",
    "    noun_tags_str = ' '.join(noun_tags)\n",
    "    test_predicted_tags_noun.append(noun_tags_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subatomic-particles',\n",
       " 'string-theory',\n",
       " 'representations particle-physics',\n",
       " 'determinism',\n",
       " 'hamilton-principle',\n",
       " '',\n",
       " 'experiment disprove',\n",
       " 'day night',\n",
       " 'energy particle collisions',\n",
       " 'monte-carlo',\n",
       " 'bicycle',\n",
       " 'electromagnetic-field',\n",
       " 'interaction quantum-mechanics',\n",
       " 'speed',\n",
       " 'relativity',\n",
       " 'coriolis sink',\n",
       " 'energy magnets',\n",
       " 'einstein-equations correspondence',\n",
       " 'field-theories mathematics',\n",
       " 'screen']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predicted_tags_noun[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81926"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_predicted_tags_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_tags = []\n",
    "for tags in test_predicted_tags_noun:\n",
    "    all_tags.extend(tags.split())\n",
    "\n",
    "counter = Counter(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('energy', 1960),\n",
       " ('time', 1354),\n",
       " ('mass', 1179),\n",
       " ('gravity', 1023),\n",
       " ('work', 1018),\n",
       " ('force', 941),\n",
       " ('space', 843),\n",
       " ('particle', 807),\n",
       " ('water', 772),\n",
       " ('velocity', 707),\n",
       " ('temperature', 653),\n",
       " ('speed', 622),\n",
       " ('particles', 603),\n",
       " ('quantum-mechanics', 601),\n",
       " ('charge', 562),\n",
       " ('acceleration', 539),\n",
       " ('momentum', 531),\n",
       " ('model', 505),\n",
       " ('earth', 499),\n",
       " ('photons', 482),\n",
       " ('electrons', 475),\n",
       " ('distance', 474),\n",
       " ('photon', 463),\n",
       " ('pressure', 461),\n",
       " ('matter', 438),\n",
       " ('electron', 437),\n",
       " ('air', 422),\n",
       " ('heat', 396),\n",
       " ('power', 390),\n",
       " ('definition', 368),\n",
       " ('vacuum', 357),\n",
       " ('radiation', 349),\n",
       " ('forces', 345),\n",
       " ('frequency', 345),\n",
       " ('density', 337),\n",
       " ('tensor', 319),\n",
       " ('vector', 319),\n",
       " ('gas', 318),\n",
       " ('symmetry', 318),\n",
       " ('general-relativity', 313),\n",
       " ('friction', 306),\n",
       " ('special-relativity', 288),\n",
       " ('interaction', 287),\n",
       " ('sun', 283),\n",
       " ('waves', 281),\n",
       " ('entropy', 277),\n",
       " ('black-holes', 276),\n",
       " ('relativity', 271),\n",
       " ('thermodynamics', 271),\n",
       " ('operators', 269),\n",
       " ('atoms', 268),\n",
       " ('time-dilation', 262),\n",
       " ('collision', 259),\n",
       " ('wave-function', 257),\n",
       " ('distribution', 253),\n",
       " ('circuit', 246),\n",
       " ('rotation', 238),\n",
       " ('voltage', 237),\n",
       " ('light', 236),\n",
       " ('wave', 233),\n",
       " ('action', 231),\n",
       " ('volume', 224),\n",
       " ('dimensions', 223),\n",
       " ('position', 219),\n",
       " ('capacitor', 219),\n",
       " ('term', 218),\n",
       " ('material', 216),\n",
       " ('shape', 216),\n",
       " ('systems', 212),\n",
       " ('rate', 206),\n",
       " ('units', 202),\n",
       " ('order', 198),\n",
       " ('interpretation', 198),\n",
       " ('effects', 196),\n",
       " ('limit', 195),\n",
       " ('orbit', 195),\n",
       " ('gravitational-waves', 194),\n",
       " ('flow', 194),\n",
       " ('laser', 193),\n",
       " ('probability', 192),\n",
       " ('conductor', 192),\n",
       " ('create', 191),\n",
       " ('data', 191),\n",
       " ('spring', 190),\n",
       " ('magnet', 190),\n",
       " ('charges', 190),\n",
       " ('universe', 189),\n",
       " ('materials', 189),\n",
       " ('torque', 187),\n",
       " ('spacetime', 185),\n",
       " ('hole', 183),\n",
       " ('increase', 183),\n",
       " ('stars', 183),\n",
       " ('expansion', 183),\n",
       " ('star', 182),\n",
       " ('glass', 182),\n",
       " ('medium', 181),\n",
       " ('wavefunction', 180),\n",
       " ('hydrogen', 180),\n",
       " ('moon', 178)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roger/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "output_file_name = 'output/20161229_w2v_bigram_title_feature5000_noun_remove-common.csv'\n",
    "\n",
    "df_output = df_test[['id']]\n",
    "df_output['tags'] = test_predicted_tags_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>subatomic-particles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>string-theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>representations particle-physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>determinism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>hamilton-principle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>experiment disprove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>day night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>energy particle collisions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>monte-carlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26</td>\n",
       "      <td>electromagnetic-field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>interaction quantum-mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29</td>\n",
       "      <td>speed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>relativity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32</td>\n",
       "      <td>coriolis sink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35</td>\n",
       "      <td>energy magnets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>37</td>\n",
       "      <td>einstein-equations correspondence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>41</td>\n",
       "      <td>field-theories mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                               tags\n",
       "0    1                subatomic-particles\n",
       "1    2                      string-theory\n",
       "2    3   representations particle-physics\n",
       "3    7                        determinism\n",
       "4    9                 hamilton-principle\n",
       "5   13                                   \n",
       "6   15                experiment disprove\n",
       "7   17                          day night\n",
       "8   19         energy particle collisions\n",
       "9   21                        monte-carlo\n",
       "10  24                            bicycle\n",
       "11  26              electromagnetic-field\n",
       "12  27      interaction quantum-mechanics\n",
       "13  29                              speed\n",
       "14  31                         relativity\n",
       "15  32                      coriolis sink\n",
       "16  35                     energy magnets\n",
       "17  37  einstein-equations correspondence\n",
       "18  41         field-theories mathematics\n",
       "19  49                             screen"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "df_output.to_csv(output_file_name, index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_file = 'output/w2v_trigram_title_feature5000_noun_2.csv'\n",
    "df_input = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>spin subatomic-particles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>explanation string-theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>lie theory representations physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>determinism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>principle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                tags\n",
       "0   1            spin subatomic-particles\n",
       "1   2           explanation string-theory\n",
       "2   3  lie theory representations physics\n",
       "3   7                         determinism\n",
       "4   9                           principle"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_tags = df_input['tags'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform(word):\n",
    "    if word in transform_dict:\n",
    "        return transform_dict[word]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "updated_tags = []\n",
    "for tags in input_tags:\n",
    "    updated_tags.append(' '.join([transform(tag) for tag in tags.split() if tag not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subatomic-particles',\n",
       " 'string-theory',\n",
       " 'lie representations',\n",
       " 'determinism',\n",
       " '',\n",
       " 'sound',\n",
       " 'experiment disprove',\n",
       " 'day sunrise night',\n",
       " 'particles energy collisions',\n",
       " 'monte-carlo',\n",
       " 'bicycle',\n",
       " 'velocity electromagnetic-field',\n",
       " 'interaction quantum-mechanics',\n",
       " 'speed',\n",
       " 'relativity',\n",
       " 'vortex sink',\n",
       " 'energy magnets',\n",
       " 'check real-world',\n",
       " 'field-theories mathematics',\n",
       " 'screen',\n",
       " 'magnets',\n",
       " 'lhc',\n",
       " 'materials stress',\n",
       " 'intuitive-explanation',\n",
       " 'proton treatment',\n",
       " 'physicists',\n",
       " 'materials',\n",
       " 'neutrons',\n",
       " 'interaction quantum-entanglement',\n",
       " 'light']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_tags[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81926"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(updated_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roger/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "output_file_name = 'output/w2v_trigram_title_feature5000_noun_2_remove-common_plural.csv'\n",
    "\n",
    "df_output = df_test[['id']]\n",
    "df_output['tags'] = updated_tags\n",
    "\n",
    "df_output.to_csv(output_file_name, index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
