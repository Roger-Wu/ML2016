{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "TRAIN_FILES = ['biology.csv', 'cooking.csv', 'crypto.csv', 'diy.csv', 'robotics.csv', 'travel.csv']\n",
    "TEST_FILE = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOMAIN_COUNT = len(TRAIN_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_trains = [pd.read_csv(DATA_FOLDER + filename) for filename in TRAIN_FILES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13196, 4)\n",
      "(15404, 4)\n",
      "(10432, 4)\n",
      "(25918, 4)\n",
      "(2771, 4)\n",
      "(19279, 4)\n"
     ]
    }
   ],
   "source": [
    "for df in df_trains:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([df.shape[0] for df in df_trains])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the criticality of the ribosome bindin...</td>\n",
       "      <td>&lt;p&gt;In prokaryotic translation, how critical fo...</td>\n",
       "      <td>ribosome binding-sites translation synthetic-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>How is RNAse contamination in RNA based experi...</td>\n",
       "      <td>&lt;p&gt;Does anyone have any suggestions to prevent...</td>\n",
       "      <td>rna biochemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Are lymphocyte sizes clustered in two groups?</td>\n",
       "      <td>&lt;p&gt;Tortora writes in &lt;em&gt;Principles of Anatomy...</td>\n",
       "      <td>immunology cell-biology hematology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>How long does antibiotic-dosed LB maintain goo...</td>\n",
       "      <td>&lt;p&gt;Various people in our lab will prepare a li...</td>\n",
       "      <td>cell-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Is exon order always preserved in splicing?</td>\n",
       "      <td>&lt;p&gt;Are there any cases in which the splicing m...</td>\n",
       "      <td>splicing mrna spliceosome introns exons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  What is the criticality of the ribosome bindin...   \n",
       "1   2  How is RNAse contamination in RNA based experi...   \n",
       "2   3      Are lymphocyte sizes clustered in two groups?   \n",
       "3   4  How long does antibiotic-dosed LB maintain goo...   \n",
       "4   5        Is exon order always preserved in splicing?   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>In prokaryotic translation, how critical fo...   \n",
       "1  <p>Does anyone have any suggestions to prevent...   \n",
       "2  <p>Tortora writes in <em>Principles of Anatomy...   \n",
       "3  <p>Various people in our lab will prepare a li...   \n",
       "4  <p>Are there any cases in which the splicing m...   \n",
       "\n",
       "                                                tags  \n",
       "0  ribosome binding-sites translation synthetic-b...  \n",
       "1                                   rna biochemistry  \n",
       "2                 immunology cell-biology hematology  \n",
       "3                                       cell-culture  \n",
       "4            splicing mrna spliceosome introns exons  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trains[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # how many unique tags\n",
    "\n",
    "# domain_unique_tags = [set() for i in range(DOMAIN_COUNT)]\n",
    "# unique_tags = set()\n",
    "\n",
    "# for i in range(DOMAIN_COUNT):\n",
    "#     df = df_trains[i]\n",
    "#     posts_tags = df['tags'].tolist()\n",
    "#     for tags in posts_tags:\n",
    "#         for tag in tags.split(' '):\n",
    "#             domain_unique_tags[i].add(tag)\n",
    "#             unique_tags.add(tag)\n",
    "\n",
    "# print('domain_unique_tag counts:')\n",
    "# s = 0\n",
    "# for tag_set in domain_unique_tags:\n",
    "#     print(len(tag_set))\n",
    "\n",
    "# print('sum of domain_unique_tag counts:')\n",
    "# print(sum([len(tag_set) for tag_set in domain_unique_tags]))\n",
    "    \n",
    "# print('all tag count:')\n",
    "# print(len(unique_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "# import nltk\n",
    "# tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "# remove [n]\n",
    "# remove pure numbers, don't remove letter+number words, like CO2\n",
    "\n",
    "# remove stopwords\n",
    "# consider ÂµL?\n",
    "# remove formulas\n",
    "\n",
    "def cleanse_html(content):\n",
    "    return BeautifulSoup(content, \"lxml\").get_text()\n",
    "\n",
    "# only reserve words. don't split sentences\n",
    "def cleanse(content):\n",
    "    # remove html tags\n",
    "    content = BeautifulSoup(content, \"lxml\").get_text()\n",
    "\n",
    "    # remove urls\n",
    "    content = re.sub(r\"\\S+:/\\S+\",\"\", content)  # \"xxx:/xxx\"\n",
    "    content = re.sub(r\"\\S+\\\\\\S+\",\"\", content)  # \"xxx\\xxx\"\n",
    "    \n",
    "#     # split content to sentences\n",
    "#     sentences = tokenizer.tokenize(content)\n",
    "    \n",
    "#     # replace punctuations with whitespaces\n",
    "#     content = re.sub(r\"[^a-zA-Z0-9]\",\" \", content)\n",
    "    \n",
    "    # replace punctuations and numbers with whitespaces\n",
    "    content = re.sub(r\"[^a-zA-Z]\",\" \", content)\n",
    "    \n",
    "#     # remove words that don't contain english (pure number, number+symbol). reserve something like \"CO2\"\n",
    "#     content = re.sub(r\"[^a-zA-Z0-9]\",\" \", content)\n",
    "    \n",
    "    # convert to lowercase\n",
    "    content = content.lower()\n",
    "    \n",
    "    # split into words\n",
    "    words = content.split()\n",
    "    \n",
    "    # remove stopwords\n",
    "    words = [word for word in words if word not in stops]\n",
    "    \n",
    "    # concat words to a string\n",
    "    content = ' '.join(words)\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "13196\n"
     ]
    }
   ],
   "source": [
    "domains_contents = [df['content'].tolist() for df in df_trains]  # list of list of strings\n",
    "print(len(domains_contents))\n",
    "print(len(domains_contents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleansed_contents = [cleanse(content) for domain_contents in domains_contents for content in domain_contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87000\n",
      "182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'prokaryotic translation critical efficient translation location ribosome binding site relative start codon ideally supposed b away start bases away even observable effect translation'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(cleansed_contents))\n",
    "print(len(cleansed_contents[0]))\n",
    "cleansed_contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# words = []\n",
    "# for w in cleansed_contents_words:\n",
    "#     words.extend(w)\n",
    "# print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract content features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=False, \\\n",
    "                             stop_words = \"english\", \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             max_features = 10000)\n",
    "\n",
    "# vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "#                              tokenizer = None,    \\\n",
    "#                              preprocessor = None, \\\n",
    "#                              stop_words = \"english\",   \\\n",
    "#                              max_features = 10000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87000, 10000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents_feature = vectorizer.fit_transform(cleansed_contents)\n",
    "contents_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2879)\t0.182574185835\n",
      "  (0, 700)\t0.182574185835\n",
      "  (0, 602)\t0.36514837167\n",
      "  (0, 8753)\t0.182574185835\n",
      "  (0, 4305)\t0.182574185835\n",
      "  (0, 1641)\t0.182574185835\n",
      "  (0, 8490)\t0.36514837167\n",
      "  (0, 7250)\t0.182574185835\n",
      "  (0, 8127)\t0.182574185835\n",
      "  (0, 829)\t0.182574185835\n",
      "  (0, 7475)\t0.182574185835\n",
      "  (0, 5161)\t0.182574185835\n",
      "  (0, 2887)\t0.182574185835\n",
      "  (0, 2107)\t0.182574185835\n",
      "  (0, 9238)\t0.547722557505\n",
      "  (0, 6821)\t0.182574185835\n"
     ]
    }
   ],
   "source": [
    "print(contents_feature[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract title features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# domains_titles = [df['title'].tolist() for df in df_trains]\n",
    "# titles = [titles for domain_titles in domains_titles for titles in domain_titles]\n",
    "# len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cleansed_titles = [cleanse(title) for title in titles]\n",
    "# len(cleansed_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cleansed_titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# titles_feature = vectorizer.transform(cleansed_titles)\n",
    "# titles_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(titles_feature[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract tags features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tag_vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "#                              tokenizer = None,    \\\n",
    "#                              preprocessor = None, \\\n",
    "#                              stop_words = None)\n",
    "\n",
    "# tag_vectorizer.fit_transform(['apple-juice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tag_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains_tags = [df['tags'].tolist() for df in df_trains]\n",
    "train_tags = [tags for domain_tags in domains_tags for tags in domain_tags]\n",
    "len(train_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tags_feature = tag_vectorizer.fit_transform(train_tags)\n",
    "# tags_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags_split = [ts.split() for ts in train_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ribosome', 'binding-sites', 'translation', 'synthetic-biology'],\n",
       " ['rna', 'biochemistry'],\n",
       " ['immunology', 'cell-biology', 'hematology'],\n",
       " ['cell-culture'],\n",
       " ['splicing', 'mrna', 'spliceosome', 'introns', 'exons'],\n",
       " ['dna', 'biochemistry', 'molecular-biology'],\n",
       " ['neuroscience', 'synapses'],\n",
       " ['plasmids'],\n",
       " ['molecular-genetics', 'gene-expression', 'experimental-design'],\n",
       " ['evolution', 'mitochondria', 'chloroplasts']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_split[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "tags_feature = mlb.fit_transform(tags_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87000, 4268)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = list(mlb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87000, 10000)\n",
      "(87000, 4268)\n"
     ]
    }
   ],
   "source": [
    "print(contents_feature.shape)\n",
    "print(tags_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # sparse to dense\n",
    "# contents_feature_dense = contents_feature.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "tree_count = 10\n",
    "\n",
    "# forest = RandomForestClassifier(n_estimators = 10)\n",
    "# multi_label_forest = OneVsRestClassifier(RandomForestClassifier(n_estimators = 100), n_jobs = -1)\n",
    "multi_label_forest = OneVsRestClassifier(RandomForestClassifier(n_estimators = tree_count), n_jobs = 4)\n",
    "\n",
    "# multi_target_forest = MultiOutputClassifier(forest, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "          n_jobs=4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_forest.fit(contents_feature, tags_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multi_label_forest_10.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(multi_label_forest, 'multi_label_forest_10.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.externals import joblib\n",
    "\n",
    "# multi_label_forest = joblib.load('multi_label_forest_100.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train_predict = multi_label_forest.predict(contents_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec_to_tags(Y):\n",
    "    tags = []\n",
    "     \n",
    "    for i in range(Y.shape[0]):\n",
    "        post_tags = []\n",
    "        for j in range(Y.shape[1]):\n",
    "            if Y[i, j] != 0:\n",
    "                post_tags.append(labels[j])\n",
    "        tags.append(post_tags)\n",
    "    \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def print_labels(Y):\n",
    "#     for i in range(Y.shape[0]):\n",
    "#         for j in range(Y.shape[1]):\n",
    "#             if Y[i, j] != 0:\n",
    "#                 print(labels[j])\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_tags_predict = vec_to_tags(Y_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['binding-sites', 'synthetic-biology', 'translation'],\n",
       " ['biochemistry', 'rna'],\n",
       " ['cell-biology', 'hematology'],\n",
       " ['cell-culture'],\n",
       " ['introns', 'spliceosome', 'splicing'],\n",
       " ['biochemistry', 'dna', 'molecular-biology'],\n",
       " ['neuroscience'],\n",
       " [],\n",
       " ['molecular-genetics'],\n",
       " ['chloroplasts']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_tags_predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ribosome', 'binding-sites', 'translation', 'synthetic-biology'],\n",
       " ['rna', 'biochemistry'],\n",
       " ['immunology', 'cell-biology', 'hematology'],\n",
       " ['cell-culture'],\n",
       " ['splicing', 'mrna', 'spliceosome', 'introns', 'exons'],\n",
       " ['dna', 'biochemistry', 'molecular-biology'],\n",
       " ['neuroscience', 'synapses'],\n",
       " ['plasmids'],\n",
       " ['molecular-genetics', 'gene-expression', 'experimental-design'],\n",
       " ['evolution', 'mitochondria', 'chloroplasts']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_split[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81926, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(DATA_FOLDER + TEST_FILE)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleansed_test_contents = [cleanse(content) for content in df_test['content'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['often hear subatomic particles property called spin also actually relate spinning axis like would think particles spin spin mean actual spinning motion',\n",
       " 'would explain string theory non physicists specially interested plausible needed successfully prove',\n",
       " 'question posted many different forums thought maybe someone would better conceptual answer seen physicists care representations lie groups think representation means sort group acting vector space vector space lie group acting certain things invariant group action maybe dumb question thought might good start clarify specifically thinking symmetry groups people think relation standard model care might certain group see group acting acting etc',\n",
       " 'main problems need solve prove laplace determinism correct overcome uncertainty principle',\n",
       " 'hamilton principle states dynamic system always follows path action integral stationary maximum minimum action integral stationary basis hamilton state principle',\n",
       " 'using term sound life really clue sound exactly created sound produced measured',\n",
       " 'know big controversy two groups physicists support string theory think oppose one arguments second group way disprove correctness string theory question defined experiment would disprove string theory',\n",
       " 'sky change color sky blue day red sunrise set black night',\n",
       " 'physicists often refer energy collisions different particles question energy calculated kinetic energy also related question know aim higher higher energy collisions e g test higgs boson understanding higher energy either accelerate use particles higher mass correct',\n",
       " 'monte carlo method used physics']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansed_test_contents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81926, 10000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_contents_features = vectorizer.transform(cleansed_test_contents)\n",
    "test_contents_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_tags_features_predict = multi_label_forest.predict(test_contents_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec_to_tags_string(Y):\n",
    "    tags = []\n",
    "     \n",
    "    for i in range(Y.shape[0]):\n",
    "        post_tags = []\n",
    "        for j in range(Y.shape[1]):\n",
    "            if Y[i, j] != 0:\n",
    "                post_tags.append(labels[j])\n",
    "        tags.append(' '.join(post_tags))\n",
    "    \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tags_strings = vec_to_tags_string(test_tags_features_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'cancer',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'biochemistry',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tags_strings[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove [n]\n",
    "# remove pure numbers, don't remove letter+number words, like CO2\n",
    "# remove urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf-idf over all contents\n",
    "# same-category contents concat as one doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for each tag, find words that mostly exist in title and contents of that tag\n",
    "# use entropy to do the above thing\n",
    "# if a test content contains words only exist in , then the content is very likely about that domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as classification problem\n",
    "# features: bow (normalized)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
